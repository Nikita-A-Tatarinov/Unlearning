# Unlearning in LLMs

This project consists of 3 main stages

## 1. Applying various unlearning methods to LLMs

## 2. Using prompt engineering, showing that they struggle

## 3. Introducing a set of simple Seq2Seq models converting unsafe responses to safes

The rationale is that it is less costly that parameter optimization/merging bad is less limited that in-context learning.
