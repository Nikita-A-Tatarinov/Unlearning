{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. devices: \n",
      "2\n",
      "NVIDIA L40S\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "if torch.cuda.is_available(): \n",
    "    print(\"Num. devices: \") \n",
    "    print(torch.cuda.device_count()) \n",
    "    print(torch.cuda.get_device_name(0)) \n",
    "else: \n",
    "    print(\"No GPU available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [01:04<00:00,  9.19s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [00:28<00:00,  4.04s/it]\n",
      "====rmu Config====\n",
      "model_name_or_path=PKU-Alignment/alpaca-7b-reproduced\n",
      "module_str={model_name}.model.layers[{layer_id}]\n",
      "output_dir=models/alpaca_rmu_alpha_0\n",
      "retain_corpora=['SafeRLHF-corpora/safe_train_sampled']\n",
      "forget_corpora=['SafeRLHF-corpora/Privacy_Violation_train']\n",
      "alpha=[0.0]\n",
      "steering_coeffs=6.5\n",
      "lr=0.0001\n",
      "min_len=0\n",
      "max_len=2000\n",
      "batch_size=2\n",
      "max_num_batches=150\n",
      "layer_id=7\n",
      "layer_ids=[5, 6, 7]\n",
      "param_ids=[6]\n",
      "seed=42\n",
      "verbose=True\n",
      "steering_coeff_list=[6.5]\n",
      "=====\n",
      "/home/hice1/jli928/.conda/envs/model-unlearning/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "======= Epoch 0 =======\n",
      "  0%|                                                   | 0/150 [00:00<?, ?it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 185, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.453 | unlearn_loss: 2.453 | retain_loss: 0 | param_change: 1.982e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.125\n",
      "Topic 0 frozen_forget_activations.norm= 23.125\n",
      "Topic 0 updated_retain_activations.norm= 23.5\n",
      "Topic 0 frozen_retain_activations.norm= 23.5\n",
      "  1%|▎                                          | 1/150 [00:01<02:58,  1.20s/it]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 170, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.672 | unlearn_loss: 2.672 | retain_loss: 0 | param_change: 2.101e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.375\n",
      "Topic 0 frozen_forget_activations.norm= 24.5\n",
      "Topic 0 updated_retain_activations.norm= 19.5\n",
      "Topic 0 frozen_retain_activations.norm= 19.5\n",
      "  1%|▌                                          | 2/150 [00:01<01:38,  1.50it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 199, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.297 | unlearn_loss: 2.297 | retain_loss: 0 | param_change: 1.922e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.625\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 25.25\n",
      "Topic 0 frozen_retain_activations.norm= 25.5\n",
      "  2%|▊                                          | 3/150 [00:01<01:08,  2.14it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 251, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.836 | unlearn_loss: 1.836 | retain_loss: 0 | param_change: 1.885e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.5\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 23.0\n",
      "Topic 0 frozen_retain_activations.norm= 23.0\n",
      "  3%|█▏                                         | 4/150 [00:01<00:56,  2.61it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 190, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.391 | unlearn_loss: 2.391 | retain_loss: 0 | param_change: 1.863e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 23.75\n",
      "Topic 0 frozen_retain_activations.norm= 24.0\n",
      "  3%|█▍                                         | 5/150 [00:02<00:47,  3.07it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 243, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.891 | unlearn_loss: 1.891 | retain_loss: 0 | param_change: 1.825e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.5\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 24.0\n",
      "Topic 0 frozen_retain_activations.norm= 24.25\n",
      "  4%|█▋                                         | 6/150 [00:02<00:43,  3.35it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 293, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.586 | unlearn_loss: 1.586 | retain_loss: 0 | param_change: 1.743e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 20.125\n",
      "Topic 0 frozen_forget_activations.norm= 20.625\n",
      "Topic 0 updated_retain_activations.norm= 24.125\n",
      "Topic 0 frozen_retain_activations.norm= 24.5\n",
      "  5%|██                                         | 7/150 [00:02<00:41,  3.46it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 244, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.875 | unlearn_loss: 1.875 | retain_loss: 0 | param_change: 1.863e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.0\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 24.5\n",
      "Topic 0 frozen_retain_activations.norm= 25.125\n",
      "  5%|██▎                                        | 8/150 [00:02<00:39,  3.64it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 162, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.797 | unlearn_loss: 2.797 | retain_loss: 0 | param_change: 2.027e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 24.25\n",
      "Topic 0 frozen_forget_activations.norm= 25.125\n",
      "Topic 0 updated_retain_activations.norm= 25.0\n",
      "Topic 0 frozen_retain_activations.norm= 25.625\n",
      "  6%|██▌                                        | 9/150 [00:03<00:36,  3.89it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 219, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.078 | unlearn_loss: 2.078 | retain_loss: 0 | param_change: 1.684e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 21.5\n",
      "Topic 0 frozen_forget_activations.norm= 22.5\n",
      "Topic 0 updated_retain_activations.norm= 21.5\n",
      "Topic 0 frozen_retain_activations.norm= 22.375\n",
      "  7%|██▊                                       | 10/150 [00:03<00:35,  3.95it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 151, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.984 | unlearn_loss: 2.984 | retain_loss: 0 | param_change: 1.937e-06\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 24.5\n",
      "Topic 0 frozen_forget_activations.norm= 25.75\n",
      "Topic 0 updated_retain_activations.norm= 23.75\n",
      "Topic 0 frozen_retain_activations.norm= 24.75\n",
      "  7%|███                                       | 11/150 [00:03<00:33,  4.12it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 144, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.125 | unlearn_loss: 3.125 | retain_loss: 0 | param_change: 1.706e-06\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 24.5\n",
      "Topic 0 frozen_forget_activations.norm= 25.75\n",
      "Topic 0 updated_retain_activations.norm= 34.75\n",
      "Topic 0 frozen_retain_activations.norm= 35.5\n",
      "  8%|███▎                                      | 12/150 [00:03<00:33,  4.11it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 255, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.797 | unlearn_loss: 1.797 | retain_loss: 0 | param_change: 1.587e-06\n",
      "unlearn_cosine_sim=0.98828125\n",
      "retain_cosine_sim=0.9921875\n",
      "Topic 0 updated_forget_activations.norm= 20.125\n",
      "Topic 0 frozen_forget_activations.norm= 21.5\n",
      "Topic 0 updated_retain_activations.norm= 21.375\n",
      "Topic 0 frozen_retain_activations.norm= 22.5\n",
      "  9%|███▋                                      | 13/150 [00:04<00:34,  4.03it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 283, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.641 | unlearn_loss: 1.641 | retain_loss: 0 | param_change: 1.609e-06\n",
      "unlearn_cosine_sim=0.984375\n",
      "retain_cosine_sim=0.98828125\n",
      "Topic 0 updated_forget_activations.norm= 19.625\n",
      "Topic 0 frozen_forget_activations.norm= 21.125\n",
      "Topic 0 updated_retain_activations.norm= 20.875\n",
      "Topic 0 frozen_retain_activations.norm= 22.25\n",
      "  9%|███▉                                      | 14/150 [00:04<00:34,  3.90it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 141, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.188 | unlearn_loss: 3.188 | retain_loss: 0 | param_change: 1.572e-06\n",
      "unlearn_cosine_sim=0.984375\n",
      "retain_cosine_sim=0.98828125\n",
      "Topic 0 updated_forget_activations.norm= 24.25\n",
      "Topic 0 frozen_forget_activations.norm= 25.75\n",
      "Topic 0 updated_retain_activations.norm= 24.75\n",
      "Topic 0 frozen_retain_activations.norm= 26.0\n",
      " 10%|████▏                                     | 15/150 [00:04<00:32,  4.10it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 181, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.5 | unlearn_loss: 2.5 | retain_loss: 0 | param_change: 1.594e-06\n",
      "unlearn_cosine_sim=0.9765625\n",
      "retain_cosine_sim=0.984375\n",
      "Topic 0 updated_forget_activations.norm= 22.25\n",
      "Topic 0 frozen_forget_activations.norm= 24.0\n",
      "Topic 0 updated_retain_activations.norm= 20.75\n",
      "Topic 0 frozen_retain_activations.norm= 22.5\n",
      " 11%|████▍                                     | 16/150 [00:04<00:32,  4.15it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 220, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.062 | unlearn_loss: 2.062 | retain_loss: 0 | param_change: 1.438e-06\n",
      "unlearn_cosine_sim=0.9765625\n",
      "retain_cosine_sim=0.98046875\n",
      "Topic 0 updated_forget_activations.norm= 20.375\n",
      "Topic 0 frozen_forget_activations.norm= 22.125\n",
      "Topic 0 updated_retain_activations.norm= 21.75\n",
      "Topic 0 frozen_retain_activations.norm= 23.5\n",
      " 11%|████▊                                     | 17/150 [00:05<00:31,  4.17it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 231, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.984 | unlearn_loss: 1.984 | retain_loss: 0 | param_change: 1.371e-06\n",
      "unlearn_cosine_sim=0.97265625\n",
      "retain_cosine_sim=0.984375\n",
      "Topic 0 updated_forget_activations.norm= 20.0\n",
      "Topic 0 frozen_forget_activations.norm= 21.875\n",
      "Topic 0 updated_retain_activations.norm= 20.625\n",
      "Topic 0 frozen_retain_activations.norm= 22.375\n",
      " 12%|█████                                     | 18/150 [00:05<00:32,  4.12it/s]loss: 3.125 | unlearn_loss: 3.125 | retain_loss: 0 | param_change: 1.468e-06\n",
      "unlearn_cosine_sim=0.9609375\n",
      "retain_cosine_sim=0.9765625\n",
      "Topic 0 updated_forget_activations.norm= 23.75\n",
      "Topic 0 frozen_forget_activations.norm= 26.0\n",
      "Topic 0 updated_retain_activations.norm= 23.25\n",
      "Topic 0 frozen_retain_activations.norm= 25.125\n",
      " 13%|█████▎                                    | 19/150 [00:05<00:30,  4.26it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 153, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.938 | unlearn_loss: 2.938 | retain_loss: 0 | param_change: 1.468e-06\n",
      "unlearn_cosine_sim=0.95703125\n",
      "retain_cosine_sim=0.98046875\n",
      "Topic 0 updated_forget_activations.norm= 23.25\n",
      "Topic 0 frozen_forget_activations.norm= 25.5\n",
      "Topic 0 updated_retain_activations.norm= 22.25\n",
      "Topic 0 frozen_retain_activations.norm= 24.25\n",
      " 13%|█████▌                                    | 20/150 [00:05<00:29,  4.34it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 217, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.094 | unlearn_loss: 2.094 | retain_loss: 0 | param_change: 1.416e-06\n",
      "unlearn_cosine_sim=0.953125\n",
      "retain_cosine_sim=0.97265625\n",
      "Topic 0 updated_forget_activations.norm= 20.125\n",
      "Topic 0 frozen_forget_activations.norm= 22.5\n",
      "Topic 0 updated_retain_activations.norm= 21.75\n",
      "Topic 0 frozen_retain_activations.norm= 23.75\n",
      " 14%|█████▉                                    | 21/150 [00:06<00:29,  4.32it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 197, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.297 | unlearn_loss: 2.297 | retain_loss: 0 | param_change: 1.445e-06\n",
      "unlearn_cosine_sim=0.953125\n",
      "retain_cosine_sim=0.9765625\n",
      "Topic 0 updated_forget_activations.norm= 21.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.5\n",
      "Topic 0 updated_retain_activations.norm= 30.5\n",
      "Topic 0 frozen_retain_activations.norm= 32.75\n",
      " 15%|██████▏                                   | 22/150 [00:06<00:29,  4.40it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 195, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.328 | unlearn_loss: 2.328 | retain_loss: 0 | param_change: 1.319e-06\n",
      "unlearn_cosine_sim=0.93359375\n",
      "retain_cosine_sim=0.95703125\n",
      "Topic 0 updated_forget_activations.norm= 21.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.5\n",
      "Topic 0 updated_retain_activations.norm= 20.25\n",
      "Topic 0 frozen_retain_activations.norm= 22.625\n",
      " 15%|██████▍                                   | 23/150 [00:06<00:29,  4.33it/s]loss: 1.781 | unlearn_loss: 1.781 | retain_loss: 0 | param_change: 1.147e-06\n",
      "unlearn_cosine_sim=0.921875\n",
      "retain_cosine_sim=0.9609375\n",
      "Topic 0 updated_forget_activations.norm= 18.75\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 30.875\n",
      "Topic 0 frozen_retain_activations.norm= 33.5\n",
      " 16%|██████▋                                   | 24/150 [00:06<00:29,  4.31it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 201, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.25 | unlearn_loss: 2.25 | retain_loss: 0 | param_change: 1.207e-06\n",
      "unlearn_cosine_sim=0.91796875\n",
      "retain_cosine_sim=0.921875\n",
      "Topic 0 updated_forget_activations.norm= 20.5\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 20.875\n",
      "Topic 0 frozen_retain_activations.norm= 23.75\n",
      " 17%|███████                                   | 25/150 [00:06<00:29,  4.30it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 252, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.805 | unlearn_loss: 1.805 | retain_loss: 0 | param_change: 1.17e-06\n",
      "unlearn_cosine_sim=0.91796875\n",
      "retain_cosine_sim=0.95703125\n",
      "Topic 0 updated_forget_activations.norm= 18.875\n",
      "Topic 0 frozen_forget_activations.norm= 21.5\n",
      "Topic 0 updated_retain_activations.norm= 24.875\n",
      "Topic 0 frozen_retain_activations.norm= 27.625\n",
      " 17%|███████▎                                  | 26/150 [00:07<00:29,  4.26it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 205, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.203 | unlearn_loss: 2.203 | retain_loss: 0 | param_change: 1.147e-06\n",
      "unlearn_cosine_sim=0.890625\n",
      "retain_cosine_sim=0.94921875\n",
      "Topic 0 updated_forget_activations.norm= 20.125\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 32.0\n",
      "Topic 0 frozen_retain_activations.norm= 35.0\n",
      " 18%|███████▌                                  | 27/150 [00:07<00:28,  4.36it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 187, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.406 | unlearn_loss: 2.406 | retain_loss: 0 | param_change: 1.155e-06\n",
      "unlearn_cosine_sim=0.8828125\n",
      "retain_cosine_sim=0.9453125\n",
      "Topic 0 updated_forget_activations.norm= 20.75\n",
      "Topic 0 frozen_forget_activations.norm= 24.0\n",
      "Topic 0 updated_retain_activations.norm= 20.25\n",
      "Topic 0 frozen_retain_activations.norm= 23.0\n",
      " 19%|███████▊                                  | 28/150 [00:07<00:28,  4.33it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 176, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.562 | unlearn_loss: 2.562 | retain_loss: 0 | param_change: 1.155e-06\n",
      "unlearn_cosine_sim=0.88671875\n",
      "retain_cosine_sim=0.92578125\n",
      "Topic 0 updated_forget_activations.norm= 21.125\n",
      "Topic 0 frozen_forget_activations.norm= 24.25\n",
      "Topic 0 updated_retain_activations.norm= 19.75\n",
      "Topic 0 frozen_retain_activations.norm= 22.5\n",
      " 19%|████████                                  | 29/150 [00:07<00:28,  4.32it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 84, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 5.25 | unlearn_loss: 5.25 | retain_loss: 0 | param_change: 1.661e-06\n",
      "unlearn_cosine_sim=0.95703125\n",
      "retain_cosine_sim=0.91796875\n",
      "Topic 0 updated_forget_activations.norm= 30.0\n",
      "Topic 0 frozen_forget_activations.norm= 32.75\n",
      "Topic 0 updated_retain_activations.norm= 18.875\n",
      "Topic 0 frozen_retain_activations.norm= 22.0\n",
      " 20%|████████▍                                 | 30/150 [00:08<00:27,  4.35it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 198, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.281 | unlearn_loss: 2.281 | retain_loss: 0 | param_change: 1.088e-06\n",
      "unlearn_cosine_sim=0.88671875\n",
      "retain_cosine_sim=0.9140625\n",
      "Topic 0 updated_forget_activations.norm= 19.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.0\n",
      "Topic 0 updated_retain_activations.norm= 20.75\n",
      "Topic 0 frozen_retain_activations.norm= 24.0\n",
      " 21%|████████▋                                 | 31/150 [00:08<00:27,  4.35it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 212, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.125 | unlearn_loss: 2.125 | retain_loss: 0 | param_change: 9.499e-07\n",
      "unlearn_cosine_sim=0.859375\n",
      "retain_cosine_sim=0.890625\n",
      "Topic 0 updated_forget_activations.norm= 19.0\n",
      "Topic 0 frozen_forget_activations.norm= 22.5\n",
      "Topic 0 updated_retain_activations.norm= 18.0\n",
      "Topic 0 frozen_retain_activations.norm= 21.375\n",
      " 21%|████████▉                                 | 32/150 [00:08<00:28,  4.19it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 242, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.875 | unlearn_loss: 1.875 | retain_loss: 0 | param_change: 1.013e-06\n",
      "unlearn_cosine_sim=0.875\n",
      "retain_cosine_sim=0.92578125\n",
      "Topic 0 updated_forget_activations.norm= 18.75\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 24.0\n",
      "Topic 0 frozen_retain_activations.norm= 27.125\n",
      " 22%|█████████▏                                | 33/150 [00:08<00:28,  4.18it/s]loss: 2.203 | unlearn_loss: 2.203 | retain_loss: 0 | param_change: 9.537e-07\n",
      "unlearn_cosine_sim=0.875\n",
      "retain_cosine_sim=0.921875\n",
      "Topic 0 updated_forget_activations.norm= 19.25\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 22.5\n",
      "Topic 0 frozen_retain_activations.norm= 25.75\n",
      " 23%|█████████▌                                | 34/150 [00:09<00:27,  4.23it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 175, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.562 | unlearn_loss: 2.562 | retain_loss: 0 | param_change: 9.686e-07\n",
      "unlearn_cosine_sim=0.84765625\n",
      "retain_cosine_sim=0.890625\n",
      "Topic 0 updated_forget_activations.norm= 20.5\n",
      "Topic 0 frozen_forget_activations.norm= 24.375\n",
      "Topic 0 updated_retain_activations.norm= 16.0\n",
      "Topic 0 frozen_retain_activations.norm= 19.5\n",
      " 23%|█████████▊                                | 35/150 [00:09<00:28,  3.99it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 182, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.469 | unlearn_loss: 2.469 | retain_loss: 0 | param_change: 9.164e-07\n",
      "unlearn_cosine_sim=0.84765625\n",
      "retain_cosine_sim=0.9140625\n",
      "Topic 0 updated_forget_activations.norm= 20.25\n",
      "Topic 0 frozen_forget_activations.norm= 24.0\n",
      "Topic 0 updated_retain_activations.norm= 20.5\n",
      "Topic 0 frozen_retain_activations.norm= 23.75\n",
      " 24%|██████████                                | 36/150 [00:09<00:27,  4.12it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 172, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.609 | unlearn_loss: 2.609 | retain_loss: 0 | param_change: 9.388e-07\n",
      "unlearn_cosine_sim=0.84375\n",
      "retain_cosine_sim=0.87890625\n",
      "Topic 0 updated_forget_activations.norm= 20.5\n",
      "Topic 0 frozen_forget_activations.norm= 24.25\n",
      "Topic 0 updated_retain_activations.norm= 22.25\n",
      "Topic 0 frozen_retain_activations.norm= 26.0\n",
      " 25%|██████████▎                               | 37/150 [00:09<00:26,  4.24it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 189, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.391 | unlearn_loss: 2.391 | retain_loss: 0 | param_change: 1.08e-06\n",
      "unlearn_cosine_sim=0.88671875\n",
      "retain_cosine_sim=0.90234375\n",
      "Topic 0 updated_forget_activations.norm= 20.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.5\n",
      "Topic 0 updated_retain_activations.norm= 21.25\n",
      "Topic 0 frozen_retain_activations.norm= 24.75\n",
      " 25%|██████████▋                               | 38/150 [00:10<00:25,  4.32it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 225, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.016 | unlearn_loss: 2.016 | retain_loss: 0 | param_change: 9.76e-07\n",
      "unlearn_cosine_sim=0.859375\n",
      "retain_cosine_sim=0.8671875\n",
      "Topic 0 updated_forget_activations.norm= 18.25\n",
      "Topic 0 frozen_forget_activations.norm= 22.125\n",
      "Topic 0 updated_retain_activations.norm= 22.25\n",
      "Topic 0 frozen_retain_activations.norm= 26.0\n",
      " 26%|██████████▉                               | 39/150 [00:10<00:25,  4.30it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 113, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.953 | unlearn_loss: 3.953 | retain_loss: 0 | param_change: 9.909e-07\n",
      "unlearn_cosine_sim=0.87890625\n",
      "retain_cosine_sim=0.90625\n",
      "Topic 0 updated_forget_activations.norm= 24.5\n",
      "Topic 0 frozen_forget_activations.norm= 28.25\n",
      "Topic 0 updated_retain_activations.norm= 21.875\n",
      "Topic 0 frozen_retain_activations.norm= 25.5\n",
      " 27%|███████████▏                              | 40/150 [00:10<00:24,  4.43it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 119, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.75 | unlearn_loss: 3.75 | retain_loss: 0 | param_change: 1.132e-06\n",
      "unlearn_cosine_sim=0.88671875\n",
      "retain_cosine_sim=0.83984375\n",
      "Topic 0 updated_forget_activations.norm= 24.375\n",
      "Topic 0 frozen_forget_activations.norm= 28.25\n",
      "Topic 0 updated_retain_activations.norm= 21.125\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 27%|███████████▍                              | 41/150 [00:10<00:24,  4.52it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 174, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.578 | unlearn_loss: 2.578 | retain_loss: 0 | param_change: 9.127e-07\n",
      "unlearn_cosine_sim=0.87109375\n",
      "retain_cosine_sim=0.91796875\n",
      "Topic 0 updated_forget_activations.norm= 20.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 17.0\n",
      "Topic 0 frozen_retain_activations.norm= 20.0\n",
      " 28%|███████████▊                              | 42/150 [00:10<00:25,  4.20it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 248, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.82 | unlearn_loss: 1.82 | retain_loss: 0 | param_change: 8.382e-07\n",
      "unlearn_cosine_sim=0.83984375\n",
      "retain_cosine_sim=0.9140625\n",
      "Topic 0 updated_forget_activations.norm= 17.75\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 23.25\n",
      "Topic 0 frozen_retain_activations.norm= 26.875\n",
      " 29%|████████████                              | 43/150 [00:11<00:25,  4.18it/s]loss: 1.773 | unlearn_loss: 1.773 | retain_loss: 0 | param_change: 7.749e-07\n",
      "unlearn_cosine_sim=0.8125\n",
      "retain_cosine_sim=0.8515625\n",
      "Topic 0 updated_forget_activations.norm= 17.375\n",
      "Topic 0 frozen_forget_activations.norm= 21.5\n",
      "Topic 0 updated_retain_activations.norm= 18.75\n",
      "Topic 0 frozen_retain_activations.norm= 22.625\n",
      " 29%|████████████▎                             | 44/150 [00:11<00:26,  4.07it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 164, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.734 | unlearn_loss: 2.734 | retain_loss: 0 | param_change: 8.68e-07\n",
      "unlearn_cosine_sim=0.8046875\n",
      "retain_cosine_sim=0.8671875\n",
      "Topic 0 updated_forget_activations.norm= 20.375\n",
      "Topic 0 frozen_forget_activations.norm= 24.75\n",
      "Topic 0 updated_retain_activations.norm= 21.25\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 30%|████████████▌                             | 45/150 [00:11<00:24,  4.21it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 339, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.344 | unlearn_loss: 1.344 | retain_loss: 0 | param_change: 8.568e-07\n",
      "unlearn_cosine_sim=0.83203125\n",
      "retain_cosine_sim=0.8515625\n",
      "Topic 0 updated_forget_activations.norm= 16.125\n",
      "Topic 0 frozen_forget_activations.norm= 20.125\n",
      "Topic 0 updated_retain_activations.norm= 17.5\n",
      "Topic 0 frozen_retain_activations.norm= 21.75\n",
      " 31%|████████████▉                             | 46/150 [00:12<00:28,  3.64it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 177, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.531 | unlearn_loss: 2.531 | retain_loss: 0 | param_change: 9.052e-07\n",
      "unlearn_cosine_sim=0.84375\n",
      "retain_cosine_sim=0.8515625\n",
      "Topic 0 updated_forget_activations.norm= 19.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.875\n",
      "Topic 0 updated_retain_activations.norm= 17.5\n",
      "Topic 0 frozen_retain_activations.norm= 21.375\n",
      " 31%|█████████████▏                            | 47/150 [00:12<00:27,  3.75it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 206, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.188 | unlearn_loss: 2.188 | retain_loss: 0 | param_change: 8.196e-07\n",
      "unlearn_cosine_sim=0.828125\n",
      "retain_cosine_sim=0.8359375\n",
      "Topic 0 updated_forget_activations.norm= 18.625\n",
      "Topic 0 frozen_forget_activations.norm= 23.0\n",
      "Topic 0 updated_retain_activations.norm= 26.375\n",
      "Topic 0 frozen_retain_activations.norm= 30.75\n",
      " 32%|█████████████▍                            | 48/150 [00:12<00:25,  3.96it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 156, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.875 | unlearn_loss: 2.875 | retain_loss: 0 | param_change: 9.09e-07\n",
      "unlearn_cosine_sim=0.78125\n",
      "retain_cosine_sim=0.8671875\n",
      "Topic 0 updated_forget_activations.norm= 21.0\n",
      "Topic 0 frozen_forget_activations.norm= 25.625\n",
      "Topic 0 updated_retain_activations.norm= 21.125\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 33%|█████████████▋                            | 49/150 [00:12<00:24,  4.13it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 111, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 4.031 | unlearn_loss: 4.031 | retain_loss: 0 | param_change: 1.028e-06\n",
      "unlearn_cosine_sim=0.85546875\n",
      "retain_cosine_sim=0.86328125\n",
      "Topic 0 updated_forget_activations.norm= 24.5\n",
      "Topic 0 frozen_forget_activations.norm= 28.75\n",
      "Topic 0 updated_retain_activations.norm= 30.375\n",
      "Topic 0 frozen_retain_activations.norm= 35.0\n",
      " 33%|██████████████                            | 50/150 [00:12<00:23,  4.27it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 209, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.156 | unlearn_loss: 2.156 | retain_loss: 0 | param_change: 7.972e-07\n",
      "unlearn_cosine_sim=0.78125\n",
      "retain_cosine_sim=0.87109375\n",
      "Topic 0 updated_forget_activations.norm= 18.375\n",
      "Topic 0 frozen_forget_activations.norm= 22.875\n",
      "Topic 0 updated_retain_activations.norm= 26.875\n",
      "Topic 0 frozen_retain_activations.norm= 31.25\n",
      " 34%|██████████████▎                           | 51/150 [00:13<00:22,  4.35it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 240, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.891 | unlearn_loss: 1.891 | retain_loss: 0 | param_change: 7.637e-07\n",
      "unlearn_cosine_sim=0.76953125\n",
      "retain_cosine_sim=0.859375\n",
      "Topic 0 updated_forget_activations.norm= 17.375\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 17.5\n",
      "Topic 0 frozen_retain_activations.norm= 21.75\n",
      " 35%|██████████████▌                           | 52/150 [00:13<00:23,  4.20it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 79, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 5.562 | unlearn_loss: 5.562 | retain_loss: 0 | param_change: 1.088e-06\n",
      "unlearn_cosine_sim=0.828125\n",
      "retain_cosine_sim=0.87890625\n",
      "Topic 0 updated_forget_activations.norm= 29.25\n",
      "Topic 0 frozen_forget_activations.norm= 34.0\n",
      "Topic 0 updated_retain_activations.norm= 25.25\n",
      "Topic 0 frozen_retain_activations.norm= 29.5\n",
      " 35%|██████████████▊                           | 53/150 [00:13<00:21,  4.43it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 264, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.727 | unlearn_loss: 1.727 | retain_loss: 0 | param_change: 7.935e-07\n",
      "unlearn_cosine_sim=0.77734375\n",
      "retain_cosine_sim=0.7890625\n",
      "Topic 0 updated_forget_activations.norm= 17.125\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 17.5\n",
      "Topic 0 frozen_retain_activations.norm= 22.0\n",
      " 36%|███████████████                           | 54/150 [00:13<00:23,  4.13it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 226, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2 | unlearn_loss: 2 | retain_loss: 0 | param_change: 7.413e-07\n",
      "unlearn_cosine_sim=0.73828125\n",
      "retain_cosine_sim=0.83203125\n",
      "Topic 0 updated_forget_activations.norm= 17.75\n",
      "Topic 0 frozen_forget_activations.norm= 22.25\n",
      "Topic 0 updated_retain_activations.norm= 22.375\n",
      "Topic 0 frozen_retain_activations.norm= 26.875\n",
      " 37%|███████████████▍                          | 55/150 [00:14<00:22,  4.17it/s]loss: 2.359 | unlearn_loss: 2.359 | retain_loss: 0 | param_change: 7.153e-07\n",
      "unlearn_cosine_sim=0.76953125\n",
      "retain_cosine_sim=0.828125\n",
      "Topic 0 updated_forget_activations.norm= 18.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 21.75\n",
      "Topic 0 frozen_retain_activations.norm= 26.25\n",
      " 37%|███████████████▋                          | 56/150 [00:14<00:22,  4.27it/s]loss: 2.453 | unlearn_loss: 2.453 | retain_loss: 0 | param_change: 8.047e-07\n",
      "unlearn_cosine_sim=0.7734375\n",
      "retain_cosine_sim=0.81640625\n",
      "Topic 0 updated_forget_activations.norm= 18.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 18.0\n",
      "Topic 0 frozen_retain_activations.norm= 22.75\n",
      " 38%|███████████████▉                          | 57/150 [00:14<00:21,  4.26it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 150, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.984 | unlearn_loss: 2.984 | retain_loss: 0 | param_change: 7.898e-07\n",
      "unlearn_cosine_sim=0.7890625\n",
      "retain_cosine_sim=0.765625\n",
      "Topic 0 updated_forget_activations.norm= 20.75\n",
      "Topic 0 frozen_forget_activations.norm= 25.25\n",
      "Topic 0 updated_retain_activations.norm= 19.25\n",
      "Topic 0 frozen_retain_activations.norm= 24.25\n",
      " 39%|████████████████▏                         | 58/150 [00:14<00:21,  4.34it/s]loss: 2.172 | unlearn_loss: 2.172 | retain_loss: 0 | param_change: 7.302e-07\n",
      "unlearn_cosine_sim=0.73046875\n",
      "retain_cosine_sim=0.7890625\n",
      "Topic 0 updated_forget_activations.norm= 18.25\n",
      "Topic 0 frozen_forget_activations.norm= 23.0\n",
      "Topic 0 updated_retain_activations.norm= 21.25\n",
      "Topic 0 frozen_retain_activations.norm= 26.0\n",
      " 39%|████████████████▌                         | 59/150 [00:15<00:20,  4.35it/s]loss: 2.062 | unlearn_loss: 2.062 | retain_loss: 0 | param_change: 8.307e-07\n",
      "unlearn_cosine_sim=0.7734375\n",
      "retain_cosine_sim=0.8046875\n",
      "Topic 0 updated_forget_activations.norm= 17.375\n",
      "Topic 0 frozen_forget_activations.norm= 22.125\n",
      "Topic 0 updated_retain_activations.norm= 19.875\n",
      "Topic 0 frozen_retain_activations.norm= 24.75\n",
      " 40%|████████████████▊                         | 60/150 [00:15<00:20,  4.34it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 135, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.297 | unlearn_loss: 3.297 | retain_loss: 0 | param_change: 8.866e-07\n",
      "unlearn_cosine_sim=0.76953125\n",
      "retain_cosine_sim=0.828125\n",
      "Topic 0 updated_forget_activations.norm= 21.75\n",
      "Topic 0 frozen_forget_activations.norm= 26.5\n",
      "Topic 0 updated_retain_activations.norm= 23.0\n",
      "Topic 0 frozen_retain_activations.norm= 27.75\n",
      " 41%|█████████████████                         | 61/150 [00:15<00:19,  4.47it/s]loss: 2.469 | unlearn_loss: 2.469 | retain_loss: 0 | param_change: 8.456e-07\n",
      "unlearn_cosine_sim=0.765625\n",
      "retain_cosine_sim=0.796875\n",
      "Topic 0 updated_forget_activations.norm= 18.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.5\n",
      "Topic 0 updated_retain_activations.norm= 19.25\n",
      "Topic 0 frozen_retain_activations.norm= 24.0\n",
      " 41%|█████████████████▎                        | 62/150 [00:15<00:19,  4.46it/s]loss: 1.891 | unlearn_loss: 1.891 | retain_loss: 0 | param_change: 6.668e-07\n",
      "unlearn_cosine_sim=0.69140625\n",
      "retain_cosine_sim=0.7890625\n",
      "Topic 0 updated_forget_activations.norm= 17.5\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 18.0\n",
      "Topic 0 frozen_retain_activations.norm= 22.5\n",
      " 42%|█████████████████▋                        | 63/150 [00:15<00:20,  4.30it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 102, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 4.375 | unlearn_loss: 4.375 | retain_loss: 0 | param_change: 9.611e-07\n",
      "unlearn_cosine_sim=0.765625\n",
      "retain_cosine_sim=0.796875\n",
      "Topic 0 updated_forget_activations.norm= 25.375\n",
      "Topic 0 frozen_forget_activations.norm= 30.25\n",
      "Topic 0 updated_retain_activations.norm= 19.0\n",
      "Topic 0 frozen_retain_activations.norm= 23.375\n",
      " 43%|█████████████████▉                        | 64/150 [00:16<00:19,  4.37it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 180, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.484 | unlearn_loss: 2.484 | retain_loss: 0 | param_change: 5.96e-07\n",
      "unlearn_cosine_sim=0.68359375\n",
      "retain_cosine_sim=0.75390625\n",
      "Topic 0 updated_forget_activations.norm= 18.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 20.5\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 43%|██████████████████▏                       | 65/150 [00:16<00:19,  4.42it/s]loss: 2.75 | unlearn_loss: 2.75 | retain_loss: 0 | param_change: 6.743e-07\n",
      "unlearn_cosine_sim=0.72265625\n",
      "retain_cosine_sim=0.7734375\n",
      "Topic 0 updated_forget_activations.norm= 20.0\n",
      "Topic 0 frozen_forget_activations.norm= 24.75\n",
      "Topic 0 updated_retain_activations.norm= 21.125\n",
      "Topic 0 frozen_retain_activations.norm= 25.875\n",
      " 44%|██████████████████▍                       | 66/150 [00:16<00:18,  4.48it/s]loss: 1.789 | unlearn_loss: 1.789 | retain_loss: 0 | param_change: 8.307e-07\n",
      "unlearn_cosine_sim=0.7265625\n",
      "retain_cosine_sim=0.76953125\n",
      "Topic 0 updated_forget_activations.norm= 17.0\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 17.875\n",
      "Topic 0 frozen_retain_activations.norm= 22.75\n",
      " 45%|██████████████████▊                       | 67/150 [00:16<00:19,  4.27it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 146, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.047 | unlearn_loss: 3.047 | retain_loss: 0 | param_change: 6.221e-07\n",
      "unlearn_cosine_sim=0.6796875\n",
      "retain_cosine_sim=0.7890625\n",
      "Topic 0 updated_forget_activations.norm= 20.75\n",
      "Topic 0 frozen_forget_activations.norm= 25.75\n",
      "Topic 0 updated_retain_activations.norm= 15.9375\n",
      "Topic 0 frozen_retain_activations.norm= 20.375\n",
      " 45%|███████████████████                       | 68/150 [00:17<00:20,  3.91it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 184, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.422 | unlearn_loss: 2.422 | retain_loss: 0 | param_change: 6.557e-07\n",
      "unlearn_cosine_sim=0.671875\n",
      "retain_cosine_sim=0.80859375\n",
      "Topic 0 updated_forget_activations.norm= 19.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 21.75\n",
      "Topic 0 frozen_retain_activations.norm= 26.375\n",
      " 46%|███████████████████▎                      | 69/150 [00:17<00:19,  4.09it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 281, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.633 | unlearn_loss: 1.633 | retain_loss: 0 | param_change: 6.258e-07\n",
      "unlearn_cosine_sim=0.6796875\n",
      "retain_cosine_sim=0.71875\n",
      "Topic 0 updated_forget_activations.norm= 16.75\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 20.25\n",
      "Topic 0 frozen_retain_activations.norm= 25.125\n",
      " 47%|███████████████████▌                      | 70/150 [00:17<00:19,  4.00it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 223, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2 | unlearn_loss: 2 | retain_loss: 0 | param_change: 7.488e-07\n",
      "unlearn_cosine_sim=0.703125\n",
      "retain_cosine_sim=0.703125\n",
      "Topic 0 updated_forget_activations.norm= 17.25\n",
      "Topic 0 frozen_forget_activations.norm= 22.375\n",
      "Topic 0 updated_retain_activations.norm= 19.0\n",
      "Topic 0 frozen_retain_activations.norm= 24.0\n",
      " 47%|███████████████████▉                      | 71/150 [00:17<00:19,  4.06it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 158, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.812 | unlearn_loss: 2.812 | retain_loss: 0 | param_change: 6.519e-07\n",
      "unlearn_cosine_sim=0.640625\n",
      "retain_cosine_sim=0.6953125\n",
      "Topic 0 updated_forget_activations.norm= 20.25\n",
      "Topic 0 frozen_forget_activations.norm= 25.25\n",
      "Topic 0 updated_retain_activations.norm= 16.25\n",
      "Topic 0 frozen_retain_activations.norm= 21.0\n",
      " 48%|████████████████████▏                     | 72/150 [00:18<00:19,  3.98it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 228, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.984 | unlearn_loss: 1.984 | retain_loss: 0 | param_change: 7.413e-07\n",
      "unlearn_cosine_sim=0.68359375\n",
      "retain_cosine_sim=0.67578125\n",
      "Topic 0 updated_forget_activations.norm= 17.125\n",
      "Topic 0 frozen_forget_activations.norm= 22.25\n",
      "Topic 0 updated_retain_activations.norm= 21.25\n",
      "Topic 0 frozen_retain_activations.norm= 26.25\n",
      " 49%|████████████████████▍                     | 73/150 [00:18<00:18,  4.06it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 324, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.406 | unlearn_loss: 1.406 | retain_loss: 0 | param_change: 5.96e-07\n",
      "unlearn_cosine_sim=0.65625\n",
      "retain_cosine_sim=0.70703125\n",
      "Topic 0 updated_forget_activations.norm= 15.875\n",
      "Topic 0 frozen_forget_activations.norm= 20.75\n",
      "Topic 0 updated_retain_activations.norm= 25.25\n",
      "Topic 0 frozen_retain_activations.norm= 30.25\n",
      " 49%|████████████████████▋                     | 74/150 [00:18<00:19,  3.96it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 163, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.734 | unlearn_loss: 2.734 | retain_loss: 0 | param_change: 6.929e-07\n",
      "unlearn_cosine_sim=0.66796875\n",
      "retain_cosine_sim=0.734375\n",
      "Topic 0 updated_forget_activations.norm= 20.0\n",
      "Topic 0 frozen_forget_activations.norm= 24.75\n",
      "Topic 0 updated_retain_activations.norm= 19.5\n",
      "Topic 0 frozen_retain_activations.norm= 24.25\n",
      " 50%|█████████████████████                     | 75/150 [00:18<00:18,  4.11it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 265, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.703 | unlearn_loss: 1.703 | retain_loss: 0 | param_change: 5.513e-07\n",
      "unlearn_cosine_sim=0.62890625\n",
      "retain_cosine_sim=0.68359375\n",
      "Topic 0 updated_forget_activations.norm= 16.75\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 16.25\n",
      "Topic 0 frozen_retain_activations.norm= 21.0\n",
      " 51%|█████████████████████▎                    | 76/150 [00:19<00:19,  3.82it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 207, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.156 | unlearn_loss: 2.156 | retain_loss: 0 | param_change: 5.662e-07\n",
      "unlearn_cosine_sim=0.6328125\n",
      "retain_cosine_sim=0.66015625\n",
      "Topic 0 updated_forget_activations.norm= 18.25\n",
      "Topic 0 frozen_forget_activations.norm= 23.0\n",
      "Topic 0 updated_retain_activations.norm= 16.625\n",
      "Topic 0 frozen_retain_activations.norm= 21.75\n",
      " 51%|█████████████████████▌                    | 77/150 [00:19<00:18,  3.88it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 179, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.484 | unlearn_loss: 2.484 | retain_loss: 0 | param_change: 6.855e-07\n",
      "unlearn_cosine_sim=0.65234375\n",
      "retain_cosine_sim=0.68359375\n",
      "Topic 0 updated_forget_activations.norm= 18.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.625\n",
      "Topic 0 updated_retain_activations.norm= 18.5\n",
      "Topic 0 frozen_retain_activations.norm= 23.125\n",
      " 52%|█████████████████████▊                    | 78/150 [00:19<00:17,  4.00it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 152, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.922 | unlearn_loss: 2.922 | retain_loss: 0 | param_change: 6.035e-07\n",
      "unlearn_cosine_sim=0.6171875\n",
      "retain_cosine_sim=0.63671875\n",
      "Topic 0 updated_forget_activations.norm= 20.75\n",
      "Topic 0 frozen_forget_activations.norm= 25.875\n",
      "Topic 0 updated_retain_activations.norm= 18.25\n",
      "Topic 0 frozen_retain_activations.norm= 23.25\n",
      " 53%|██████████████████████                    | 79/150 [00:19<00:17,  4.10it/s]loss: 2.406 | unlearn_loss: 2.406 | retain_loss: 0 | param_change: 6.445e-07\n",
      "unlearn_cosine_sim=0.5859375\n",
      "retain_cosine_sim=0.6953125\n",
      "Topic 0 updated_forget_activations.norm= 19.5\n",
      "Topic 0 frozen_forget_activations.norm= 24.25\n",
      "Topic 0 updated_retain_activations.norm= 17.0\n",
      "Topic 0 frozen_retain_activations.norm= 21.625\n",
      " 53%|██████████████████████▍                   | 80/150 [00:20<00:17,  4.00it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 188, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.375 | unlearn_loss: 2.375 | retain_loss: 0 | param_change: 5.029e-07\n",
      "unlearn_cosine_sim=0.6171875\n",
      "retain_cosine_sim=0.67578125\n",
      "Topic 0 updated_forget_activations.norm= 18.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 15.375\n",
      "Topic 0 frozen_retain_activations.norm= 20.125\n",
      " 54%|██████████████████████▋                   | 81/150 [00:20<00:18,  3.73it/s]loss: 2.859 | unlearn_loss: 2.859 | retain_loss: 0 | param_change: 6.035e-07\n",
      "unlearn_cosine_sim=0.609375\n",
      "retain_cosine_sim=0.69140625\n",
      "Topic 0 updated_forget_activations.norm= 20.75\n",
      "Topic 0 frozen_forget_activations.norm= 25.5\n",
      "Topic 0 updated_retain_activations.norm= 22.875\n",
      "Topic 0 frozen_retain_activations.norm= 27.625\n",
      " 55%|██████████████████████▉                   | 82/150 [00:20<00:17,  3.99it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 192, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.328 | unlearn_loss: 2.328 | retain_loss: 0 | param_change: 5.29e-07\n",
      "unlearn_cosine_sim=0.5859375\n",
      "retain_cosine_sim=0.640625\n",
      "Topic 0 updated_forget_activations.norm= 19.125\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 20.125\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 55%|███████████████████████▏                  | 83/150 [00:20<00:16,  4.12it/s]loss: 1.992 | unlearn_loss: 1.992 | retain_loss: 0 | param_change: 5.066e-07\n",
      "unlearn_cosine_sim=0.5859375\n",
      "retain_cosine_sim=0.62109375\n",
      "Topic 0 updated_forget_activations.norm= 17.25\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 21.0\n",
      "Topic 0 frozen_retain_activations.norm= 25.75\n",
      " 56%|███████████████████████▌                  | 84/150 [00:21<00:15,  4.14it/s]loss: 3.047 | unlearn_loss: 3.047 | retain_loss: 0 | param_change: 6.072e-07\n",
      "unlearn_cosine_sim=0.59375\n",
      "retain_cosine_sim=0.65625\n",
      "Topic 0 updated_forget_activations.norm= 21.25\n",
      "Topic 0 frozen_forget_activations.norm= 25.875\n",
      "Topic 0 updated_retain_activations.norm= 18.75\n",
      "Topic 0 frozen_retain_activations.norm= 23.75\n",
      " 57%|███████████████████████▊                  | 85/150 [00:21<00:15,  4.25it/s]loss: 2.062 | unlearn_loss: 2.062 | retain_loss: 0 | param_change: 7.376e-07\n",
      "unlearn_cosine_sim=0.55078125\n",
      "retain_cosine_sim=0.65234375\n",
      "Topic 0 updated_forget_activations.norm= 18.0\n",
      "Topic 0 frozen_forget_activations.norm= 22.5\n",
      "Topic 0 updated_retain_activations.norm= 20.0\n",
      "Topic 0 frozen_retain_activations.norm= 24.875\n",
      " 57%|████████████████████████                  | 86/150 [00:21<00:14,  4.27it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 166, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.688 | unlearn_loss: 2.688 | retain_loss: 0 | param_change: 5.849e-07\n",
      "unlearn_cosine_sim=0.5859375\n",
      "retain_cosine_sim=0.62890625\n",
      "Topic 0 updated_forget_activations.norm= 19.5\n",
      "Topic 0 frozen_forget_activations.norm= 24.5\n",
      "Topic 0 updated_retain_activations.norm= 19.375\n",
      "Topic 0 frozen_retain_activations.norm= 24.125\n",
      " 58%|████████████████████████▎                 | 87/150 [00:21<00:14,  4.34it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 215, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.078 | unlearn_loss: 2.078 | retain_loss: 0 | param_change: 5.141e-07\n",
      "unlearn_cosine_sim=0.59765625\n",
      "retain_cosine_sim=0.6171875\n",
      "Topic 0 updated_forget_activations.norm= 18.0\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 20.5\n",
      "Topic 0 frozen_retain_activations.norm= 25.125\n",
      " 59%|████████████████████████▋                 | 88/150 [00:22<00:14,  4.33it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 169, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.641 | unlearn_loss: 2.641 | retain_loss: 0 | param_change: 5.551e-07\n",
      "unlearn_cosine_sim=0.578125\n",
      "retain_cosine_sim=0.625\n",
      "Topic 0 updated_forget_activations.norm= 19.5\n",
      "Topic 0 frozen_forget_activations.norm= 24.375\n",
      "Topic 0 updated_retain_activations.norm= 17.25\n",
      "Topic 0 frozen_retain_activations.norm= 22.25\n",
      " 59%|████████████████████████▉                 | 89/150 [00:22<00:14,  4.32it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 129, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.453 | unlearn_loss: 3.453 | retain_loss: 0 | param_change: 6.407e-07\n",
      "unlearn_cosine_sim=0.6171875\n",
      "retain_cosine_sim=0.609375\n",
      "Topic 0 updated_forget_activations.norm= 22.75\n",
      "Topic 0 frozen_forget_activations.norm= 27.75\n",
      "Topic 0 updated_retain_activations.norm= 22.0\n",
      "Topic 0 frozen_retain_activations.norm= 27.0\n",
      " 60%|█████████████████████████▏                | 90/150 [00:22<00:13,  4.43it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 361, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.25 | unlearn_loss: 1.25 | retain_loss: 0 | param_change: 4.601e-07\n",
      "unlearn_cosine_sim=0.56640625\n",
      "retain_cosine_sim=0.66015625\n",
      "Topic 0 updated_forget_activations.norm= 15.5\n",
      "Topic 0 frozen_forget_activations.norm= 20.25\n",
      "Topic 0 updated_retain_activations.norm= 20.125\n",
      "Topic 0 frozen_retain_activations.norm= 24.75\n",
      " 61%|█████████████████████████▍                | 91/150 [00:22<00:14,  4.12it/s]loss: 2.812 | unlearn_loss: 2.812 | retain_loss: 0 | param_change: 4.88e-07\n",
      "unlearn_cosine_sim=0.55859375\n",
      "retain_cosine_sim=0.61328125\n",
      "Topic 0 updated_forget_activations.norm= 20.375\n",
      "Topic 0 frozen_forget_activations.norm= 25.25\n",
      "Topic 0 updated_retain_activations.norm= 18.625\n",
      "Topic 0 frozen_retain_activations.norm= 23.5\n",
      " 61%|█████████████████████████▊                | 92/150 [00:22<00:13,  4.22it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 258, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.75 | unlearn_loss: 1.75 | retain_loss: 0 | param_change: 4.545e-07\n",
      "unlearn_cosine_sim=0.578125\n",
      "retain_cosine_sim=0.6796875\n",
      "Topic 0 updated_forget_activations.norm= 16.625\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 29.625\n",
      "Topic 0 frozen_retain_activations.norm= 34.5\n",
      " 62%|██████████████████████████                | 93/150 [00:23<00:13,  4.16it/s]loss: 1.594 | unlearn_loss: 1.594 | retain_loss: 0 | param_change: 4.172e-07\n",
      "unlearn_cosine_sim=0.5625\n",
      "retain_cosine_sim=0.7421875\n",
      "Topic 0 updated_forget_activations.norm= 16.5\n",
      "Topic 0 frozen_forget_activations.norm= 21.0\n",
      "Topic 0 updated_retain_activations.norm= 286.0\n",
      "Topic 0 frozen_retain_activations.norm= 290.0\n",
      " 63%|██████████████████████████▎               | 94/150 [00:23<00:14,  3.83it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 103, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 4.312 | unlearn_loss: 4.312 | retain_loss: 0 | param_change: 8.047e-07\n",
      "unlearn_cosine_sim=0.65625\n",
      "retain_cosine_sim=0.57421875\n",
      "Topic 0 updated_forget_activations.norm= 25.0\n",
      "Topic 0 frozen_forget_activations.norm= 30.0\n",
      "Topic 0 updated_retain_activations.norm= 17.25\n",
      "Topic 0 frozen_retain_activations.norm= 22.25\n",
      " 63%|██████████████████████████▌               | 95/150 [00:23<00:13,  4.01it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 161, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.766 | unlearn_loss: 2.766 | retain_loss: 0 | param_change: 4.657e-07\n",
      "unlearn_cosine_sim=0.5390625\n",
      "retain_cosine_sim=0.62890625\n",
      "Topic 0 updated_forget_activations.norm= 20.125\n",
      "Topic 0 frozen_forget_activations.norm= 25.0\n",
      "Topic 0 updated_retain_activations.norm= 16.75\n",
      "Topic 0 frozen_retain_activations.norm= 22.0\n",
      " 64%|██████████████████████████▉               | 96/150 [00:24<00:13,  4.07it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 282, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.602 | unlearn_loss: 1.602 | retain_loss: 0 | param_change: 4.545e-07\n",
      "unlearn_cosine_sim=0.53515625\n",
      "retain_cosine_sim=0.6328125\n",
      "Topic 0 updated_forget_activations.norm= 15.9375\n",
      "Topic 0 frozen_forget_activations.norm= 20.75\n",
      "Topic 0 updated_retain_activations.norm= 17.25\n",
      "Topic 0 frozen_retain_activations.norm= 22.0\n",
      " 65%|███████████████████████████▏              | 97/150 [00:24<00:13,  3.90it/s]loss: 2.547 | unlearn_loss: 2.547 | retain_loss: 0 | param_change: 5.402e-07\n",
      "unlearn_cosine_sim=0.57421875\n",
      "retain_cosine_sim=0.5859375\n",
      "Topic 0 updated_forget_activations.norm= 18.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 17.25\n",
      "Topic 0 frozen_retain_activations.norm= 22.25\n",
      " 65%|███████████████████████████▍              | 98/150 [00:24<00:13,  3.94it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 269, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.68 | unlearn_loss: 1.68 | retain_loss: 0 | param_change: 4.433e-07\n",
      "unlearn_cosine_sim=0.54296875\n",
      "retain_cosine_sim=0.67578125\n",
      "Topic 0 updated_forget_activations.norm= 16.25\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 21.5\n",
      "Topic 0 frozen_retain_activations.norm= 26.375\n",
      " 66%|███████████████████████████▋              | 99/150 [00:24<00:13,  3.92it/s]loss: 2.719 | unlearn_loss: 2.719 | retain_loss: 0 | param_change: 5.029e-07\n",
      "unlearn_cosine_sim=0.55859375\n",
      "retain_cosine_sim=0.61328125\n",
      "Topic 0 updated_forget_activations.norm= 20.0\n",
      "Topic 0 frozen_forget_activations.norm= 24.875\n",
      "Topic 0 updated_retain_activations.norm= 18.75\n",
      "Topic 0 frozen_retain_activations.norm= 23.5\n",
      " 67%|███████████████████████████▎             | 100/150 [00:25<00:12,  4.04it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 154, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.891 | unlearn_loss: 2.891 | retain_loss: 0 | param_change: 5.029e-07\n",
      "unlearn_cosine_sim=0.56640625\n",
      "retain_cosine_sim=0.546875\n",
      "Topic 0 updated_forget_activations.norm= 20.0\n",
      "Topic 0 frozen_forget_activations.norm= 25.0\n",
      "Topic 0 updated_retain_activations.norm= 18.75\n",
      "Topic 0 frozen_retain_activations.norm= 24.0\n",
      " 67%|███████████████████████████▌             | 101/150 [00:25<00:11,  4.18it/s]loss: 2.25 | unlearn_loss: 2.25 | retain_loss: 0 | param_change: 4.228e-07\n",
      "unlearn_cosine_sim=0.5390625\n",
      "retain_cosine_sim=0.609375\n",
      "Topic 0 updated_forget_activations.norm= 18.5\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 19.25\n",
      "Topic 0 frozen_retain_activations.norm= 24.5\n",
      " 68%|███████████████████████████▉             | 102/150 [00:25<00:11,  4.22it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 155, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.875 | unlearn_loss: 2.875 | retain_loss: 0 | param_change: 5.364e-07\n",
      "unlearn_cosine_sim=0.5625\n",
      "retain_cosine_sim=0.57421875\n",
      "Topic 0 updated_forget_activations.norm= 19.75\n",
      "Topic 0 frozen_forget_activations.norm= 25.0\n",
      "Topic 0 updated_retain_activations.norm= 17.25\n",
      "Topic 0 frozen_retain_activations.norm= 22.25\n",
      " 69%|████████████████████████████▏            | 103/150 [00:25<00:11,  4.23it/s]loss: 2.281 | unlearn_loss: 2.281 | retain_loss: 0 | param_change: 4.992e-07\n",
      "unlearn_cosine_sim=0.56640625\n",
      "retain_cosine_sim=0.61328125\n",
      "Topic 0 updated_forget_activations.norm= 18.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.125\n",
      "Topic 0 updated_retain_activations.norm= 16.75\n",
      "Topic 0 frozen_retain_activations.norm= 21.625\n",
      " 69%|████████████████████████████▍            | 104/150 [00:25<00:11,  4.13it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 245, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.82 | unlearn_loss: 1.82 | retain_loss: 0 | param_change: 3.818e-07\n",
      "unlearn_cosine_sim=0.53125\n",
      "retain_cosine_sim=0.66015625\n",
      "Topic 0 updated_forget_activations.norm= 16.75\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 21.5\n",
      "Topic 0 frozen_retain_activations.norm= 27.0\n",
      " 70%|████████████████████████████▋            | 105/150 [00:26<00:10,  4.12it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 323, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.391 | unlearn_loss: 1.391 | retain_loss: 0 | param_change: 4.731e-07\n",
      "unlearn_cosine_sim=0.5546875\n",
      "retain_cosine_sim=0.59375\n",
      "Topic 0 updated_forget_activations.norm= 15.375\n",
      "Topic 0 frozen_forget_activations.norm= 20.0\n",
      "Topic 0 updated_retain_activations.norm= 23.0\n",
      "Topic 0 frozen_retain_activations.norm= 28.125\n",
      " 71%|████████████████████████████▉            | 106/150 [00:26<00:11,  4.00it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 230, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.961 | unlearn_loss: 1.961 | retain_loss: 0 | param_change: 5.327e-07\n",
      "unlearn_cosine_sim=0.54296875\n",
      "retain_cosine_sim=0.55078125\n",
      "Topic 0 updated_forget_activations.norm= 17.75\n",
      "Topic 0 frozen_forget_activations.norm= 22.375\n",
      "Topic 0 updated_retain_activations.norm= 17.5\n",
      "Topic 0 frozen_retain_activations.norm= 22.75\n",
      " 71%|█████████████████████████████▏           | 107/150 [00:26<00:10,  4.00it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 165, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.703 | unlearn_loss: 2.703 | retain_loss: 0 | param_change: 4.563e-07\n",
      "unlearn_cosine_sim=0.5703125\n",
      "retain_cosine_sim=0.5859375\n",
      "Topic 0 updated_forget_activations.norm= 19.875\n",
      "Topic 0 frozen_forget_activations.norm= 24.75\n",
      "Topic 0 updated_retain_activations.norm= 21.375\n",
      "Topic 0 frozen_retain_activations.norm= 26.5\n",
      " 72%|█████████████████████████████▌           | 108/150 [00:26<00:10,  4.16it/s]loss: 2.375 | unlearn_loss: 2.375 | retain_loss: 0 | param_change: 5.253e-07\n",
      "unlearn_cosine_sim=0.578125\n",
      "retain_cosine_sim=0.64453125\n",
      "Topic 0 updated_forget_activations.norm= 18.5\n",
      "Topic 0 frozen_forget_activations.norm= 23.625\n",
      "Topic 0 updated_retain_activations.norm= 22.0\n",
      "Topic 0 frozen_retain_activations.norm= 27.125\n",
      " 73%|█████████████████████████████▊           | 109/150 [00:27<00:09,  4.27it/s]loss: 1.836 | unlearn_loss: 1.836 | retain_loss: 0 | param_change: 3.93e-07\n",
      "unlearn_cosine_sim=0.546875\n",
      "retain_cosine_sim=0.59375\n",
      "Topic 0 updated_forget_activations.norm= 17.25\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 17.125\n",
      "Topic 0 frozen_retain_activations.norm= 22.625\n",
      " 73%|██████████████████████████████           | 110/150 [00:27<00:09,  4.15it/s]loss: 1.703 | unlearn_loss: 1.703 | retain_loss: 0 | param_change: 4.452e-07\n",
      "unlearn_cosine_sim=0.5\n",
      "retain_cosine_sim=0.6171875\n",
      "Topic 0 updated_forget_activations.norm= 16.25\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 29.0\n",
      "Topic 0 frozen_retain_activations.norm= 34.25\n",
      " 74%|██████████████████████████████▎          | 111/150 [00:27<00:09,  4.11it/s]loss: 2.234 | unlearn_loss: 2.234 | retain_loss: 0 | param_change: 4.359e-07\n",
      "unlearn_cosine_sim=0.54296875\n",
      "retain_cosine_sim=0.6015625\n",
      "Topic 0 updated_forget_activations.norm= 18.5\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 19.625\n",
      "Topic 0 frozen_retain_activations.norm= 24.625\n",
      " 75%|██████████████████████████████▌          | 112/150 [00:27<00:09,  4.17it/s]loss: 2.891 | unlearn_loss: 2.891 | retain_loss: 0 | param_change: 5.513e-07\n",
      "unlearn_cosine_sim=0.578125\n",
      "retain_cosine_sim=0.640625\n",
      "Topic 0 updated_forget_activations.norm= 19.75\n",
      "Topic 0 frozen_forget_activations.norm= 25.125\n",
      "Topic 0 updated_retain_activations.norm= 20.75\n",
      "Topic 0 frozen_retain_activations.norm= 25.625\n",
      " 75%|██████████████████████████████▉          | 113/150 [00:28<00:08,  4.29it/s]loss: 2.344 | unlearn_loss: 2.344 | retain_loss: 0 | param_change: 5.104e-07\n",
      "unlearn_cosine_sim=0.55078125\n",
      "retain_cosine_sim=0.5703125\n",
      "Topic 0 updated_forget_activations.norm= 18.25\n",
      "Topic 0 frozen_forget_activations.norm= 23.625\n",
      "Topic 0 updated_retain_activations.norm= 22.75\n",
      "Topic 0 frozen_retain_activations.norm= 28.0\n",
      " 76%|███████████████████████████████▏         | 114/150 [00:28<00:08,  4.40it/s]loss: 2.516 | unlearn_loss: 2.516 | retain_loss: 0 | param_change: 4.955e-07\n",
      "unlearn_cosine_sim=0.54296875\n",
      "retain_cosine_sim=0.5859375\n",
      "Topic 0 updated_forget_activations.norm= 19.25\n",
      "Topic 0 frozen_forget_activations.norm= 24.25\n",
      "Topic 0 updated_retain_activations.norm= 18.25\n",
      "Topic 0 frozen_retain_activations.norm= 23.5\n",
      " 77%|███████████████████████████████▍         | 115/150 [00:28<00:08,  4.37it/s]loss: 2.766 | unlearn_loss: 2.766 | retain_loss: 0 | param_change: 4.657e-07\n",
      "unlearn_cosine_sim=0.53125\n",
      "retain_cosine_sim=0.59765625\n",
      "Topic 0 updated_forget_activations.norm= 19.25\n",
      "Topic 0 frozen_forget_activations.norm= 24.5\n",
      "Topic 0 updated_retain_activations.norm= 17.0\n",
      "Topic 0 frozen_retain_activations.norm= 22.0\n",
      " 77%|███████████████████████████████▋         | 116/150 [00:28<00:07,  4.32it/s]loss: 2.438 | unlearn_loss: 2.438 | retain_loss: 0 | param_change: 4.396e-07\n",
      "unlearn_cosine_sim=0.54296875\n",
      "retain_cosine_sim=0.55078125\n",
      "Topic 0 updated_forget_activations.norm= 19.0\n",
      "Topic 0 frozen_forget_activations.norm= 24.0\n",
      "Topic 0 updated_retain_activations.norm= 17.0\n",
      "Topic 0 frozen_retain_activations.norm= 22.375\n",
      " 78%|███████████████████████████████▉         | 117/150 [00:29<00:07,  4.30it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 193, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.312 | unlearn_loss: 2.312 | retain_loss: 0 | param_change: 3.93e-07\n",
      "unlearn_cosine_sim=0.52734375\n",
      "retain_cosine_sim=0.546875\n",
      "Topic 0 updated_forget_activations.norm= 18.25\n",
      "Topic 0 frozen_forget_activations.norm= 23.5\n",
      "Topic 0 updated_retain_activations.norm= 14.625\n",
      "Topic 0 frozen_retain_activations.norm= 19.875\n",
      " 79%|████████████████████████████████▎        | 118/150 [00:29<00:07,  4.00it/s]loss: 2.766 | unlearn_loss: 2.766 | retain_loss: 0 | param_change: 4.079e-07\n",
      "unlearn_cosine_sim=0.50390625\n",
      "retain_cosine_sim=0.58984375\n",
      "Topic 0 updated_forget_activations.norm= 19.125\n",
      "Topic 0 frozen_forget_activations.norm= 24.5\n",
      "Topic 0 updated_retain_activations.norm= 26.625\n",
      "Topic 0 frozen_retain_activations.norm= 32.25\n",
      " 79%|████████████████████████████████▌        | 119/150 [00:29<00:07,  4.22it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 131, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.391 | unlearn_loss: 3.391 | retain_loss: 0 | param_change: 5.439e-07\n",
      "unlearn_cosine_sim=0.578125\n",
      "retain_cosine_sim=0.55859375\n",
      "Topic 0 updated_forget_activations.norm= 21.5\n",
      "Topic 0 frozen_forget_activations.norm= 26.75\n",
      "Topic 0 updated_retain_activations.norm= 17.25\n",
      "Topic 0 frozen_retain_activations.norm= 22.75\n",
      " 80%|████████████████████████████████▊        | 120/150 [00:29<00:07,  4.27it/s]loss: 2.281 | unlearn_loss: 2.281 | retain_loss: 0 | param_change: 4.061e-07\n",
      "unlearn_cosine_sim=0.52734375\n",
      "retain_cosine_sim=0.58203125\n",
      "Topic 0 updated_forget_activations.norm= 17.625\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 23.5\n",
      "Topic 0 frozen_retain_activations.norm= 29.0\n",
      " 81%|█████████████████████████████████        | 121/150 [00:29<00:06,  4.35it/s]loss: 2.406 | unlearn_loss: 2.406 | retain_loss: 0 | param_change: 5.029e-07\n",
      "unlearn_cosine_sim=0.515625\n",
      "retain_cosine_sim=0.59375\n",
      "Topic 0 updated_forget_activations.norm= 18.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 19.5\n",
      "Topic 0 frozen_retain_activations.norm= 24.5\n",
      " 81%|█████████████████████████████████▎       | 122/150 [00:30<00:06,  4.39it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 168, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.641 | unlearn_loss: 2.641 | retain_loss: 0 | param_change: 4.955e-07\n",
      "unlearn_cosine_sim=0.5234375\n",
      "retain_cosine_sim=0.61328125\n",
      "Topic 0 updated_forget_activations.norm= 18.5\n",
      "Topic 0 frozen_forget_activations.norm= 24.0\n",
      "Topic 0 updated_retain_activations.norm= 19.25\n",
      "Topic 0 frozen_retain_activations.norm= 24.5\n",
      " 82%|█████████████████████████████████▌       | 123/150 [00:30<00:06,  4.44it/s]loss: 2.156 | unlearn_loss: 2.156 | retain_loss: 0 | param_change: 4.079e-07\n",
      "unlearn_cosine_sim=0.515625\n",
      "retain_cosine_sim=0.53515625\n",
      "Topic 0 updated_forget_activations.norm= 17.5\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 22.0\n",
      "Topic 0 frozen_retain_activations.norm= 27.25\n",
      " 83%|█████████████████████████████████▉       | 124/150 [00:30<00:05,  4.44it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 235, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.914 | unlearn_loss: 1.914 | retain_loss: 0 | param_change: 4.34e-07\n",
      "unlearn_cosine_sim=0.53125\n",
      "retain_cosine_sim=0.6015625\n",
      "Topic 0 updated_forget_activations.norm= 16.625\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 18.0\n",
      "Topic 0 frozen_retain_activations.norm= 23.5\n",
      " 83%|██████████████████████████████████▏      | 125/150 [00:30<00:05,  4.31it/s]loss: 2.625 | unlearn_loss: 2.625 | retain_loss: 0 | param_change: 5.439e-07\n",
      "unlearn_cosine_sim=0.55078125\n",
      "retain_cosine_sim=0.5703125\n",
      "Topic 0 updated_forget_activations.norm= 18.5\n",
      "Topic 0 frozen_forget_activations.norm= 24.25\n",
      "Topic 0 updated_retain_activations.norm= 21.125\n",
      "Topic 0 frozen_retain_activations.norm= 26.25\n",
      " 84%|██████████████████████████████████▍      | 126/150 [00:31<00:05,  4.39it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 122, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.641 | unlearn_loss: 3.641 | retain_loss: 0 | param_change: 4.582e-07\n",
      "unlearn_cosine_sim=0.54296875\n",
      "retain_cosine_sim=0.54296875\n",
      "Topic 0 updated_forget_activations.norm= 22.75\n",
      "Topic 0 frozen_forget_activations.norm= 28.0\n",
      "Topic 0 updated_retain_activations.norm= 16.25\n",
      "Topic 0 frozen_retain_activations.norm= 21.5\n",
      " 85%|██████████████████████████████████▋      | 127/150 [00:31<00:05,  4.33it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 232, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.938 | unlearn_loss: 1.938 | retain_loss: 0 | param_change: 4.526e-07\n",
      "unlearn_cosine_sim=0.49609375\n",
      "retain_cosine_sim=0.59375\n",
      "Topic 0 updated_forget_activations.norm= 16.375\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 20.75\n",
      "Topic 0 frozen_retain_activations.norm= 26.0\n",
      " 85%|██████████████████████████████████▉      | 128/150 [00:31<00:05,  4.31it/s]loss: 2.688 | unlearn_loss: 2.688 | retain_loss: 0 | param_change: 5.774e-07\n",
      "unlearn_cosine_sim=0.5859375\n",
      "retain_cosine_sim=0.5546875\n",
      "Topic 0 updated_forget_activations.norm= 19.625\n",
      "Topic 0 frozen_forget_activations.norm= 25.0\n",
      "Topic 0 updated_retain_activations.norm= 22.5\n",
      "Topic 0 frozen_retain_activations.norm= 27.75\n",
      " 86%|███████████████████████████████████▎     | 129/150 [00:31<00:04,  4.42it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 218, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.047 | unlearn_loss: 2.047 | retain_loss: 0 | param_change: 3.912e-07\n",
      "unlearn_cosine_sim=0.53125\n",
      "retain_cosine_sim=0.5625\n",
      "Topic 0 updated_forget_activations.norm= 17.625\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 20.0\n",
      "Topic 0 frozen_retain_activations.norm= 24.875\n",
      " 87%|███████████████████████████████████▌     | 130/150 [00:32<00:04,  4.38it/s]loss: 2.406 | unlearn_loss: 2.406 | retain_loss: 0 | param_change: 3.781e-07\n",
      "unlearn_cosine_sim=0.52734375\n",
      "retain_cosine_sim=0.5859375\n",
      "Topic 0 updated_forget_activations.norm= 18.5\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 20.0\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 87%|███████████████████████████████████▊     | 131/150 [00:32<00:04,  4.42it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 112, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.953 | unlearn_loss: 3.953 | retain_loss: 0 | param_change: 4.359e-07\n",
      "unlearn_cosine_sim=0.52734375\n",
      "retain_cosine_sim=0.56640625\n",
      "Topic 0 updated_forget_activations.norm= 23.625\n",
      "Topic 0 frozen_forget_activations.norm= 29.375\n",
      "Topic 0 updated_retain_activations.norm= 21.125\n",
      "Topic 0 frozen_retain_activations.norm= 26.5\n",
      " 88%|████████████████████████████████████     | 132/150 [00:32<00:03,  4.53it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 329, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.359 | unlearn_loss: 1.359 | retain_loss: 0 | param_change: 3.558e-07\n",
      "unlearn_cosine_sim=0.51953125\n",
      "retain_cosine_sim=0.5859375\n",
      "Topic 0 updated_forget_activations.norm= 15.125\n",
      "Topic 0 frozen_forget_activations.norm= 20.375\n",
      "Topic 0 updated_retain_activations.norm= 21.75\n",
      "Topic 0 frozen_retain_activations.norm= 27.125\n",
      " 89%|████████████████████████████████████▎    | 133/150 [00:32<00:04,  4.23it/s]loss: 2.359 | unlearn_loss: 2.359 | retain_loss: 0 | param_change: 4.359e-07\n",
      "unlearn_cosine_sim=0.53515625\n",
      "retain_cosine_sim=0.50390625\n",
      "Topic 0 updated_forget_activations.norm= 18.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.5\n",
      "Topic 0 updated_retain_activations.norm= 15.875\n",
      "Topic 0 frozen_retain_activations.norm= 21.625\n",
      " 89%|████████████████████████████████████▋    | 134/150 [00:32<00:03,  4.16it/s]loss: 2.219 | unlearn_loss: 2.219 | retain_loss: 0 | param_change: 6.855e-07\n",
      "unlearn_cosine_sim=0.515625\n",
      "retain_cosine_sim=0.546875\n",
      "Topic 0 updated_forget_activations.norm= 18.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.0\n",
      "Topic 0 updated_retain_activations.norm= 23.25\n",
      "Topic 0 frozen_retain_activations.norm= 28.625\n",
      " 90%|████████████████████████████████████▉    | 135/150 [00:33<00:03,  4.26it/s]loss: 2.125 | unlearn_loss: 2.125 | retain_loss: 0 | param_change: 5.215e-07\n",
      "unlearn_cosine_sim=0.49609375\n",
      "retain_cosine_sim=0.51953125\n",
      "Topic 0 updated_forget_activations.norm= 17.625\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 17.5\n",
      "Topic 0 frozen_retain_activations.norm= 23.25\n",
      " 91%|█████████████████████████████████████▏   | 136/150 [00:33<00:03,  4.22it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 224, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.992 | unlearn_loss: 1.992 | retain_loss: 0 | param_change: 3.669e-07\n",
      "unlearn_cosine_sim=0.5390625\n",
      "retain_cosine_sim=0.5625\n",
      "Topic 0 updated_forget_activations.norm= 17.25\n",
      "Topic 0 frozen_forget_activations.norm= 22.125\n",
      "Topic 0 updated_retain_activations.norm= 24.25\n",
      "Topic 0 frozen_retain_activations.norm= 29.75\n",
      " 91%|█████████████████████████████████████▍   | 137/150 [00:33<00:03,  4.29it/s]loss: 2.672 | unlearn_loss: 2.672 | retain_loss: 0 | param_change: 4.042e-07\n",
      "unlearn_cosine_sim=0.53125\n",
      "retain_cosine_sim=0.58203125\n",
      "Topic 0 updated_forget_activations.norm= 19.25\n",
      "Topic 0 frozen_forget_activations.norm= 24.5\n",
      "Topic 0 updated_retain_activations.norm= 15.375\n",
      "Topic 0 frozen_retain_activations.norm= 20.5\n",
      " 92%|█████████████████████████████████████▋   | 138/150 [00:33<00:02,  4.11it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 250, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.781 | unlearn_loss: 1.781 | retain_loss: 0 | param_change: 4.247e-07\n",
      "unlearn_cosine_sim=0.49609375\n",
      "retain_cosine_sim=0.55078125\n",
      "Topic 0 updated_forget_activations.norm= 15.625\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 20.5\n",
      "Topic 0 frozen_retain_activations.norm= 25.875\n",
      " 93%|█████████████████████████████████████▉   | 139/150 [00:34<00:02,  4.10it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 138, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.219 | unlearn_loss: 3.219 | retain_loss: 0 | param_change: 4.396e-07\n",
      "unlearn_cosine_sim=0.51171875\n",
      "retain_cosine_sim=0.55859375\n",
      "Topic 0 updated_forget_activations.norm= 21.25\n",
      "Topic 0 frozen_forget_activations.norm= 26.5\n",
      "Topic 0 updated_retain_activations.norm= 18.25\n",
      "Topic 0 frozen_retain_activations.norm= 23.25\n",
      " 93%|██████████████████████████████████████▎  | 140/150 [00:34<00:02,  4.22it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 216, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.062 | unlearn_loss: 2.062 | retain_loss: 0 | param_change: 3.763e-07\n",
      "unlearn_cosine_sim=0.5078125\n",
      "retain_cosine_sim=0.58203125\n",
      "Topic 0 updated_forget_activations.norm= 17.5\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 19.875\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 94%|██████████████████████████████████████▌  | 141/150 [00:34<00:02,  4.26it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 311, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.453 | unlearn_loss: 1.453 | retain_loss: 0 | param_change: 4.768e-07\n",
      "unlearn_cosine_sim=0.4921875\n",
      "retain_cosine_sim=0.52734375\n",
      "Topic 0 updated_forget_activations.norm= 15.0625\n",
      "Topic 0 frozen_forget_activations.norm= 20.75\n",
      "Topic 0 updated_retain_activations.norm= 19.875\n",
      "Topic 0 frozen_retain_activations.norm= 25.5\n",
      " 95%|██████████████████████████████████████▊  | 142/150 [00:34<00:01,  4.09it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 331, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.352 | unlearn_loss: 1.352 | retain_loss: 0 | param_change: 3.334e-07\n",
      "unlearn_cosine_sim=0.47265625\n",
      "retain_cosine_sim=0.6015625\n",
      "Topic 0 updated_forget_activations.norm= 14.625\n",
      "Topic 0 frozen_forget_activations.norm= 20.25\n",
      "Topic 0 updated_retain_activations.norm= 20.75\n",
      "Topic 0 frozen_retain_activations.norm= 26.25\n",
      " 95%|███████████████████████████████████████  | 143/150 [00:35<00:01,  3.94it/s]loss: 2.156 | unlearn_loss: 2.156 | retain_loss: 0 | param_change: 4.247e-07\n",
      "unlearn_cosine_sim=0.53515625\n",
      "retain_cosine_sim=0.6171875\n",
      "Topic 0 updated_forget_activations.norm= 17.5\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 19.25\n",
      "Topic 0 frozen_retain_activations.norm= 24.5\n",
      " 96%|███████████████████████████████████████▎ | 144/150 [00:35<00:01,  4.04it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 115, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.859 | unlearn_loss: 3.859 | retain_loss: 0 | param_change: 4.563e-07\n",
      "unlearn_cosine_sim=0.55078125\n",
      "retain_cosine_sim=0.57421875\n",
      "Topic 0 updated_forget_activations.norm= 23.25\n",
      "Topic 0 frozen_forget_activations.norm= 29.0\n",
      "Topic 0 updated_retain_activations.norm= 17.25\n",
      "Topic 0 frozen_retain_activations.norm= 22.5\n",
      " 97%|███████████████████████████████████████▋ | 145/150 [00:35<00:01,  4.16it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 171, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.594 | unlearn_loss: 2.594 | retain_loss: 0 | param_change: 3.502e-07\n",
      "unlearn_cosine_sim=0.52734375\n",
      "retain_cosine_sim=0.57421875\n",
      "Topic 0 updated_forget_activations.norm= 19.0\n",
      "Topic 0 frozen_forget_activations.norm= 24.5\n",
      "Topic 0 updated_retain_activations.norm= 19.875\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 97%|███████████████████████████████████████▉ | 146/150 [00:35<00:00,  4.27it/s]loss: 2.25 | unlearn_loss: 2.25 | retain_loss: 0 | param_change: 5.066e-07\n",
      "unlearn_cosine_sim=0.578125\n",
      "retain_cosine_sim=0.5078125\n",
      "Topic 0 updated_forget_activations.norm= 18.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 15.5\n",
      "Topic 0 frozen_retain_activations.norm= 21.125\n",
      " 98%|████████████████████████████████████████▏| 147/150 [00:36<00:00,  4.08it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 147, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.016 | unlearn_loss: 3.016 | retain_loss: 0 | param_change: 3.818e-07\n",
      "unlearn_cosine_sim=0.51953125\n",
      "retain_cosine_sim=0.54296875\n",
      "Topic 0 updated_forget_activations.norm= 20.5\n",
      "Topic 0 frozen_forget_activations.norm= 25.875\n",
      "Topic 0 updated_retain_activations.norm= 18.75\n",
      "Topic 0 frozen_retain_activations.norm= 24.0\n",
      " 99%|████████████████████████████████████████▍| 148/150 [00:36<00:00,  4.21it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 318, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.422 | unlearn_loss: 1.422 | retain_loss: 0 | param_change: 3.856e-07\n",
      "unlearn_cosine_sim=0.515625\n",
      "retain_cosine_sim=0.61328125\n",
      "Topic 0 updated_forget_activations.norm= 14.625\n",
      "Topic 0 frozen_forget_activations.norm= 20.0\n",
      "Topic 0 updated_retain_activations.norm= 19.0\n",
      "Topic 0 frozen_retain_activations.norm= 24.5\n",
      " 99%|████████████████████████████████████████▋| 149/150 [00:36<00:00,  4.04it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 210, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.125 | unlearn_loss: 2.125 | retain_loss: 0 | param_change: 3.632e-07\n",
      "unlearn_cosine_sim=0.5\n",
      "retain_cosine_sim=0.5546875\n",
      "Topic 0 updated_forget_activations.norm= 17.375\n",
      "Topic 0 frozen_forget_activations.norm= 22.5\n",
      "Topic 0 updated_retain_activations.norm= 14.875\n",
      "Topic 0 frozen_retain_activations.norm= 20.25\n",
      "100%|█████████████████████████████████████████| 150/150 [00:36<00:00,  4.06it/s]\n",
      "Saved model to models/alpaca_rmu_alpha_0\n"
     ]
    }
   ],
   "source": [
    "# best\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "\n",
    "!python3 -m rmu.unlearn --model_name PKU-Alignment/alpaca-7b-reproduced --max_num_batches 150 --batch_size=2 --retain_corpora SafeRLHF-corpora/safe_train_sampled --forget_corpora SafeRLHF-corpora/Privacy_Violation_train --layer_id 7 --steering_coeffs 6.5 --alpha 0 --lr 1e-4 --seed 42 --output_dir models/alpaca_rmu_alpha_0 --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [01:39<00:00, 14.16s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [00:12<00:00,  1.74s/it]\n",
      "====rmu Config====\n",
      "model_name_or_path=PKU-Alignment/alpaca-7b-reproduced\n",
      "module_str={model_name}.model.layers[{layer_id}]\n",
      "output_dir=models/alpaca_rmu_alpha_1\n",
      "retain_corpora=['SafeRLHF-corpora/safe_train_sampled']\n",
      "forget_corpora=['SafeRLHF-corpora/Privacy_Violation_train']\n",
      "alpha=[1.0]\n",
      "steering_coeffs=6.5\n",
      "lr=0.0001\n",
      "min_len=0\n",
      "max_len=2000\n",
      "batch_size=2\n",
      "max_num_batches=150\n",
      "layer_id=7\n",
      "layer_ids=[5, 6, 7]\n",
      "param_ids=[6]\n",
      "seed=42\n",
      "verbose=True\n",
      "steering_coeff_list=[6.5]\n",
      "=====\n",
      "/home/hice1/jli928/.conda/envs/model-unlearning/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "======= Epoch 0 =======\n",
      "  0%|                                                   | 0/150 [00:00<?, ?it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 185, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.453 | unlearn_loss: 2.453 | retain_loss: 0 | param_change: 1.982e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.125\n",
      "Topic 0 frozen_forget_activations.norm= 23.125\n",
      "Topic 0 updated_retain_activations.norm= 23.5\n",
      "Topic 0 frozen_retain_activations.norm= 23.5\n",
      "  1%|▎                                          | 1/150 [00:01<03:10,  1.28s/it]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 170, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.672 | unlearn_loss: 2.672 | retain_loss: 8.345e-06 | param_change: 2.101e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.375\n",
      "Topic 0 frozen_forget_activations.norm= 24.5\n",
      "Topic 0 updated_retain_activations.norm= 19.5\n",
      "Topic 0 frozen_retain_activations.norm= 19.5\n",
      "  1%|▌                                          | 2/150 [00:01<01:43,  1.43it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 199, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.297 | unlearn_loss: 2.297 | retain_loss: 2.348e-05 | param_change: 1.9e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.625\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 25.25\n",
      "Topic 0 frozen_retain_activations.norm= 25.5\n",
      "  2%|▊                                          | 3/150 [00:01<01:11,  2.06it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 251, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.836 | unlearn_loss: 1.836 | retain_loss: 3.767e-05 | param_change: 1.855e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.5\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 23.0\n",
      "Topic 0 frozen_retain_activations.norm= 23.0\n",
      "  3%|█▏                                         | 4/150 [00:02<00:57,  2.53it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 190, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.391 | unlearn_loss: 2.391 | retain_loss: 8.059e-05 | param_change: 1.825e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.875\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 23.75\n",
      "Topic 0 frozen_retain_activations.norm= 24.0\n",
      "  3%|█▍                                         | 5/150 [00:02<00:48,  2.99it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 243, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.891 | unlearn_loss: 1.891 | retain_loss: 0.0001149 | param_change: 1.781e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.5\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 24.0\n",
      "Topic 0 frozen_retain_activations.norm= 24.25\n",
      "  4%|█▋                                         | 6/150 [00:02<00:43,  3.28it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 293, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.586 | unlearn_loss: 1.586 | retain_loss: 0.0001545 | param_change: 1.699e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 20.125\n",
      "Topic 0 frozen_forget_activations.norm= 20.625\n",
      "Topic 0 updated_retain_activations.norm= 24.125\n",
      "Topic 0 frozen_retain_activations.norm= 24.5\n",
      "  5%|██                                         | 7/150 [00:02<00:41,  3.41it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 244, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.875 | unlearn_loss: 1.875 | retain_loss: 0.0003166 | param_change: 1.788e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.0\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 24.625\n",
      "Topic 0 frozen_retain_activations.norm= 25.125\n",
      "  5%|██▎                                        | 8/150 [00:03<00:39,  3.59it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 162, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.797 | unlearn_loss: 2.797 | retain_loss: 0.0004616 | param_change: 1.907e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 24.25\n",
      "Topic 0 frozen_forget_activations.norm= 25.125\n",
      "Topic 0 updated_retain_activations.norm= 25.0\n",
      "Topic 0 frozen_retain_activations.norm= 25.625\n",
      "  6%|██▌                                        | 9/150 [00:03<00:36,  3.84it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 219, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.078 | unlearn_loss: 2.078 | retain_loss: 0.0005951 | param_change: 1.594e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 21.625\n",
      "Topic 0 frozen_forget_activations.norm= 22.5\n",
      "Topic 0 updated_retain_activations.norm= 21.5\n",
      "Topic 0 frozen_retain_activations.norm= 22.375\n",
      "  7%|██▊                                       | 10/150 [00:03<00:35,  3.90it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 151, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3 | unlearn_loss: 3 | retain_loss: 0.0007324 | param_change: 1.878e-06\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 24.625\n",
      "Topic 0 frozen_forget_activations.norm= 25.75\n",
      "Topic 0 updated_retain_activations.norm= 24.0\n",
      "Topic 0 frozen_retain_activations.norm= 24.75\n",
      "  7%|███                                       | 11/150 [00:03<00:34,  4.08it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 144, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.125 | unlearn_loss: 3.125 | retain_loss: 0.0008278 | param_change: 1.617e-06\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 24.625\n",
      "Topic 0 frozen_forget_activations.norm= 25.75\n",
      "Topic 0 updated_retain_activations.norm= 35.0\n",
      "Topic 0 frozen_retain_activations.norm= 35.5\n",
      "  8%|███▎                                      | 12/150 [00:03<00:33,  4.08it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 255, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.797 | unlearn_loss: 1.797 | retain_loss: 0.001129 | param_change: 1.512e-06\n",
      "unlearn_cosine_sim=0.98828125\n",
      "retain_cosine_sim=0.9921875\n",
      "Topic 0 updated_forget_activations.norm= 20.25\n",
      "Topic 0 frozen_forget_activations.norm= 21.5\n",
      "Topic 0 updated_retain_activations.norm= 21.375\n",
      "Topic 0 frozen_retain_activations.norm= 22.5\n",
      "  9%|███▋                                      | 13/150 [00:04<00:34,  4.00it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 283, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.641 | unlearn_loss: 1.641 | retain_loss: 0.001595 | param_change: 1.565e-06\n",
      "unlearn_cosine_sim=0.98828125\n",
      "retain_cosine_sim=0.9921875\n",
      "Topic 0 updated_forget_activations.norm= 19.75\n",
      "Topic 0 frozen_forget_activations.norm= 21.125\n",
      "Topic 0 updated_retain_activations.norm= 21.0\n",
      "Topic 0 frozen_retain_activations.norm= 22.25\n",
      "  9%|███▉                                      | 14/150 [00:04<00:35,  3.87it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 141, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.188 | unlearn_loss: 3.188 | retain_loss: 0.001732 | param_change: 1.55e-06\n",
      "unlearn_cosine_sim=0.98828125\n",
      "retain_cosine_sim=0.9921875\n",
      "Topic 0 updated_forget_activations.norm= 24.25\n",
      "Topic 0 frozen_forget_activations.norm= 25.75\n",
      "Topic 0 updated_retain_activations.norm= 24.75\n",
      "Topic 0 frozen_retain_activations.norm= 26.0\n",
      " 10%|████▏                                     | 15/150 [00:04<00:33,  4.07it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 181, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.5 | unlearn_loss: 2.5 | retain_loss: 0.002182 | param_change: 1.557e-06\n",
      "unlearn_cosine_sim=0.984375\n",
      "retain_cosine_sim=0.98828125\n",
      "Topic 0 updated_forget_activations.norm= 22.5\n",
      "Topic 0 frozen_forget_activations.norm= 24.0\n",
      "Topic 0 updated_retain_activations.norm= 21.0\n",
      "Topic 0 frozen_retain_activations.norm= 22.5\n",
      " 11%|████▍                                     | 16/150 [00:04<00:32,  4.13it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 220, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.062 | unlearn_loss: 2.062 | retain_loss: 0.002304 | param_change: 1.423e-06\n",
      "unlearn_cosine_sim=0.984375\n",
      "retain_cosine_sim=0.98828125\n",
      "Topic 0 updated_forget_activations.norm= 20.5\n",
      "Topic 0 frozen_forget_activations.norm= 22.125\n",
      "Topic 0 updated_retain_activations.norm= 21.75\n",
      "Topic 0 frozen_retain_activations.norm= 23.5\n",
      " 11%|████▊                                     | 17/150 [00:05<00:32,  4.15it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 231, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.992 | unlearn_loss: 1.992 | retain_loss: 0.002136 | param_change: 1.371e-06\n",
      "unlearn_cosine_sim=0.98046875\n",
      "retain_cosine_sim=0.98828125\n",
      "Topic 0 updated_forget_activations.norm= 20.25\n",
      "Topic 0 frozen_forget_activations.norm= 21.875\n",
      "Topic 0 updated_retain_activations.norm= 20.875\n",
      "Topic 0 frozen_retain_activations.norm= 22.375\n",
      " 12%|█████                                     | 18/150 [00:05<00:32,  4.10it/s]loss: 3.125 | unlearn_loss: 3.125 | retain_loss: 0.002899 | param_change: 1.55e-06\n",
      "unlearn_cosine_sim=0.97265625\n",
      "retain_cosine_sim=0.984375\n",
      "Topic 0 updated_forget_activations.norm= 24.0\n",
      "Topic 0 frozen_forget_activations.norm= 26.0\n",
      "Topic 0 updated_retain_activations.norm= 23.5\n",
      "Topic 0 frozen_retain_activations.norm= 25.125\n",
      " 13%|█████▎                                    | 19/150 [00:05<00:30,  4.24it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 153, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.953 | unlearn_loss: 2.953 | retain_loss: 0.002396 | param_change: 1.565e-06\n",
      "unlearn_cosine_sim=0.97265625\n",
      "retain_cosine_sim=0.98828125\n",
      "Topic 0 updated_forget_activations.norm= 23.5\n",
      "Topic 0 frozen_forget_activations.norm= 25.5\n",
      "Topic 0 updated_retain_activations.norm= 22.5\n",
      "Topic 0 frozen_retain_activations.norm= 24.25\n",
      " 13%|█████▌                                    | 20/150 [00:05<00:30,  4.31it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 217, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.094 | unlearn_loss: 2.094 | retain_loss: 0.002869 | param_change: 1.55e-06\n",
      "unlearn_cosine_sim=0.97265625\n",
      "retain_cosine_sim=0.984375\n",
      "Topic 0 updated_forget_activations.norm= 20.5\n",
      "Topic 0 frozen_forget_activations.norm= 22.5\n",
      "Topic 0 updated_retain_activations.norm= 22.0\n",
      "Topic 0 frozen_retain_activations.norm= 23.75\n",
      " 14%|█████▉                                    | 21/150 [00:06<00:30,  4.29it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 197, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.297 | unlearn_loss: 2.297 | retain_loss: 0.003433 | param_change: 1.587e-06\n",
      "unlearn_cosine_sim=0.97265625\n",
      "retain_cosine_sim=0.98828125\n",
      "Topic 0 updated_forget_activations.norm= 21.375\n",
      "Topic 0 frozen_forget_activations.norm= 23.5\n",
      "Topic 0 updated_retain_activations.norm= 30.75\n",
      "Topic 0 frozen_retain_activations.norm= 32.75\n",
      " 15%|██████▏                                   | 22/150 [00:06<00:29,  4.37it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 195, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.328 | unlearn_loss: 2.328 | retain_loss: 0.00386 | param_change: 1.505e-06\n",
      "unlearn_cosine_sim=0.96484375\n",
      "retain_cosine_sim=0.9765625\n",
      "Topic 0 updated_forget_activations.norm= 21.25\n",
      "Topic 0 frozen_forget_activations.norm= 23.5\n",
      "Topic 0 updated_retain_activations.norm= 20.5\n",
      "Topic 0 frozen_retain_activations.norm= 22.625\n",
      " 15%|██████▍                                   | 23/150 [00:06<00:29,  4.30it/s]loss: 1.797 | unlearn_loss: 1.789 | retain_loss: 0.004761 | param_change: 1.431e-06\n",
      "unlearn_cosine_sim=0.95703125\n",
      "retain_cosine_sim=0.98046875\n",
      "Topic 0 updated_forget_activations.norm= 19.0\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 31.25\n",
      "Topic 0 frozen_retain_activations.norm= 33.5\n",
      " 16%|██████▋                                   | 24/150 [00:06<00:29,  4.28it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 201, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.25 | unlearn_loss: 2.25 | retain_loss: 0.006134 | param_change: 1.632e-06\n",
      "unlearn_cosine_sim=0.95703125\n",
      "retain_cosine_sim=0.9609375\n",
      "Topic 0 updated_forget_activations.norm= 20.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 21.25\n",
      "Topic 0 frozen_retain_activations.norm= 23.75\n",
      " 17%|███████                                   | 25/150 [00:07<00:29,  4.27it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 252, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.812 | unlearn_loss: 1.805 | retain_loss: 0.004089 | param_change: 1.416e-06\n",
      "unlearn_cosine_sim=0.95703125\n",
      "retain_cosine_sim=0.98046875\n",
      "Topic 0 updated_forget_activations.norm= 19.25\n",
      "Topic 0 frozen_forget_activations.norm= 21.5\n",
      "Topic 0 updated_retain_activations.norm= 25.375\n",
      "Topic 0 frozen_retain_activations.norm= 27.625\n",
      " 17%|███████▎                                  | 26/150 [00:07<00:29,  4.24it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 205, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.203 | unlearn_loss: 2.203 | retain_loss: 0.004791 | param_change: 1.565e-06\n",
      "unlearn_cosine_sim=0.9453125\n",
      "retain_cosine_sim=0.98046875\n",
      "Topic 0 updated_forget_activations.norm= 20.5\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 32.75\n",
      "Topic 0 frozen_retain_activations.norm= 35.0\n",
      " 18%|███████▌                                  | 27/150 [00:07<00:28,  4.34it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 187, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.422 | unlearn_loss: 2.422 | retain_loss: 0.00415 | param_change: 1.445e-06\n",
      "unlearn_cosine_sim=0.94140625\n",
      "retain_cosine_sim=0.98046875\n",
      "Topic 0 updated_forget_activations.norm= 21.125\n",
      "Topic 0 frozen_forget_activations.norm= 24.0\n",
      "Topic 0 updated_retain_activations.norm= 20.75\n",
      "Topic 0 frozen_retain_activations.norm= 23.0\n",
      " 19%|███████▊                                  | 28/150 [00:07<00:28,  4.31it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 176, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.562 | unlearn_loss: 2.562 | retain_loss: 0.00473 | param_change: 1.431e-06\n",
      "unlearn_cosine_sim=0.9453125\n",
      "retain_cosine_sim=0.97265625\n",
      "Topic 0 updated_forget_activations.norm= 21.5\n",
      "Topic 0 frozen_forget_activations.norm= 24.25\n",
      "Topic 0 updated_retain_activations.norm= 20.25\n",
      "Topic 0 frozen_retain_activations.norm= 22.5\n",
      " 19%|████████                                  | 29/150 [00:07<00:28,  4.29it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 84, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 5.25 | unlearn_loss: 5.25 | retain_loss: 0.00528 | param_change: 2.012e-06\n",
      "unlearn_cosine_sim=0.98046875\n",
      "retain_cosine_sim=0.96875\n",
      "Topic 0 updated_forget_activations.norm= 30.625\n",
      "Topic 0 frozen_forget_activations.norm= 32.75\n",
      "Topic 0 updated_retain_activations.norm= 19.5\n",
      "Topic 0 frozen_retain_activations.norm= 22.0\n",
      " 20%|████████▍                                 | 30/150 [00:08<00:27,  4.33it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 198, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.281 | unlearn_loss: 2.281 | retain_loss: 0.005249 | param_change: 1.445e-06\n",
      "unlearn_cosine_sim=0.953125\n",
      "retain_cosine_sim=0.96875\n",
      "Topic 0 updated_forget_activations.norm= 20.25\n",
      "Topic 0 frozen_forget_activations.norm= 23.0\n",
      "Topic 0 updated_retain_activations.norm= 21.5\n",
      "Topic 0 frozen_retain_activations.norm= 24.0\n",
      " 21%|████████▋                                 | 31/150 [00:08<00:27,  4.33it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 212, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.125 | unlearn_loss: 2.125 | retain_loss: 0.006165 | param_change: 1.386e-06\n",
      "unlearn_cosine_sim=0.94140625\n",
      "retain_cosine_sim=0.9609375\n",
      "Topic 0 updated_forget_activations.norm= 19.625\n",
      "Topic 0 frozen_forget_activations.norm= 22.5\n",
      "Topic 0 updated_retain_activations.norm= 18.75\n",
      "Topic 0 frozen_retain_activations.norm= 21.375\n",
      " 21%|████████▉                                 | 32/150 [00:08<00:28,  4.17it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 242, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.883 | unlearn_loss: 1.875 | retain_loss: 0.004608 | param_change: 1.349e-06\n",
      "unlearn_cosine_sim=0.9453125\n",
      "retain_cosine_sim=0.9765625\n",
      "Topic 0 updated_forget_activations.norm= 19.25\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 24.75\n",
      "Topic 0 frozen_retain_activations.norm= 27.125\n",
      " 22%|█████████▏                                | 33/150 [00:08<00:28,  4.16it/s]loss: 2.203 | unlearn_loss: 2.203 | retain_loss: 0.004761 | param_change: 1.304e-06\n",
      "unlearn_cosine_sim=0.953125\n",
      "retain_cosine_sim=0.9765625\n",
      "Topic 0 updated_forget_activations.norm= 20.0\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 23.25\n",
      "Topic 0 frozen_retain_activations.norm= 25.75\n",
      " 23%|█████████▌                                | 34/150 [00:09<00:27,  4.21it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 175, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.578 | unlearn_loss: 2.578 | retain_loss: 0.005402 | param_change: 1.416e-06\n",
      "unlearn_cosine_sim=0.9375\n",
      "retain_cosine_sim=0.96484375\n",
      "Topic 0 updated_forget_activations.norm= 21.125\n",
      "Topic 0 frozen_forget_activations.norm= 24.375\n",
      "Topic 0 updated_retain_activations.norm= 16.875\n",
      "Topic 0 frozen_retain_activations.norm= 19.5\n",
      " 23%|█████████▊                                | 35/150 [00:09<00:29,  3.96it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 182, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.484 | unlearn_loss: 2.484 | retain_loss: 0.004608 | param_change: 1.237e-06\n",
      "unlearn_cosine_sim=0.9375\n",
      "retain_cosine_sim=0.9765625\n",
      "Topic 0 updated_forget_activations.norm= 20.75\n",
      "Topic 0 frozen_forget_activations.norm= 24.0\n",
      "Topic 0 updated_retain_activations.norm= 21.25\n",
      "Topic 0 frozen_retain_activations.norm= 23.75\n",
      " 24%|██████████                                | 36/150 [00:09<00:27,  4.09it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 172, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.609 | unlearn_loss: 2.609 | retain_loss: 0.006073 | param_change: 1.431e-06\n",
      "unlearn_cosine_sim=0.9375\n",
      "retain_cosine_sim=0.96484375\n",
      "Topic 0 updated_forget_activations.norm= 21.125\n",
      "Topic 0 frozen_forget_activations.norm= 24.25\n",
      "Topic 0 updated_retain_activations.norm= 23.25\n",
      "Topic 0 frozen_retain_activations.norm= 26.0\n",
      " 25%|██████████▎                               | 37/150 [00:09<00:26,  4.22it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 189, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.391 | unlearn_loss: 2.391 | retain_loss: 0.005005 | param_change: 1.356e-06\n",
      "unlearn_cosine_sim=0.95703125\n",
      "retain_cosine_sim=0.97265625\n",
      "Topic 0 updated_forget_activations.norm= 20.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.5\n",
      "Topic 0 updated_retain_activations.norm= 22.25\n",
      "Topic 0 frozen_retain_activations.norm= 24.75\n",
      " 25%|██████████▋                               | 38/150 [00:10<00:26,  4.29it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 225, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.031 | unlearn_loss: 2.031 | retain_loss: 0.006744 | param_change: 1.594e-06\n",
      "unlearn_cosine_sim=0.95703125\n",
      "retain_cosine_sim=0.96484375\n",
      "Topic 0 updated_forget_activations.norm= 19.25\n",
      "Topic 0 frozen_forget_activations.norm= 22.125\n",
      "Topic 0 updated_retain_activations.norm= 23.125\n",
      "Topic 0 frozen_retain_activations.norm= 26.0\n",
      " 26%|██████████▉                               | 39/150 [00:10<00:25,  4.28it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 113, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.953 | unlearn_loss: 3.953 | retain_loss: 0.005066 | param_change: 1.296e-06\n",
      "unlearn_cosine_sim=0.9609375\n",
      "retain_cosine_sim=0.97265625\n",
      "Topic 0 updated_forget_activations.norm= 25.5\n",
      "Topic 0 frozen_forget_activations.norm= 28.25\n",
      "Topic 0 updated_retain_activations.norm= 22.875\n",
      "Topic 0 frozen_retain_activations.norm= 25.5\n",
      " 27%|███████████▏                              | 40/150 [00:10<00:24,  4.41it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 119, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.781 | unlearn_loss: 3.766 | retain_loss: 0.008301 | param_change: 1.721e-06\n",
      "unlearn_cosine_sim=0.9609375\n",
      "retain_cosine_sim=0.94921875\n",
      "Topic 0 updated_forget_activations.norm= 25.25\n",
      "Topic 0 frozen_forget_activations.norm= 28.25\n",
      "Topic 0 updated_retain_activations.norm= 22.25\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 27%|███████████▍                              | 41/150 [00:10<00:24,  4.50it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 174, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.578 | unlearn_loss: 2.578 | retain_loss: 0.003372 | param_change: 1.2e-06\n",
      "unlearn_cosine_sim=0.953125\n",
      "retain_cosine_sim=0.98046875\n",
      "Topic 0 updated_forget_activations.norm= 21.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 18.0\n",
      "Topic 0 frozen_retain_activations.norm= 20.0\n",
      " 28%|███████████▊                              | 42/150 [00:11<00:25,  4.17it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 248, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.836 | unlearn_loss: 1.828 | retain_loss: 0.004089 | param_change: 1.356e-06\n",
      "unlearn_cosine_sim=0.94921875\n",
      "retain_cosine_sim=0.98046875\n",
      "Topic 0 updated_forget_activations.norm= 18.75\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 24.5\n",
      "Topic 0 frozen_retain_activations.norm= 26.875\n",
      " 29%|████████████                              | 43/150 [00:11<00:25,  4.15it/s]loss: 1.789 | unlearn_loss: 1.781 | retain_loss: 0.006012 | param_change: 1.207e-06\n",
      "unlearn_cosine_sim=0.94140625\n",
      "retain_cosine_sim=0.96484375\n",
      "Topic 0 updated_forget_activations.norm= 18.25\n",
      "Topic 0 frozen_forget_activations.norm= 21.5\n",
      "Topic 0 updated_retain_activations.norm= 19.875\n",
      "Topic 0 frozen_retain_activations.norm= 22.625\n",
      " 29%|████████████▎                             | 44/150 [00:11<00:26,  4.04it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 164, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.734 | unlearn_loss: 2.734 | retain_loss: 0.005371 | param_change: 1.259e-06\n",
      "unlearn_cosine_sim=0.9296875\n",
      "retain_cosine_sim=0.97265625\n",
      "Topic 0 updated_forget_activations.norm= 21.25\n",
      "Topic 0 frozen_forget_activations.norm= 24.75\n",
      "Topic 0 updated_retain_activations.norm= 22.5\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 30%|████████████▌                             | 45/150 [00:11<00:25,  4.19it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 339, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.359 | unlearn_loss: 1.352 | retain_loss: 0.005829 | param_change: 1.244e-06\n",
      "unlearn_cosine_sim=0.94921875\n",
      "retain_cosine_sim=0.96875\n",
      "Topic 0 updated_forget_activations.norm= 17.125\n",
      "Topic 0 frozen_forget_activations.norm= 20.125\n",
      "Topic 0 updated_retain_activations.norm= 18.75\n",
      "Topic 0 frozen_retain_activations.norm= 21.75\n",
      " 31%|████████████▉                             | 46/150 [00:12<00:29,  3.54it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 177, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.547 | unlearn_loss: 2.547 | retain_loss: 0.005188 | param_change: 1.267e-06\n",
      "unlearn_cosine_sim=0.9453125\n",
      "retain_cosine_sim=0.96875\n",
      "Topic 0 updated_forget_activations.norm= 20.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.875\n",
      "Topic 0 updated_retain_activations.norm= 18.75\n",
      "Topic 0 frozen_retain_activations.norm= 21.375\n",
      " 31%|█████████████▏                            | 47/150 [00:12<00:28,  3.66it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 206, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.188 | unlearn_loss: 2.188 | retain_loss: 0.007812 | param_change: 1.468e-06\n",
      "unlearn_cosine_sim=0.94921875\n",
      "retain_cosine_sim=0.9609375\n",
      "Topic 0 updated_forget_activations.norm= 19.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.0\n",
      "Topic 0 updated_retain_activations.norm= 27.5\n",
      "Topic 0 frozen_retain_activations.norm= 30.75\n",
      " 32%|█████████████▍                            | 48/150 [00:12<00:26,  3.89it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 156, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.875 | unlearn_loss: 2.875 | retain_loss: 0.00531 | param_change: 1.319e-06\n",
      "unlearn_cosine_sim=0.921875\n",
      "retain_cosine_sim=0.97265625\n",
      "Topic 0 updated_forget_activations.norm= 22.0\n",
      "Topic 0 frozen_forget_activations.norm= 25.625\n",
      "Topic 0 updated_retain_activations.norm= 22.5\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 33%|█████████████▋                            | 49/150 [00:12<00:24,  4.07it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 111, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 4.031 | unlearn_loss: 4.031 | retain_loss: 0.007324 | param_change: 1.58e-06\n",
      "unlearn_cosine_sim=0.96484375\n",
      "retain_cosine_sim=0.96875\n",
      "Topic 0 updated_forget_activations.norm= 25.75\n",
      "Topic 0 frozen_forget_activations.norm= 28.75\n",
      "Topic 0 updated_retain_activations.norm= 31.75\n",
      "Topic 0 frozen_retain_activations.norm= 35.0\n",
      " 33%|██████████████                            | 50/150 [00:13<00:23,  4.19it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 209, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.156 | unlearn_loss: 2.156 | retain_loss: 0.005066 | param_change: 1.356e-06\n",
      "unlearn_cosine_sim=0.93359375\n",
      "retain_cosine_sim=0.98046875\n",
      "Topic 0 updated_forget_activations.norm= 19.375\n",
      "Topic 0 frozen_forget_activations.norm= 22.875\n",
      "Topic 0 updated_retain_activations.norm= 28.625\n",
      "Topic 0 frozen_retain_activations.norm= 31.25\n",
      " 34%|██████████████▎                           | 51/150 [00:13<00:23,  4.28it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 240, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.914 | unlearn_loss: 1.906 | retain_loss: 0.004547 | param_change: 1.311e-06\n",
      "unlearn_cosine_sim=0.93359375\n",
      "retain_cosine_sim=0.9765625\n",
      "Topic 0 updated_forget_activations.norm= 18.5\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 19.0\n",
      "Topic 0 frozen_retain_activations.norm= 21.75\n",
      " 35%|██████████████▌                           | 52/150 [00:13<00:23,  4.15it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 79, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 5.562 | unlearn_loss: 5.562 | retain_loss: 0.004822 | param_change: 1.363e-06\n",
      "unlearn_cosine_sim=0.94921875\n",
      "retain_cosine_sim=0.98046875\n",
      "Topic 0 updated_forget_activations.norm= 30.5\n",
      "Topic 0 frozen_forget_activations.norm= 34.0\n",
      "Topic 0 updated_retain_activations.norm= 26.875\n",
      "Topic 0 frozen_retain_activations.norm= 29.5\n",
      " 35%|██████████████▊                           | 53/150 [00:13<00:22,  4.38it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 264, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.742 | unlearn_loss: 1.734 | retain_loss: 0.007172 | param_change: 1.401e-06\n",
      "unlearn_cosine_sim=0.94140625\n",
      "retain_cosine_sim=0.95703125\n",
      "Topic 0 updated_forget_activations.norm= 18.25\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 19.0\n",
      "Topic 0 frozen_retain_activations.norm= 22.0\n",
      " 36%|███████████████                           | 54/150 [00:14<00:23,  4.10it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 226, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.016 | unlearn_loss: 2.016 | retain_loss: 0.005646 | param_change: 1.095e-06\n",
      "unlearn_cosine_sim=0.90625\n",
      "retain_cosine_sim=0.97265625\n",
      "Topic 0 updated_forget_activations.norm= 18.5\n",
      "Topic 0 frozen_forget_activations.norm= 22.25\n",
      "Topic 0 updated_retain_activations.norm= 24.0\n",
      "Topic 0 frozen_retain_activations.norm= 26.875\n",
      " 37%|███████████████▍                          | 55/150 [00:14<00:22,  4.15it/s]loss: 2.375 | unlearn_loss: 2.375 | retain_loss: 0.005463 | param_change: 1.244e-06\n",
      "unlearn_cosine_sim=0.92578125\n",
      "retain_cosine_sim=0.97265625\n",
      "Topic 0 updated_forget_activations.norm= 19.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 23.5\n",
      "Topic 0 frozen_retain_activations.norm= 26.25\n",
      " 37%|███████████████▋                          | 56/150 [00:14<00:22,  4.24it/s]loss: 2.469 | unlearn_loss: 2.469 | retain_loss: 0.007477 | param_change: 1.587e-06\n",
      "unlearn_cosine_sim=0.94140625\n",
      "retain_cosine_sim=0.95703125\n",
      "Topic 0 updated_forget_activations.norm= 20.125\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 19.5\n",
      "Topic 0 frozen_retain_activations.norm= 22.75\n",
      " 38%|███████████████▉                          | 57/150 [00:14<00:21,  4.24it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 150, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3 | unlearn_loss: 2.984 | retain_loss: 0.009583 | param_change: 1.617e-06\n",
      "unlearn_cosine_sim=0.9375\n",
      "retain_cosine_sim=0.94140625\n",
      "Topic 0 updated_forget_activations.norm= 21.875\n",
      "Topic 0 frozen_forget_activations.norm= 25.25\n",
      "Topic 0 updated_retain_activations.norm= 20.625\n",
      "Topic 0 frozen_retain_activations.norm= 24.25\n",
      " 39%|████████████████▏                         | 58/150 [00:14<00:21,  4.32it/s]loss: 2.188 | unlearn_loss: 2.188 | retain_loss: 0.006012 | param_change: 1.259e-06\n",
      "unlearn_cosine_sim=0.91015625\n",
      "retain_cosine_sim=0.96875\n",
      "Topic 0 updated_forget_activations.norm= 19.25\n",
      "Topic 0 frozen_forget_activations.norm= 23.0\n",
      "Topic 0 updated_retain_activations.norm= 23.0\n",
      "Topic 0 frozen_retain_activations.norm= 26.0\n",
      " 39%|████████████████▌                         | 59/150 [00:15<00:21,  4.33it/s]loss: 2.078 | unlearn_loss: 2.078 | retain_loss: 0.005859 | param_change: 1.229e-06\n",
      "unlearn_cosine_sim=0.9453125\n",
      "retain_cosine_sim=0.97265625\n",
      "Topic 0 updated_forget_activations.norm= 18.75\n",
      "Topic 0 frozen_forget_activations.norm= 22.125\n",
      "Topic 0 updated_retain_activations.norm= 21.625\n",
      "Topic 0 frozen_retain_activations.norm= 24.75\n",
      " 40%|████████████████▊                         | 60/150 [00:15<00:20,  4.31it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 135, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.312 | unlearn_loss: 3.312 | retain_loss: 0.004944 | param_change: 1.222e-06\n",
      "unlearn_cosine_sim=0.9375\n",
      "retain_cosine_sim=0.9765625\n",
      "Topic 0 updated_forget_activations.norm= 22.875\n",
      "Topic 0 frozen_forget_activations.norm= 26.5\n",
      "Topic 0 updated_retain_activations.norm= 25.0\n",
      "Topic 0 frozen_retain_activations.norm= 27.75\n",
      " 41%|█████████████████                         | 61/150 [00:15<00:20,  4.44it/s]loss: 2.484 | unlearn_loss: 2.484 | retain_loss: 0.005859 | param_change: 1.371e-06\n",
      "unlearn_cosine_sim=0.9375\n",
      "retain_cosine_sim=0.96875\n",
      "Topic 0 updated_forget_activations.norm= 20.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.5\n",
      "Topic 0 updated_retain_activations.norm= 21.0\n",
      "Topic 0 frozen_retain_activations.norm= 24.0\n",
      " 41%|█████████████████▎                        | 62/150 [00:15<00:19,  4.44it/s]loss: 1.906 | unlearn_loss: 1.898 | retain_loss: 0.005798 | param_change: 1.103e-06\n",
      "unlearn_cosine_sim=0.87109375\n",
      "retain_cosine_sim=0.96875\n",
      "Topic 0 updated_forget_activations.norm= 18.0\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 19.75\n",
      "Topic 0 frozen_retain_activations.norm= 22.5\n",
      " 42%|█████████████████▋                        | 63/150 [00:16<00:20,  4.28it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 102, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 4.375 | unlearn_loss: 4.375 | retain_loss: 0.005768 | param_change: 1.542e-06\n",
      "unlearn_cosine_sim=0.94140625\n",
      "retain_cosine_sim=0.96875\n",
      "Topic 0 updated_forget_activations.norm= 26.75\n",
      "Topic 0 frozen_forget_activations.norm= 30.25\n",
      "Topic 0 updated_retain_activations.norm= 20.5\n",
      "Topic 0 frozen_retain_activations.norm= 23.375\n",
      " 43%|█████████████████▉                        | 64/150 [00:16<00:19,  4.35it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 180, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.484 | unlearn_loss: 2.484 | retain_loss: 0.006775 | param_change: 1.229e-06\n",
      "unlearn_cosine_sim=0.890625\n",
      "retain_cosine_sim=0.96484375\n",
      "Topic 0 updated_forget_activations.norm= 19.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 22.25\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 43%|██████████████████▏                       | 65/150 [00:16<00:19,  4.40it/s]loss: 2.766 | unlearn_loss: 2.766 | retain_loss: 0.005859 | param_change: 1.17e-06\n",
      "unlearn_cosine_sim=0.92578125\n",
      "retain_cosine_sim=0.97265625\n",
      "Topic 0 updated_forget_activations.norm= 21.0\n",
      "Topic 0 frozen_forget_activations.norm= 24.75\n",
      "Topic 0 updated_retain_activations.norm= 23.0\n",
      "Topic 0 frozen_retain_activations.norm= 25.875\n",
      " 44%|██████████████████▍                       | 66/150 [00:16<00:18,  4.46it/s]loss: 1.812 | unlearn_loss: 1.805 | retain_loss: 0.006348 | param_change: 1.58e-06\n",
      "unlearn_cosine_sim=0.953125\n",
      "retain_cosine_sim=0.96484375\n",
      "Topic 0 updated_forget_activations.norm= 18.75\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 19.625\n",
      "Topic 0 frozen_retain_activations.norm= 22.75\n",
      " 45%|██████████████████▊                       | 67/150 [00:17<00:19,  4.25it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 146, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.062 | unlearn_loss: 3.062 | retain_loss: 0.006287 | param_change: 1.296e-06\n",
      "unlearn_cosine_sim=0.8828125\n",
      "retain_cosine_sim=0.9609375\n",
      "Topic 0 updated_forget_activations.norm= 21.5\n",
      "Topic 0 frozen_forget_activations.norm= 25.75\n",
      "Topic 0 updated_retain_activations.norm= 17.5\n",
      "Topic 0 frozen_retain_activations.norm= 20.375\n",
      " 45%|███████████████████                       | 68/150 [00:17<00:21,  3.89it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 184, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.438 | unlearn_loss: 2.438 | retain_loss: 0.005737 | param_change: 1.52e-06\n",
      "unlearn_cosine_sim=0.9140625\n",
      "retain_cosine_sim=0.97265625\n",
      "Topic 0 updated_forget_activations.norm= 20.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 23.5\n",
      "Topic 0 frozen_retain_activations.norm= 26.375\n",
      " 46%|███████████████████▎                      | 69/150 [00:17<00:19,  4.06it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 281, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.656 | unlearn_loss: 1.648 | retain_loss: 0.008118 | param_change: 1.319e-06\n",
      "unlearn_cosine_sim=0.9140625\n",
      "retain_cosine_sim=0.953125\n",
      "Topic 0 updated_forget_activations.norm= 17.5\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 21.75\n",
      "Topic 0 frozen_retain_activations.norm= 25.125\n",
      " 47%|███████████████████▌                      | 70/150 [00:17<00:20,  3.98it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 223, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.016 | unlearn_loss: 2.016 | retain_loss: 0.007385 | param_change: 1.386e-06\n",
      "unlearn_cosine_sim=0.9140625\n",
      "retain_cosine_sim=0.9609375\n",
      "Topic 0 updated_forget_activations.norm= 18.5\n",
      "Topic 0 frozen_forget_activations.norm= 22.375\n",
      "Topic 0 updated_retain_activations.norm= 20.75\n",
      "Topic 0 frozen_retain_activations.norm= 24.0\n",
      " 47%|███████████████████▉                      | 71/150 [00:18<00:19,  4.04it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 158, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.844 | unlearn_loss: 2.828 | retain_loss: 0.009338 | param_change: 1.453e-06\n",
      "unlearn_cosine_sim=0.86328125\n",
      "retain_cosine_sim=0.9375\n",
      "Topic 0 updated_forget_activations.norm= 20.75\n",
      "Topic 0 frozen_forget_activations.norm= 25.25\n",
      "Topic 0 updated_retain_activations.norm= 17.5\n",
      "Topic 0 frozen_retain_activations.norm= 21.0\n",
      " 48%|████████████████████▏                     | 72/150 [00:18<00:19,  3.95it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 228, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2 | unlearn_loss: 1.992 | retain_loss: 0.01044 | param_change: 1.661e-06\n",
      "unlearn_cosine_sim=0.9140625\n",
      "retain_cosine_sim=0.94140625\n",
      "Topic 0 updated_forget_activations.norm= 18.25\n",
      "Topic 0 frozen_forget_activations.norm= 22.25\n",
      "Topic 0 updated_retain_activations.norm= 22.5\n",
      "Topic 0 frozen_retain_activations.norm= 26.25\n",
      " 49%|████████████████████▍                     | 73/150 [00:18<00:19,  4.03it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 324, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.43 | unlearn_loss: 1.422 | retain_loss: 0.00885 | param_change: 1.296e-06\n",
      "unlearn_cosine_sim=0.8828125\n",
      "retain_cosine_sim=0.953125\n",
      "Topic 0 updated_forget_activations.norm= 16.5\n",
      "Topic 0 frozen_forget_activations.norm= 20.75\n",
      "Topic 0 updated_retain_activations.norm= 26.75\n",
      "Topic 0 frozen_retain_activations.norm= 30.25\n",
      " 49%|████████████████████▋                     | 74/150 [00:18<00:19,  3.94it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 163, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.75 | unlearn_loss: 2.75 | retain_loss: 0.005798 | param_change: 1.386e-06\n",
      "unlearn_cosine_sim=0.92578125\n",
      "retain_cosine_sim=0.97265625\n",
      "Topic 0 updated_forget_activations.norm= 21.0\n",
      "Topic 0 frozen_forget_activations.norm= 24.75\n",
      "Topic 0 updated_retain_activations.norm= 21.25\n",
      "Topic 0 frozen_retain_activations.norm= 24.25\n",
      " 50%|█████████████████████                     | 75/150 [00:19<00:18,  4.09it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 265, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.727 | unlearn_loss: 1.719 | retain_loss: 0.006714 | param_change: 1.118e-06\n",
      "unlearn_cosine_sim=0.890625\n",
      "retain_cosine_sim=0.9609375\n",
      "Topic 0 updated_forget_activations.norm= 17.25\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 17.875\n",
      "Topic 0 frozen_retain_activations.norm= 21.0\n",
      " 51%|█████████████████████▎                    | 76/150 [00:19<00:19,  3.80it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 207, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.188 | unlearn_loss: 2.172 | retain_loss: 0.008484 | param_change: 1.326e-06\n",
      "unlearn_cosine_sim=0.90234375\n",
      "retain_cosine_sim=0.94921875\n",
      "Topic 0 updated_forget_activations.norm= 19.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.0\n",
      "Topic 0 updated_retain_activations.norm= 18.125\n",
      "Topic 0 frozen_retain_activations.norm= 21.75\n",
      " 51%|█████████████████████▌                    | 77/150 [00:19<00:18,  3.85it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 179, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.5 | unlearn_loss: 2.5 | retain_loss: 0.006592 | param_change: 1.192e-06\n",
      "unlearn_cosine_sim=0.91015625\n",
      "retain_cosine_sim=0.96484375\n",
      "Topic 0 updated_forget_activations.norm= 19.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.625\n",
      "Topic 0 updated_retain_activations.norm= 20.0\n",
      "Topic 0 frozen_retain_activations.norm= 23.125\n",
      " 52%|█████████████████████▊                    | 78/150 [00:19<00:18,  3.97it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 152, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.953 | unlearn_loss: 2.938 | retain_loss: 0.01367 | param_change: 1.639e-06\n",
      "unlearn_cosine_sim=0.91015625\n",
      "retain_cosine_sim=0.91015625\n",
      "Topic 0 updated_forget_activations.norm= 21.5\n",
      "Topic 0 frozen_forget_activations.norm= 25.875\n",
      "Topic 0 updated_retain_activations.norm= 19.125\n",
      "Topic 0 frozen_retain_activations.norm= 23.25\n",
      " 53%|██████████████████████                    | 79/150 [00:20<00:17,  4.07it/s]loss: 2.422 | unlearn_loss: 2.422 | retain_loss: 0.005371 | param_change: 1.11e-06\n",
      "unlearn_cosine_sim=0.83203125\n",
      "retain_cosine_sim=0.97265625\n",
      "Topic 0 updated_forget_activations.norm= 19.625\n",
      "Topic 0 frozen_forget_activations.norm= 24.25\n",
      "Topic 0 updated_retain_activations.norm= 18.875\n",
      "Topic 0 frozen_retain_activations.norm= 21.625\n",
      " 53%|██████████████████████▍                   | 80/150 [00:20<00:17,  3.97it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 188, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.391 | unlearn_loss: 2.391 | retain_loss: 0.007416 | param_change: 1.393e-06\n",
      "unlearn_cosine_sim=0.8984375\n",
      "retain_cosine_sim=0.953125\n",
      "Topic 0 updated_forget_activations.norm= 19.5\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 17.0\n",
      "Topic 0 frozen_retain_activations.norm= 20.125\n",
      " 54%|██████████████████████▋                   | 81/150 [00:20<00:18,  3.70it/s]loss: 2.875 | unlearn_loss: 2.875 | retain_loss: 0.0065 | param_change: 1.371e-06\n",
      "unlearn_cosine_sim=0.8828125\n",
      "retain_cosine_sim=0.96875\n",
      "Topic 0 updated_forget_activations.norm= 21.25\n",
      "Topic 0 frozen_forget_activations.norm= 25.5\n",
      "Topic 0 updated_retain_activations.norm= 24.5\n",
      "Topic 0 frozen_retain_activations.norm= 27.625\n",
      " 55%|██████████████████████▉                   | 82/150 [00:20<00:17,  3.96it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 192, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.344 | unlearn_loss: 2.328 | retain_loss: 0.01117 | param_change: 1.52e-06\n",
      "unlearn_cosine_sim=0.83203125\n",
      "retain_cosine_sim=0.93359375\n",
      "Topic 0 updated_forget_activations.norm= 19.125\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 21.25\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 55%|███████████████████████▏                  | 83/150 [00:21<00:16,  4.10it/s]loss: 2.016 | unlearn_loss: 2 | retain_loss: 0.01172 | param_change: 1.505e-06\n",
      "unlearn_cosine_sim=0.87890625\n",
      "retain_cosine_sim=0.92578125\n",
      "Topic 0 updated_forget_activations.norm= 17.75\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 21.75\n",
      "Topic 0 frozen_retain_activations.norm= 25.75\n",
      " 56%|███████████████████████▌                  | 84/150 [00:21<00:15,  4.14it/s]loss: 3.062 | unlearn_loss: 3.062 | retain_loss: 0.006653 | param_change: 1.445e-06\n",
      "unlearn_cosine_sim=0.90625\n",
      "retain_cosine_sim=0.96484375\n",
      "Topic 0 updated_forget_activations.norm= 21.75\n",
      "Topic 0 frozen_forget_activations.norm= 25.875\n",
      "Topic 0 updated_retain_activations.norm= 20.5\n",
      "Topic 0 frozen_retain_activations.norm= 23.75\n",
      " 57%|███████████████████████▊                  | 85/150 [00:21<00:15,  4.25it/s]loss: 2.062 | unlearn_loss: 2.062 | retain_loss: 0.007202 | param_change: 1.058e-06\n",
      "unlearn_cosine_sim=0.84765625\n",
      "retain_cosine_sim=0.9609375\n",
      "Topic 0 updated_forget_activations.norm= 18.0\n",
      "Topic 0 frozen_forget_activations.norm= 22.5\n",
      "Topic 0 updated_retain_activations.norm= 21.75\n",
      "Topic 0 frozen_retain_activations.norm= 24.875\n",
      " 57%|████████████████████████                  | 86/150 [00:21<00:15,  4.27it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 166, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.703 | unlearn_loss: 2.688 | retain_loss: 0.008423 | param_change: 1.214e-06\n",
      "unlearn_cosine_sim=0.8671875\n",
      "retain_cosine_sim=0.953125\n",
      "Topic 0 updated_forget_activations.norm= 20.0\n",
      "Topic 0 frozen_forget_activations.norm= 24.5\n",
      "Topic 0 updated_retain_activations.norm= 20.75\n",
      "Topic 0 frozen_retain_activations.norm= 24.125\n",
      " 58%|████████████████████████▎                 | 87/150 [00:22<00:14,  4.34it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 215, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.109 | unlearn_loss: 2.094 | retain_loss: 0.008301 | param_change: 1.453e-06\n",
      "unlearn_cosine_sim=0.90234375\n",
      "retain_cosine_sim=0.953125\n",
      "Topic 0 updated_forget_activations.norm= 18.625\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 21.75\n",
      "Topic 0 frozen_retain_activations.norm= 25.125\n",
      " 59%|████████████████████████▋                 | 88/150 [00:22<00:14,  4.33it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 169, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.641 | unlearn_loss: 2.641 | retain_loss: 0.006775 | param_change: 1.289e-06\n",
      "unlearn_cosine_sim=0.8984375\n",
      "retain_cosine_sim=0.9609375\n",
      "Topic 0 updated_forget_activations.norm= 20.0\n",
      "Topic 0 frozen_forget_activations.norm= 24.375\n",
      "Topic 0 updated_retain_activations.norm= 19.0\n",
      "Topic 0 frozen_retain_activations.norm= 22.25\n",
      " 59%|████████████████████████▉                 | 89/150 [00:22<00:14,  4.31it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 129, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.484 | unlearn_loss: 3.469 | retain_loss: 0.008301 | param_change: 1.46e-06\n",
      "unlearn_cosine_sim=0.890625\n",
      "retain_cosine_sim=0.95703125\n",
      "Topic 0 updated_forget_activations.norm= 23.625\n",
      "Topic 0 frozen_forget_activations.norm= 27.75\n",
      "Topic 0 updated_retain_activations.norm= 23.5\n",
      "Topic 0 frozen_retain_activations.norm= 27.0\n",
      " 60%|█████████████████████████▏                | 90/150 [00:22<00:13,  4.43it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 361, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.273 | unlearn_loss: 1.266 | retain_loss: 0.006073 | param_change: 1.073e-06\n",
      "unlearn_cosine_sim=0.82421875\n",
      "retain_cosine_sim=0.96875\n",
      "Topic 0 updated_forget_activations.norm= 15.625\n",
      "Topic 0 frozen_forget_activations.norm= 20.25\n",
      "Topic 0 updated_retain_activations.norm= 22.0\n",
      "Topic 0 frozen_retain_activations.norm= 24.75\n",
      " 61%|█████████████████████████▍                | 91/150 [00:22<00:14,  4.11it/s]loss: 2.844 | unlearn_loss: 2.828 | retain_loss: 0.008301 | param_change: 1.252e-06\n",
      "unlearn_cosine_sim=0.828125\n",
      "retain_cosine_sim=0.953125\n",
      "Topic 0 updated_forget_activations.norm= 20.625\n",
      "Topic 0 frozen_forget_activations.norm= 25.25\n",
      "Topic 0 updated_retain_activations.norm= 20.0\n",
      "Topic 0 frozen_retain_activations.norm= 23.5\n",
      " 61%|█████████████████████████▊                | 92/150 [00:23<00:13,  4.22it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 258, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.766 | unlearn_loss: 1.758 | retain_loss: 0.007874 | param_change: 1.408e-06\n",
      "unlearn_cosine_sim=0.8671875\n",
      "retain_cosine_sim=0.96484375\n",
      "Topic 0 updated_forget_activations.norm= 17.0\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 31.25\n",
      "Topic 0 frozen_retain_activations.norm= 34.5\n",
      " 62%|██████████████████████████                | 93/150 [00:23<00:13,  4.15it/s]loss: 1.617 | unlearn_loss: 1.609 | retain_loss: 0.004913 | param_change: 1.214e-06\n",
      "unlearn_cosine_sim=0.84375\n",
      "retain_cosine_sim=0.9765625\n",
      "Topic 0 updated_forget_activations.norm= 16.75\n",
      "Topic 0 frozen_forget_activations.norm= 21.0\n",
      "Topic 0 updated_retain_activations.norm= 288.0\n",
      "Topic 0 frozen_retain_activations.norm= 290.0\n",
      " 63%|██████████████████████████▎               | 94/150 [00:23<00:14,  3.82it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 103, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 4.312 | unlearn_loss: 4.312 | retain_loss: 0.01166 | param_change: 1.803e-06\n",
      "unlearn_cosine_sim=0.921875\n",
      "retain_cosine_sim=0.921875\n",
      "Topic 0 updated_forget_activations.norm= 26.0\n",
      "Topic 0 frozen_forget_activations.norm= 30.0\n",
      "Topic 0 updated_retain_activations.norm= 18.375\n",
      "Topic 0 frozen_retain_activations.norm= 22.25\n",
      " 63%|██████████████████████████▌               | 95/150 [00:23<00:13,  4.00it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 161, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.797 | unlearn_loss: 2.781 | retain_loss: 0.00824 | param_change: 1.416e-06\n",
      "unlearn_cosine_sim=0.8515625\n",
      "retain_cosine_sim=0.94921875\n",
      "Topic 0 updated_forget_activations.norm= 20.375\n",
      "Topic 0 frozen_forget_activations.norm= 25.0\n",
      "Topic 0 updated_retain_activations.norm= 18.625\n",
      "Topic 0 frozen_retain_activations.norm= 22.0\n",
      " 64%|██████████████████████████▉               | 96/150 [00:24<00:13,  4.06it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 282, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.617 | unlearn_loss: 1.609 | retain_loss: 0.00824 | param_change: 1.296e-06\n",
      "unlearn_cosine_sim=0.84375\n",
      "retain_cosine_sim=0.94921875\n",
      "Topic 0 updated_forget_activations.norm= 16.25\n",
      "Topic 0 frozen_forget_activations.norm= 20.75\n",
      "Topic 0 updated_retain_activations.norm= 18.5\n",
      "Topic 0 frozen_retain_activations.norm= 22.0\n",
      " 65%|███████████████████████████▏              | 97/150 [00:24<00:13,  3.88it/s]loss: 2.578 | unlearn_loss: 2.562 | retain_loss: 0.008057 | param_change: 1.259e-06\n",
      "unlearn_cosine_sim=0.91015625\n",
      "retain_cosine_sim=0.953125\n",
      "Topic 0 updated_forget_activations.norm= 19.625\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 18.75\n",
      "Topic 0 frozen_retain_activations.norm= 22.25\n",
      " 65%|███████████████████████████▍              | 98/150 [00:24<00:13,  4.00it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 269, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.695 | unlearn_loss: 1.688 | retain_loss: 0.006165 | param_change: 1.006e-06\n",
      "unlearn_cosine_sim=0.765625\n",
      "retain_cosine_sim=0.96875\n",
      "Topic 0 updated_forget_activations.norm= 16.75\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 23.5\n",
      "Topic 0 frozen_retain_activations.norm= 26.375\n",
      " 66%|███████████████████████████▋              | 99/150 [00:25<00:12,  3.95it/s]loss: 2.734 | unlearn_loss: 2.719 | retain_loss: 0.008362 | param_change: 1.498e-06\n",
      "unlearn_cosine_sim=0.828125\n",
      "retain_cosine_sim=0.953125\n",
      "Topic 0 updated_forget_activations.norm= 20.5\n",
      "Topic 0 frozen_forget_activations.norm= 24.875\n",
      "Topic 0 updated_retain_activations.norm= 20.25\n",
      "Topic 0 frozen_retain_activations.norm= 23.5\n",
      " 67%|███████████████████████████▎             | 100/150 [00:25<00:12,  4.05it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 154, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.922 | unlearn_loss: 2.906 | retain_loss: 0.01019 | param_change: 1.431e-06\n",
      "unlearn_cosine_sim=0.859375\n",
      "retain_cosine_sim=0.94140625\n",
      "Topic 0 updated_forget_activations.norm= 20.5\n",
      "Topic 0 frozen_forget_activations.norm= 25.0\n",
      "Topic 0 updated_retain_activations.norm= 20.0\n",
      "Topic 0 frozen_retain_activations.norm= 24.0\n",
      " 67%|███████████████████████████▌             | 101/150 [00:25<00:11,  4.19it/s]loss: 2.281 | unlearn_loss: 2.266 | retain_loss: 0.008606 | param_change: 1.229e-06\n",
      "unlearn_cosine_sim=0.78125\n",
      "retain_cosine_sim=0.953125\n",
      "Topic 0 updated_forget_activations.norm= 18.5\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 20.875\n",
      "Topic 0 frozen_retain_activations.norm= 24.5\n",
      " 68%|███████████████████████████▉             | 102/150 [00:25<00:11,  4.23it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 155, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.875 | unlearn_loss: 2.875 | retain_loss: 0.007782 | param_change: 1.252e-06\n",
      "unlearn_cosine_sim=0.875\n",
      "retain_cosine_sim=0.953125\n",
      "Topic 0 updated_forget_activations.norm= 20.75\n",
      "Topic 0 frozen_forget_activations.norm= 25.0\n",
      "Topic 0 updated_retain_activations.norm= 19.0\n",
      "Topic 0 frozen_retain_activations.norm= 22.25\n",
      " 69%|████████████████████████████▏            | 103/150 [00:25<00:11,  4.23it/s]loss: 2.297 | unlearn_loss: 2.297 | retain_loss: 0.00592 | param_change: 1.17e-06\n",
      "unlearn_cosine_sim=0.87109375\n",
      "retain_cosine_sim=0.96484375\n",
      "Topic 0 updated_forget_activations.norm= 18.625\n",
      "Topic 0 frozen_forget_activations.norm= 23.125\n",
      "Topic 0 updated_retain_activations.norm= 19.0\n",
      "Topic 0 frozen_retain_activations.norm= 21.625\n",
      " 69%|████████████████████████████▍            | 104/150 [00:26<00:11,  4.12it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 245, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.836 | unlearn_loss: 1.828 | retain_loss: 0.008057 | param_change: 1.222e-06\n",
      "unlearn_cosine_sim=0.8125\n",
      "retain_cosine_sim=0.95703125\n",
      "Topic 0 updated_forget_activations.norm= 17.0\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 23.75\n",
      "Topic 0 frozen_retain_activations.norm= 27.0\n",
      " 70%|████████████████████████████▋            | 105/150 [00:26<00:10,  4.11it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 323, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.414 | unlearn_loss: 1.406 | retain_loss: 0.01038 | param_change: 1.766e-06\n",
      "unlearn_cosine_sim=0.8984375\n",
      "retain_cosine_sim=0.94140625\n",
      "Topic 0 updated_forget_activations.norm= 16.0\n",
      "Topic 0 frozen_forget_activations.norm= 20.0\n",
      "Topic 0 updated_retain_activations.norm= 24.375\n",
      "Topic 0 frozen_retain_activations.norm= 28.125\n",
      " 71%|████████████████████████████▉            | 106/150 [00:26<00:11,  3.99it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 230, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.977 | unlearn_loss: 1.969 | retain_loss: 0.01019 | param_change: 1.49e-06\n",
      "unlearn_cosine_sim=0.78125\n",
      "retain_cosine_sim=0.9375\n",
      "Topic 0 updated_forget_activations.norm= 18.0\n",
      "Topic 0 frozen_forget_activations.norm= 22.375\n",
      "Topic 0 updated_retain_activations.norm= 18.875\n",
      "Topic 0 frozen_retain_activations.norm= 22.75\n",
      " 71%|█████████████████████████████▏           | 107/150 [00:26<00:10,  3.99it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 165, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.719 | unlearn_loss: 2.703 | retain_loss: 0.009155 | param_change: 1.445e-06\n",
      "unlearn_cosine_sim=0.83984375\n",
      "retain_cosine_sim=0.94921875\n",
      "Topic 0 updated_forget_activations.norm= 20.5\n",
      "Topic 0 frozen_forget_activations.norm= 24.75\n",
      "Topic 0 updated_retain_activations.norm= 23.0\n",
      "Topic 0 frozen_retain_activations.norm= 26.5\n",
      " 72%|█████████████████████████████▌           | 108/150 [00:27<00:10,  4.16it/s]loss: 2.406 | unlearn_loss: 2.391 | retain_loss: 0.008789 | param_change: 1.408e-06\n",
      "unlearn_cosine_sim=0.875\n",
      "retain_cosine_sim=0.953125\n",
      "Topic 0 updated_forget_activations.norm= 19.25\n",
      "Topic 0 frozen_forget_activations.norm= 23.625\n",
      "Topic 0 updated_retain_activations.norm= 23.75\n",
      "Topic 0 frozen_retain_activations.norm= 27.125\n",
      " 73%|█████████████████████████████▊           | 109/150 [00:27<00:09,  4.27it/s]loss: 1.859 | unlearn_loss: 1.852 | retain_loss: 0.005981 | param_change: 1.349e-06\n",
      "unlearn_cosine_sim=0.82421875\n",
      "retain_cosine_sim=0.96875\n",
      "Topic 0 updated_forget_activations.norm= 17.5\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 19.75\n",
      "Topic 0 frozen_retain_activations.norm= 22.625\n",
      " 73%|██████████████████████████████           | 110/150 [00:27<00:09,  4.15it/s]loss: 1.727 | unlearn_loss: 1.711 | retain_loss: 0.01215 | param_change: 1.803e-06\n",
      "unlearn_cosine_sim=0.7421875\n",
      "retain_cosine_sim=0.92578125\n",
      "Topic 0 updated_forget_activations.norm= 16.625\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 30.25\n",
      "Topic 0 frozen_retain_activations.norm= 34.25\n",
      " 74%|██████████████████████████████▎          | 111/150 [00:27<00:09,  4.11it/s]loss: 2.266 | unlearn_loss: 2.25 | retain_loss: 0.009338 | param_change: 1.326e-06\n",
      "unlearn_cosine_sim=0.8125\n",
      "retain_cosine_sim=0.9453125\n",
      "Topic 0 updated_forget_activations.norm= 18.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 21.25\n",
      "Topic 0 frozen_retain_activations.norm= 24.625\n",
      " 75%|██████████████████████████████▌          | 112/150 [00:28<00:09,  4.16it/s]loss: 2.891 | unlearn_loss: 2.891 | retain_loss: 0.007568 | param_change: 1.296e-06\n",
      "unlearn_cosine_sim=0.859375\n",
      "retain_cosine_sim=0.95703125\n",
      "Topic 0 updated_forget_activations.norm= 20.5\n",
      "Topic 0 frozen_forget_activations.norm= 25.125\n",
      "Topic 0 updated_retain_activations.norm= 22.5\n",
      "Topic 0 frozen_retain_activations.norm= 25.625\n",
      " 75%|██████████████████████████████▉          | 113/150 [00:28<00:08,  4.29it/s]loss: 2.375 | unlearn_loss: 2.359 | retain_loss: 0.01166 | param_change: 1.743e-06\n",
      "unlearn_cosine_sim=0.8671875\n",
      "retain_cosine_sim=0.92578125\n",
      "Topic 0 updated_forget_activations.norm= 19.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.625\n",
      "Topic 0 updated_retain_activations.norm= 24.125\n",
      "Topic 0 frozen_retain_activations.norm= 28.0\n",
      " 76%|███████████████████████████████▏         | 114/150 [00:28<00:08,  4.39it/s]loss: 2.547 | unlearn_loss: 2.531 | retain_loss: 0.01196 | param_change: 1.706e-06\n",
      "unlearn_cosine_sim=0.83984375\n",
      "retain_cosine_sim=0.921875\n",
      "Topic 0 updated_forget_activations.norm= 19.75\n",
      "Topic 0 frozen_forget_activations.norm= 24.25\n",
      "Topic 0 updated_retain_activations.norm= 19.625\n",
      "Topic 0 frozen_retain_activations.norm= 23.5\n",
      " 77%|███████████████████████████████▍         | 115/150 [00:28<00:08,  4.36it/s]loss: 2.781 | unlearn_loss: 2.766 | retain_loss: 0.01117 | param_change: 1.9e-06\n",
      "unlearn_cosine_sim=0.8515625\n",
      "retain_cosine_sim=0.91796875\n",
      "Topic 0 updated_forget_activations.norm= 20.0\n",
      "Topic 0 frozen_forget_activations.norm= 24.5\n",
      "Topic 0 updated_retain_activations.norm= 18.25\n",
      "Topic 0 frozen_retain_activations.norm= 22.0\n",
      " 77%|███████████████████████████████▋         | 116/150 [00:29<00:07,  4.31it/s]loss: 2.469 | unlearn_loss: 2.453 | retain_loss: 0.009705 | param_change: 1.416e-06\n",
      "unlearn_cosine_sim=0.765625\n",
      "retain_cosine_sim=0.9375\n",
      "Topic 0 updated_forget_activations.norm= 19.25\n",
      "Topic 0 frozen_forget_activations.norm= 24.0\n",
      "Topic 0 updated_retain_activations.norm= 18.5\n",
      "Topic 0 frozen_retain_activations.norm= 22.375\n",
      " 78%|███████████████████████████████▉         | 117/150 [00:29<00:07,  4.29it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 193, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.328 | unlearn_loss: 2.312 | retain_loss: 0.00824 | param_change: 1.483e-06\n",
      "unlearn_cosine_sim=0.828125\n",
      "retain_cosine_sim=0.9453125\n",
      "Topic 0 updated_forget_activations.norm= 18.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.5\n",
      "Topic 0 updated_retain_activations.norm= 16.5\n",
      "Topic 0 frozen_retain_activations.norm= 19.875\n",
      " 79%|████████████████████████████████▎        | 118/150 [00:29<00:08,  3.98it/s]loss: 2.781 | unlearn_loss: 2.766 | retain_loss: 0.009766 | param_change: 1.498e-06\n",
      "unlearn_cosine_sim=0.80078125\n",
      "retain_cosine_sim=0.94921875\n",
      "Topic 0 updated_forget_activations.norm= 19.75\n",
      "Topic 0 frozen_forget_activations.norm= 24.5\n",
      "Topic 0 updated_retain_activations.norm= 28.5\n",
      "Topic 0 frozen_retain_activations.norm= 32.25\n",
      " 79%|████████████████████████████████▌        | 119/150 [00:29<00:07,  4.19it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 131, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.422 | unlearn_loss: 3.406 | retain_loss: 0.008545 | param_change: 1.796e-06\n",
      "unlearn_cosine_sim=0.921875\n",
      "retain_cosine_sim=0.94921875\n",
      "Topic 0 updated_forget_activations.norm= 22.875\n",
      "Topic 0 frozen_forget_activations.norm= 26.75\n",
      "Topic 0 updated_retain_activations.norm= 19.25\n",
      "Topic 0 frozen_retain_activations.norm= 22.75\n",
      " 80%|████████████████████████████████▊        | 120/150 [00:29<00:07,  4.26it/s]loss: 2.312 | unlearn_loss: 2.297 | retain_loss: 0.01038 | param_change: 1.393e-06\n",
      "unlearn_cosine_sim=0.8515625\n",
      "retain_cosine_sim=0.9375\n",
      "Topic 0 updated_forget_activations.norm= 18.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 25.25\n",
      "Topic 0 frozen_retain_activations.norm= 29.0\n",
      " 81%|█████████████████████████████████        | 121/150 [00:30<00:06,  4.34it/s]loss: 2.406 | unlearn_loss: 2.406 | retain_loss: 0.007233 | param_change: 1.378e-06\n",
      "unlearn_cosine_sim=0.703125\n",
      "retain_cosine_sim=0.95703125\n",
      "Topic 0 updated_forget_activations.norm= 19.25\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 21.5\n",
      "Topic 0 frozen_retain_activations.norm= 24.5\n",
      " 81%|█████████████████████████████████▎       | 122/150 [00:30<00:06,  4.38it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 168, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.656 | unlearn_loss: 2.656 | retain_loss: 0.006897 | param_change: 1.445e-06\n",
      "unlearn_cosine_sim=0.90234375\n",
      "retain_cosine_sim=0.9609375\n",
      "Topic 0 updated_forget_activations.norm= 19.75\n",
      "Topic 0 frozen_forget_activations.norm= 24.0\n",
      "Topic 0 updated_retain_activations.norm= 21.5\n",
      "Topic 0 frozen_retain_activations.norm= 24.5\n",
      " 82%|█████████████████████████████████▌       | 123/150 [00:30<00:06,  4.42it/s]loss: 2.188 | unlearn_loss: 2.172 | retain_loss: 0.009827 | param_change: 1.594e-06\n",
      "unlearn_cosine_sim=0.85546875\n",
      "retain_cosine_sim=0.94140625\n",
      "Topic 0 updated_forget_activations.norm= 18.125\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 23.625\n",
      "Topic 0 frozen_retain_activations.norm= 27.25\n",
      " 83%|█████████████████████████████████▉       | 124/150 [00:30<00:05,  4.43it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 235, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.93 | unlearn_loss: 1.922 | retain_loss: 0.006317 | param_change: 9.76e-07\n",
      "unlearn_cosine_sim=0.765625\n",
      "retain_cosine_sim=0.96484375\n",
      "Topic 0 updated_forget_activations.norm= 17.5\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 20.5\n",
      "Topic 0 frozen_retain_activations.norm= 23.5\n",
      " 83%|██████████████████████████████████▏      | 125/150 [00:31<00:05,  4.30it/s]loss: 2.656 | unlearn_loss: 2.641 | retain_loss: 0.00885 | param_change: 1.587e-06\n",
      "unlearn_cosine_sim=0.87109375\n",
      "retain_cosine_sim=0.94921875\n",
      "Topic 0 updated_forget_activations.norm= 19.875\n",
      "Topic 0 frozen_forget_activations.norm= 24.25\n",
      "Topic 0 updated_retain_activations.norm= 22.875\n",
      "Topic 0 frozen_retain_activations.norm= 26.25\n",
      " 84%|██████████████████████████████████▍      | 126/150 [00:31<00:05,  4.38it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 122, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.672 | unlearn_loss: 3.656 | retain_loss: 0.01068 | param_change: 2.071e-06\n",
      "unlearn_cosine_sim=0.8828125\n",
      "retain_cosine_sim=0.92578125\n",
      "Topic 0 updated_forget_activations.norm= 23.5\n",
      "Topic 0 frozen_forget_activations.norm= 28.0\n",
      "Topic 0 updated_retain_activations.norm= 18.0\n",
      "Topic 0 frozen_retain_activations.norm= 21.5\n",
      " 85%|██████████████████████████████████▋      | 127/150 [00:31<00:05,  4.31it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 232, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.953 | unlearn_loss: 1.945 | retain_loss: 0.008301 | param_change: 1.445e-06\n",
      "unlearn_cosine_sim=0.7734375\n",
      "retain_cosine_sim=0.953125\n",
      "Topic 0 updated_forget_activations.norm= 17.25\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 22.5\n",
      "Topic 0 frozen_retain_activations.norm= 26.0\n",
      " 85%|██████████████████████████████████▉      | 128/150 [00:31<00:05,  4.29it/s]loss: 2.719 | unlearn_loss: 2.703 | retain_loss: 0.01349 | param_change: 1.952e-06\n",
      "unlearn_cosine_sim=0.8828125\n",
      "retain_cosine_sim=0.90625\n",
      "Topic 0 updated_forget_activations.norm= 20.75\n",
      "Topic 0 frozen_forget_activations.norm= 25.0\n",
      "Topic 0 updated_retain_activations.norm= 23.875\n",
      "Topic 0 frozen_retain_activations.norm= 27.75\n",
      " 86%|███████████████████████████████████▎     | 129/150 [00:32<00:04,  4.41it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 218, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.062 | unlearn_loss: 2.047 | retain_loss: 0.01306 | param_change: 1.773e-06\n",
      "unlearn_cosine_sim=0.6875\n",
      "retain_cosine_sim=0.90625\n",
      "Topic 0 updated_forget_activations.norm= 18.0\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 21.25\n",
      "Topic 0 frozen_retain_activations.norm= 24.875\n",
      " 87%|███████████████████████████████████▌     | 130/150 [00:32<00:04,  4.37it/s]loss: 2.422 | unlearn_loss: 2.422 | retain_loss: 0.00766 | param_change: 1.244e-06\n",
      "unlearn_cosine_sim=0.8046875\n",
      "retain_cosine_sim=0.95703125\n",
      "Topic 0 updated_forget_activations.norm= 19.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 22.125\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 87%|███████████████████████████████████▊     | 131/150 [00:32<00:04,  4.40it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 112, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.984 | unlearn_loss: 3.969 | retain_loss: 0.008911 | param_change: 1.498e-06\n",
      "unlearn_cosine_sim=0.74609375\n",
      "retain_cosine_sim=0.94921875\n",
      "Topic 0 updated_forget_activations.norm= 24.5\n",
      "Topic 0 frozen_forget_activations.norm= 29.375\n",
      "Topic 0 updated_retain_activations.norm= 23.0\n",
      "Topic 0 frozen_retain_activations.norm= 26.5\n",
      " 88%|████████████████████████████████████     | 132/150 [00:32<00:03,  4.52it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 329, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.383 | unlearn_loss: 1.375 | retain_loss: 0.009033 | param_change: 1.527e-06\n",
      "unlearn_cosine_sim=0.77734375\n",
      "retain_cosine_sim=0.94921875\n",
      "Topic 0 updated_forget_activations.norm= 15.875\n",
      "Topic 0 frozen_forget_activations.norm= 20.375\n",
      "Topic 0 updated_retain_activations.norm= 23.75\n",
      "Topic 0 frozen_retain_activations.norm= 27.125\n",
      " 89%|████████████████████████████████████▎    | 133/150 [00:32<00:04,  4.18it/s]loss: 2.375 | unlearn_loss: 2.359 | retain_loss: 0.009033 | param_change: 1.349e-06\n",
      "unlearn_cosine_sim=0.83203125\n",
      "retain_cosine_sim=0.9453125\n",
      "Topic 0 updated_forget_activations.norm= 18.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.5\n",
      "Topic 0 updated_retain_activations.norm= 18.0\n",
      "Topic 0 frozen_retain_activations.norm= 21.625\n",
      " 89%|████████████████████████████████████▋    | 134/150 [00:33<00:03,  4.11it/s]loss: 2.234 | unlearn_loss: 2.219 | retain_loss: 0.01105 | param_change: 1.632e-06\n",
      "unlearn_cosine_sim=0.828125\n",
      "retain_cosine_sim=0.9375\n",
      "Topic 0 updated_forget_activations.norm= 18.5\n",
      "Topic 0 frozen_forget_activations.norm= 23.0\n",
      "Topic 0 updated_retain_activations.norm= 24.75\n",
      "Topic 0 frozen_retain_activations.norm= 28.625\n",
      " 90%|████████████████████████████████████▉    | 135/150 [00:33<00:03,  4.22it/s]loss: 2.156 | unlearn_loss: 2.141 | retain_loss: 0.008118 | param_change: 1.08e-06\n",
      "unlearn_cosine_sim=0.73828125\n",
      "retain_cosine_sim=0.953125\n",
      "Topic 0 updated_forget_activations.norm= 18.0\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 19.75\n",
      "Topic 0 frozen_retain_activations.norm= 23.25\n",
      " 91%|█████████████████████████████████████▏   | 136/150 [00:33<00:03,  4.20it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 224, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.016 | unlearn_loss: 2 | retain_loss: 0.01007 | param_change: 1.967e-06\n",
      "unlearn_cosine_sim=0.88671875\n",
      "retain_cosine_sim=0.94140625\n",
      "Topic 0 updated_forget_activations.norm= 18.125\n",
      "Topic 0 frozen_forget_activations.norm= 22.125\n",
      "Topic 0 updated_retain_activations.norm= 26.25\n",
      "Topic 0 frozen_retain_activations.norm= 29.75\n",
      " 91%|█████████████████████████████████████▍   | 137/150 [00:33<00:03,  4.28it/s]loss: 2.703 | unlearn_loss: 2.688 | retain_loss: 0.01056 | param_change: 1.49e-06\n",
      "unlearn_cosine_sim=0.8359375\n",
      "retain_cosine_sim=0.921875\n",
      "Topic 0 updated_forget_activations.norm= 19.875\n",
      "Topic 0 frozen_forget_activations.norm= 24.5\n",
      "Topic 0 updated_retain_activations.norm= 17.0\n",
      "Topic 0 frozen_retain_activations.norm= 20.5\n",
      " 92%|█████████████████████████████████████▋   | 138/150 [00:34<00:02,  4.09it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 250, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.805 | unlearn_loss: 1.797 | retain_loss: 0.008728 | param_change: 1.453e-06\n",
      "unlearn_cosine_sim=0.81640625\n",
      "retain_cosine_sim=0.953125\n",
      "Topic 0 updated_forget_activations.norm= 16.625\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 22.375\n",
      "Topic 0 frozen_retain_activations.norm= 25.875\n",
      " 93%|█████████████████████████████████████▉   | 139/150 [00:34<00:02,  4.08it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 138, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.234 | unlearn_loss: 3.219 | retain_loss: 0.01074 | param_change: 1.557e-06\n",
      "unlearn_cosine_sim=0.73828125\n",
      "retain_cosine_sim=0.9296875\n",
      "Topic 0 updated_forget_activations.norm= 21.75\n",
      "Topic 0 frozen_forget_activations.norm= 26.5\n",
      "Topic 0 updated_retain_activations.norm= 19.5\n",
      "Topic 0 frozen_retain_activations.norm= 23.25\n",
      " 93%|██████████████████████████████████████▎  | 140/150 [00:34<00:02,  4.21it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 216, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.078 | unlearn_loss: 2.078 | retain_loss: 0.006226 | param_change: 1.036e-06\n",
      "unlearn_cosine_sim=0.7578125\n",
      "retain_cosine_sim=0.96484375\n",
      "Topic 0 updated_forget_activations.norm= 18.0\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 22.75\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 94%|██████████████████████████████████████▌  | 141/150 [00:34<00:02,  4.24it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 311, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.477 | unlearn_loss: 1.469 | retain_loss: 0.01062 | param_change: 1.609e-06\n",
      "unlearn_cosine_sim=0.82421875\n",
      "retain_cosine_sim=0.93359375\n",
      "Topic 0 updated_forget_activations.norm= 16.0\n",
      "Topic 0 frozen_forget_activations.norm= 20.75\n",
      "Topic 0 updated_retain_activations.norm= 21.5\n",
      "Topic 0 frozen_retain_activations.norm= 25.5\n",
      " 95%|██████████████████████████████████████▊  | 142/150 [00:35<00:01,  4.07it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 331, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.367 | unlearn_loss: 1.359 | retain_loss: 0.00528 | param_change: 1.132e-06\n",
      "unlearn_cosine_sim=0.77734375\n",
      "retain_cosine_sim=0.97265625\n",
      "Topic 0 updated_forget_activations.norm= 15.5\n",
      "Topic 0 frozen_forget_activations.norm= 20.25\n",
      "Topic 0 updated_retain_activations.norm= 23.75\n",
      "Topic 0 frozen_retain_activations.norm= 26.25\n",
      " 95%|███████████████████████████████████████  | 143/150 [00:35<00:01,  3.92it/s]loss: 2.172 | unlearn_loss: 2.172 | retain_loss: 0.006897 | param_change: 1.661e-06\n",
      "unlearn_cosine_sim=0.875\n",
      "retain_cosine_sim=0.9609375\n",
      "Topic 0 updated_forget_activations.norm= 18.75\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 21.75\n",
      "Topic 0 frozen_retain_activations.norm= 24.5\n",
      " 96%|███████████████████████████████████████▎ | 144/150 [00:35<00:01,  4.03it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 115, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.891 | unlearn_loss: 3.875 | retain_loss: 0.008545 | param_change: 1.55e-06\n",
      "unlearn_cosine_sim=0.73828125\n",
      "retain_cosine_sim=0.9453125\n",
      "Topic 0 updated_forget_activations.norm= 24.125\n",
      "Topic 0 frozen_forget_activations.norm= 29.0\n",
      "Topic 0 updated_retain_activations.norm= 19.25\n",
      "Topic 0 frozen_retain_activations.norm= 22.5\n",
      " 97%|███████████████████████████████████████▋ | 145/150 [00:35<00:01,  4.15it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 171, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.609 | unlearn_loss: 2.609 | retain_loss: 0.006561 | param_change: 1.557e-06\n",
      "unlearn_cosine_sim=0.8046875\n",
      "retain_cosine_sim=0.96484375\n",
      "Topic 0 updated_forget_activations.norm= 20.125\n",
      "Topic 0 frozen_forget_activations.norm= 24.5\n",
      "Topic 0 updated_retain_activations.norm= 22.5\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 97%|███████████████████████████████████████▉ | 146/150 [00:36<00:00,  4.26it/s]loss: 2.281 | unlearn_loss: 2.266 | retain_loss: 0.0105 | param_change: 2.563e-06\n",
      "unlearn_cosine_sim=0.921875\n",
      "retain_cosine_sim=0.92578125\n",
      "Topic 0 updated_forget_activations.norm= 19.5\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 17.375\n",
      "Topic 0 frozen_retain_activations.norm= 21.125\n",
      " 98%|████████████████████████████████████████▏| 147/150 [00:36<00:00,  4.07it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 147, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.047 | unlearn_loss: 3.031 | retain_loss: 0.0105 | param_change: 1.542e-06\n",
      "unlearn_cosine_sim=0.73828125\n",
      "retain_cosine_sim=0.93359375\n",
      "Topic 0 updated_forget_activations.norm= 21.125\n",
      "Topic 0 frozen_forget_activations.norm= 25.875\n",
      "Topic 0 updated_retain_activations.norm= 20.5\n",
      "Topic 0 frozen_retain_activations.norm= 24.0\n",
      " 99%|████████████████████████████████████████▍| 148/150 [00:36<00:00,  4.20it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 318, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.438 | unlearn_loss: 1.43 | retain_loss: 0.006714 | param_change: 1.661e-06\n",
      "unlearn_cosine_sim=0.87109375\n",
      "retain_cosine_sim=0.96484375\n",
      "Topic 0 updated_forget_activations.norm= 15.625\n",
      "Topic 0 frozen_forget_activations.norm= 20.0\n",
      "Topic 0 updated_retain_activations.norm= 21.5\n",
      "Topic 0 frozen_retain_activations.norm= 24.5\n",
      " 99%|████████████████████████████████████████▋| 149/150 [00:36<00:00,  4.03it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 210, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.141 | unlearn_loss: 2.125 | retain_loss: 0.02258 | param_change: 1.997e-06\n",
      "unlearn_cosine_sim=0.8046875\n",
      "retain_cosine_sim=0.80859375\n",
      "Topic 0 updated_forget_activations.norm= 18.0\n",
      "Topic 0 frozen_forget_activations.norm= 22.5\n",
      "Topic 0 updated_retain_activations.norm= 16.25\n",
      "Topic 0 frozen_retain_activations.norm= 20.25\n",
      "100%|█████████████████████████████████████████| 150/150 [00:37<00:00,  4.04it/s]\n",
      "Saved model to models/alpaca_rmu_alpha_1\n"
     ]
    }
   ],
   "source": [
    "!python3 -m rmu.unlearn --model_name PKU-Alignment/alpaca-7b-reproduced --max_num_batches 150 --batch_size=2 --retain_corpora SafeRLHF-corpora/safe_train_sampled --forget_corpora SafeRLHF-corpora/Privacy_Violation_train --layer_id 7 --steering_coeffs 6.5 --alpha 1 --lr 1e-4 --seed 42 --output_dir models/alpaca_rmu_alpha_1 --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [01:41<00:00, 14.45s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [00:02<00:00,  2.57it/s]\n",
      "====rmu Config====\n",
      "model_name_or_path=PKU-Alignment/alpaca-7b-reproduced\n",
      "module_str={model_name}.model.layers[{layer_id}]\n",
      "output_dir=models/alpaca_rmu_alpha_1000\n",
      "retain_corpora=['SafeRLHF-corpora/safe_train_sampled']\n",
      "forget_corpora=['SafeRLHF-corpora/Privacy_Violation_train']\n",
      "alpha=[1200.0]\n",
      "steering_coeffs=6.5\n",
      "lr=0.0001\n",
      "min_len=0\n",
      "max_len=2000\n",
      "batch_size=2\n",
      "max_num_batches=150\n",
      "layer_id=7\n",
      "layer_ids=[5, 6, 7]\n",
      "param_ids=[6]\n",
      "seed=42\n",
      "verbose=True\n",
      "steering_coeff_list=[6.5]\n",
      "=====\n",
      "/home/hice1/jli928/.conda/envs/model-unlearning/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "======= Epoch 0 =======\n",
      "  0%|                                                   | 0/150 [00:00<?, ?it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 185, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.453 | unlearn_loss: 2.453 | retain_loss: 0 | param_change: 1.982e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.125\n",
      "Topic 0 frozen_forget_activations.norm= 23.125\n",
      "Topic 0 updated_retain_activations.norm= 23.5\n",
      "Topic 0 frozen_retain_activations.norm= 23.5\n",
      "  1%|▎                                          | 1/150 [00:01<03:56,  1.59s/it]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 170, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.688 | unlearn_loss: 2.672 | retain_loss: 0.01001 | param_change: 4.745e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.375\n",
      "Topic 0 frozen_forget_activations.norm= 24.5\n",
      "Topic 0 updated_retain_activations.norm= 19.5\n",
      "Topic 0 frozen_retain_activations.norm= 19.5\n",
      "  1%|▌                                          | 2/150 [00:01<02:02,  1.21it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 199, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.5 | unlearn_loss: 2.297 | retain_loss: 0.1973 | param_change: 0.0001602\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.875\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 25.5\n",
      "Topic 0 frozen_retain_activations.norm= 25.5\n",
      "  2%|▊                                          | 3/150 [00:02<01:21,  1.81it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 251, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.875 | unlearn_loss: 1.836 | retain_loss: 0.0376 | param_change: 9.06e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.625\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 23.125\n",
      "Topic 0 frozen_retain_activations.norm= 23.0\n",
      "  3%|█▏                                         | 4/150 [00:02<01:03,  2.30it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 190, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.484 | unlearn_loss: 2.391 | retain_loss: 0.1001 | param_change: 0.0001364\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.125\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 23.875\n",
      "Topic 0 frozen_retain_activations.norm= 24.0\n",
      "  3%|█▍                                         | 5/150 [00:02<00:52,  2.79it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 243, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.961 | unlearn_loss: 1.891 | retain_loss: 0.07129 | param_change: 9.155e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.875\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 24.25\n",
      "Topic 0 frozen_retain_activations.norm= 24.25\n",
      "  4%|█▋                                         | 6/150 [00:02<00:46,  3.12it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 293, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.625 | unlearn_loss: 1.594 | retain_loss: 0.03418 | param_change: 6.151e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 20.75\n",
      "Topic 0 frozen_forget_activations.norm= 20.625\n",
      "Topic 0 updated_retain_activations.norm= 24.5\n",
      "Topic 0 frozen_retain_activations.norm= 24.5\n",
      "  5%|██                                         | 7/150 [00:03<00:43,  3.31it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 244, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.992 | unlearn_loss: 1.883 | retain_loss: 0.1099 | param_change: 0.0001888\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.625\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 25.25\n",
      "Topic 0 frozen_retain_activations.norm= 25.125\n",
      "  5%|██▎                                        | 8/150 [00:03<00:40,  3.52it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 162, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.828 | unlearn_loss: 2.797 | retain_loss: 0.0354 | param_change: 5.341e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 25.0\n",
      "Topic 0 frozen_forget_activations.norm= 25.125\n",
      "Topic 0 updated_retain_activations.norm= 25.625\n",
      "Topic 0 frozen_retain_activations.norm= 25.625\n",
      "  6%|██▌                                        | 9/150 [00:03<00:37,  3.80it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 219, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.172 | unlearn_loss: 2.094 | retain_loss: 0.07715 | param_change: 7.677e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.5\n",
      "Topic 0 frozen_forget_activations.norm= 22.5\n",
      "Topic 0 updated_retain_activations.norm= 22.25\n",
      "Topic 0 frozen_retain_activations.norm= 22.375\n",
      "  7%|██▊                                       | 10/150 [00:03<00:36,  3.88it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 151, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.078 | unlearn_loss: 3 | retain_loss: 0.0835 | param_change: 8.249e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 25.625\n",
      "Topic 0 frozen_forget_activations.norm= 25.75\n",
      "Topic 0 updated_retain_activations.norm= 24.75\n",
      "Topic 0 frozen_retain_activations.norm= 24.75\n",
      "  7%|███                                       | 11/150 [00:04<00:34,  4.07it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 144, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.281 | unlearn_loss: 3.141 | retain_loss: 0.1377 | param_change: 0.0001526\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 25.625\n",
      "Topic 0 frozen_forget_activations.norm= 25.75\n",
      "Topic 0 updated_retain_activations.norm= 35.5\n",
      "Topic 0 frozen_retain_activations.norm= 35.5\n",
      "  8%|███▎                                      | 12/150 [00:04<00:33,  4.11it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 255, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.906 | unlearn_loss: 1.805 | retain_loss: 0.09912 | param_change: 9.775e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.5\n",
      "Topic 0 frozen_forget_activations.norm= 21.5\n",
      "Topic 0 updated_retain_activations.norm= 22.5\n",
      "Topic 0 frozen_retain_activations.norm= 22.5\n",
      "  9%|███▋                                      | 13/150 [00:04<00:33,  4.03it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 283, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.969 | unlearn_loss: 1.648 | retain_loss: 0.3164 | param_change: 0.0001898\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 21.0\n",
      "Topic 0 frozen_forget_activations.norm= 21.125\n",
      "Topic 0 updated_retain_activations.norm= 22.25\n",
      "Topic 0 frozen_retain_activations.norm= 22.25\n",
      "  9%|███▉                                      | 14/150 [00:04<00:34,  3.91it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 141, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.312 | unlearn_loss: 3.203 | retain_loss: 0.1157 | param_change: 0.0001287\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 25.75\n",
      "Topic 0 frozen_forget_activations.norm= 25.75\n",
      "Topic 0 updated_retain_activations.norm= 26.0\n",
      "Topic 0 frozen_retain_activations.norm= 26.0\n",
      " 10%|████▏                                     | 15/150 [00:05<00:32,  4.11it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 181, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.844 | unlearn_loss: 2.516 | retain_loss: 0.3301 | param_change: 0.0002203\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 24.0\n",
      "Topic 0 frozen_forget_activations.norm= 24.0\n",
      "Topic 0 updated_retain_activations.norm= 22.5\n",
      "Topic 0 frozen_retain_activations.norm= 22.5\n",
      " 11%|████▍                                     | 16/150 [00:05<00:32,  4.16it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 220, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.25 | unlearn_loss: 2.078 | retain_loss: 0.1758 | param_change: 0.000144\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.125\n",
      "Topic 0 frozen_forget_activations.norm= 22.125\n",
      "Topic 0 updated_retain_activations.norm= 23.5\n",
      "Topic 0 frozen_retain_activations.norm= 23.5\n",
      " 11%|████▊                                     | 17/150 [00:05<00:31,  4.19it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 231, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.203 | unlearn_loss: 2 | retain_loss: 0.2051 | param_change: 0.0001526\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.875\n",
      "Topic 0 frozen_forget_activations.norm= 21.875\n",
      "Topic 0 updated_retain_activations.norm= 22.5\n",
      "Topic 0 frozen_retain_activations.norm= 22.375\n",
      " 12%|█████                                     | 18/150 [00:05<00:31,  4.14it/s]loss: 3.297 | unlearn_loss: 3.141 | retain_loss: 0.1572 | param_change: 0.0001602\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 26.0\n",
      "Topic 0 frozen_forget_activations.norm= 26.0\n",
      "Topic 0 updated_retain_activations.norm= 25.125\n",
      "Topic 0 frozen_retain_activations.norm= 25.125\n",
      " 13%|█████▎                                    | 19/150 [00:05<00:30,  4.29it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 153, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.188 | unlearn_loss: 2.969 | retain_loss: 0.2236 | param_change: 0.0001621\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 25.5\n",
      "Topic 0 frozen_forget_activations.norm= 25.5\n",
      "Topic 0 updated_retain_activations.norm= 24.25\n",
      "Topic 0 frozen_retain_activations.norm= 24.25\n",
      " 13%|█████▌                                    | 20/150 [00:06<00:29,  4.36it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 217, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.344 | unlearn_loss: 2.109 | retain_loss: 0.2266 | param_change: 0.0002012\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 22.5\n",
      "Topic 0 frozen_forget_activations.norm= 22.5\n",
      "Topic 0 updated_retain_activations.norm= 23.75\n",
      "Topic 0 frozen_retain_activations.norm= 23.75\n",
      " 14%|█████▉                                    | 21/150 [00:06<00:29,  4.34it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 197, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.406 | unlearn_loss: 2.312 | retain_loss: 0.08984 | param_change: 9.918e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.375\n",
      "Topic 0 frozen_forget_activations.norm= 23.5\n",
      "Topic 0 updated_retain_activations.norm= 32.75\n",
      "Topic 0 frozen_retain_activations.norm= 32.75\n",
      " 15%|██████▏                                   | 22/150 [00:06<00:28,  4.42it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 195, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.609 | unlearn_loss: 2.344 | retain_loss: 0.2656 | param_change: 0.0002041\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 23.5\n",
      "Topic 0 frozen_forget_activations.norm= 23.5\n",
      "Topic 0 updated_retain_activations.norm= 22.5\n",
      "Topic 0 frozen_retain_activations.norm= 22.625\n",
      " 15%|██████▍                                   | 23/150 [00:06<00:29,  4.35it/s]loss: 1.961 | unlearn_loss: 1.805 | retain_loss: 0.1553 | param_change: 0.0001831\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.25\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 33.5\n",
      "Topic 0 frozen_retain_activations.norm= 33.5\n",
      " 16%|██████▋                                   | 24/150 [00:07<00:29,  4.32it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 201, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.406 | unlearn_loss: 2.266 | retain_loss: 0.1455 | param_change: 0.0001516\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 23.5\n",
      "Topic 0 frozen_retain_activations.norm= 23.75\n",
      " 17%|███████                                   | 25/150 [00:07<00:28,  4.32it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 252, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.984 | unlearn_loss: 1.828 | retain_loss: 0.1582 | param_change: 0.0001392\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.5\n",
      "Topic 0 frozen_forget_activations.norm= 21.5\n",
      "Topic 0 updated_retain_activations.norm= 27.5\n",
      "Topic 0 frozen_retain_activations.norm= 27.625\n",
      " 17%|███████▎                                  | 26/150 [00:07<00:28,  4.29it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 205, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.094 | unlearn_loss: 2.234 | retain_loss: 0.8594 | param_change: 0.0006104\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 23.25\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 35.0\n",
      "Topic 0 frozen_retain_activations.norm= 35.0\n",
      " 18%|███████▌                                  | 27/150 [00:07<00:28,  4.38it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 187, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.641 | unlearn_loss: 2.438 | retain_loss: 0.2021 | param_change: 0.0001459\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.0\n",
      "Topic 0 frozen_forget_activations.norm= 24.0\n",
      "Topic 0 updated_retain_activations.norm= 23.0\n",
      "Topic 0 frozen_retain_activations.norm= 23.0\n",
      " 19%|███████▊                                  | 28/150 [00:07<00:28,  4.35it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 176, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.906 | unlearn_loss: 2.594 | retain_loss: 0.3164 | param_change: 0.0002708\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.375\n",
      "Topic 0 frozen_forget_activations.norm= 24.25\n",
      "Topic 0 updated_retain_activations.norm= 22.75\n",
      "Topic 0 frozen_retain_activations.norm= 22.5\n",
      " 19%|████████                                  | 29/150 [00:08<00:27,  4.33it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 84, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 5.438 | unlearn_loss: 5.25 | retain_loss: 0.1875 | param_change: 0.0002346\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 33.0\n",
      "Topic 0 frozen_forget_activations.norm= 32.75\n",
      "Topic 0 updated_retain_activations.norm= 22.0\n",
      "Topic 0 frozen_retain_activations.norm= 22.0\n",
      " 20%|████████▍                                 | 30/150 [00:08<00:27,  4.36it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 198, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.469 | unlearn_loss: 2.312 | retain_loss: 0.1582 | param_change: 0.0001316\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.25\n",
      "Topic 0 frozen_forget_activations.norm= 23.0\n",
      "Topic 0 updated_retain_activations.norm= 24.0\n",
      "Topic 0 frozen_retain_activations.norm= 24.0\n",
      " 21%|████████▋                                 | 31/150 [00:08<00:27,  4.35it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 212, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.281 | unlearn_loss: 2.156 | retain_loss: 0.1289 | param_change: 0.0001125\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.5\n",
      "Topic 0 frozen_forget_activations.norm= 22.5\n",
      "Topic 0 updated_retain_activations.norm= 21.25\n",
      "Topic 0 frozen_retain_activations.norm= 21.375\n",
      " 21%|████████▉                                 | 32/150 [00:08<00:28,  4.19it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 242, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.016 | unlearn_loss: 1.898 | retain_loss: 0.1104 | param_change: 0.0001211\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.0\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 27.0\n",
      "Topic 0 frozen_retain_activations.norm= 27.125\n",
      " 22%|█████████▏                                | 33/150 [00:09<00:27,  4.18it/s]loss: 2.375 | unlearn_loss: 2.234 | retain_loss: 0.1484 | param_change: 0.0002594\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.75\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 25.625\n",
      "Topic 0 frozen_retain_activations.norm= 25.75\n",
      " 23%|█████████▌                                | 34/150 [00:09<00:27,  4.24it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 175, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.984 | unlearn_loss: 2.594 | retain_loss: 0.3887 | param_change: 0.0002556\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 24.375\n",
      "Topic 0 frozen_forget_activations.norm= 24.375\n",
      "Topic 0 updated_retain_activations.norm= 19.625\n",
      "Topic 0 frozen_retain_activations.norm= 19.5\n",
      " 23%|█████████▊                                | 35/150 [00:09<00:34,  3.33it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 182, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.609 | unlearn_loss: 2.5 | retain_loss: 0.1079 | param_change: 9.298e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.875\n",
      "Topic 0 frozen_forget_activations.norm= 24.0\n",
      "Topic 0 updated_retain_activations.norm= 23.75\n",
      "Topic 0 frozen_retain_activations.norm= 23.75\n",
      " 24%|██████████                                | 36/150 [00:10<00:31,  3.60it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 172, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.734 | unlearn_loss: 2.641 | retain_loss: 0.0957 | param_change: 9.441e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.25\n",
      "Topic 0 frozen_forget_activations.norm= 24.25\n",
      "Topic 0 updated_retain_activations.norm= 25.875\n",
      "Topic 0 frozen_retain_activations.norm= 26.0\n",
      " 25%|██████████▎                               | 37/150 [00:10<00:29,  3.85it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 189, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.703 | unlearn_loss: 2.406 | retain_loss: 0.3008 | param_change: 0.0002499\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 23.5\n",
      "Topic 0 frozen_forget_activations.norm= 23.5\n",
      "Topic 0 updated_retain_activations.norm= 24.625\n",
      "Topic 0 frozen_retain_activations.norm= 24.75\n",
      " 25%|██████████▋                               | 38/150 [00:10<00:27,  4.03it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 225, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.203 | unlearn_loss: 2.047 | retain_loss: 0.1504 | param_change: 0.0001488\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.0\n",
      "Topic 0 frozen_forget_activations.norm= 22.125\n",
      "Topic 0 updated_retain_activations.norm= 26.0\n",
      "Topic 0 frozen_retain_activations.norm= 26.0\n",
      " 26%|██████████▉                               | 39/150 [00:10<00:27,  4.10it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 113, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 4.219 | unlearn_loss: 3.984 | retain_loss: 0.2422 | param_change: 0.000185\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 28.25\n",
      "Topic 0 frozen_forget_activations.norm= 28.25\n",
      "Topic 0 updated_retain_activations.norm= 25.25\n",
      "Topic 0 frozen_retain_activations.norm= 25.5\n",
      " 27%|███████████▏                              | 40/150 [00:10<00:25,  4.29it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 119, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.969 | unlearn_loss: 3.781 | retain_loss: 0.1836 | param_change: 0.0002136\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 28.125\n",
      "Topic 0 frozen_forget_activations.norm= 28.25\n",
      "Topic 0 updated_retain_activations.norm= 25.375\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 27%|███████████▍                              | 41/150 [00:11<00:24,  4.42it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 174, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.734 | unlearn_loss: 2.609 | retain_loss: 0.123 | param_change: 0.0001345\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 20.125\n",
      "Topic 0 frozen_retain_activations.norm= 20.0\n",
      " 28%|███████████▊                              | 42/150 [00:11<00:26,  4.14it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 248, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.125 | unlearn_loss: 1.852 | retain_loss: 0.2812 | param_change: 0.0001831\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 21.75\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 26.75\n",
      "Topic 0 frozen_retain_activations.norm= 26.875\n",
      " 29%|████████████                              | 43/150 [00:11<00:25,  4.14it/s]loss: 2.031 | unlearn_loss: 1.805 | retain_loss: 0.2188 | param_change: 0.0001974\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.5\n",
      "Topic 0 frozen_forget_activations.norm= 21.5\n",
      "Topic 0 updated_retain_activations.norm= 22.5\n",
      "Topic 0 frozen_retain_activations.norm= 22.625\n",
      " 29%|████████████▎                             | 44/150 [00:11<00:26,  4.05it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 164, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.891 | unlearn_loss: 2.766 | retain_loss: 0.127 | param_change: 0.0001001\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.625\n",
      "Topic 0 frozen_forget_activations.norm= 24.75\n",
      "Topic 0 updated_retain_activations.norm= 25.25\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 30%|████████████▌                             | 45/150 [00:12<00:24,  4.20it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 339, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.703 | unlearn_loss: 1.383 | retain_loss: 0.3164 | param_change: 0.0001717\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 20.0\n",
      "Topic 0 frozen_forget_activations.norm= 20.125\n",
      "Topic 0 updated_retain_activations.norm= 21.75\n",
      "Topic 0 frozen_retain_activations.norm= 21.75\n",
      " 31%|████████████▉                             | 46/150 [00:12<00:28,  3.66it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 177, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.734 | unlearn_loss: 2.562 | retain_loss: 0.166 | param_change: 0.0001187\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.875\n",
      "Topic 0 frozen_forget_activations.norm= 23.875\n",
      "Topic 0 updated_retain_activations.norm= 21.375\n",
      "Topic 0 frozen_retain_activations.norm= 21.375\n",
      " 31%|█████████████▏                            | 47/150 [00:12<00:27,  3.77it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 206, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.375 | unlearn_loss: 2.219 | retain_loss: 0.1523 | param_change: 0.0001602\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.0\n",
      "Topic 0 updated_retain_activations.norm= 30.75\n",
      "Topic 0 frozen_retain_activations.norm= 30.75\n",
      " 32%|█████████████▍                            | 48/150 [00:12<00:25,  3.98it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 156, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.047 | unlearn_loss: 2.906 | retain_loss: 0.1426 | param_change: 0.000124\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 25.5\n",
      "Topic 0 frozen_forget_activations.norm= 25.625\n",
      "Topic 0 updated_retain_activations.norm= 25.25\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 33%|█████████████▋                            | 49/150 [00:13<00:24,  4.15it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 111, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 4.156 | unlearn_loss: 4.062 | retain_loss: 0.103 | param_change: 0.0001326\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 28.75\n",
      "Topic 0 frozen_forget_activations.norm= 28.75\n",
      "Topic 0 updated_retain_activations.norm= 35.0\n",
      "Topic 0 frozen_retain_activations.norm= 35.0\n",
      " 33%|██████████████                            | 50/150 [00:13<00:23,  4.30it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 209, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.375 | unlearn_loss: 2.188 | retain_loss: 0.1924 | param_change: 0.0002127\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.75\n",
      "Topic 0 frozen_forget_activations.norm= 22.875\n",
      "Topic 0 updated_retain_activations.norm= 31.375\n",
      "Topic 0 frozen_retain_activations.norm= 31.25\n",
      " 34%|██████████████▎                           | 51/150 [00:13<00:22,  4.38it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 240, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.172 | unlearn_loss: 1.93 | retain_loss: 0.249 | param_change: 0.0001907\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 22.0\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 21.75\n",
      "Topic 0 frozen_retain_activations.norm= 21.75\n",
      " 35%|██████████████▌                           | 52/150 [00:13<00:23,  4.22it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 79, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 5.875 | unlearn_loss: 5.594 | retain_loss: 0.2695 | param_change: 0.0002689\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 34.25\n",
      "Topic 0 frozen_forget_activations.norm= 34.0\n",
      "Topic 0 updated_retain_activations.norm= 29.75\n",
      "Topic 0 frozen_retain_activations.norm= 29.5\n",
      " 35%|██████████████▊                           | 53/150 [00:14<00:21,  4.45it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 264, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.016 | unlearn_loss: 1.766 | retain_loss: 0.252 | param_change: 0.0001783\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 21.625\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 22.125\n",
      "Topic 0 frozen_retain_activations.norm= 22.0\n",
      " 36%|███████████████                           | 54/150 [00:14<00:23,  4.16it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 226, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.281 | unlearn_loss: 2.047 | retain_loss: 0.2285 | param_change: 0.0002041\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.0\n",
      "Topic 0 frozen_forget_activations.norm= 22.25\n",
      "Topic 0 updated_retain_activations.norm= 27.0\n",
      "Topic 0 frozen_retain_activations.norm= 26.875\n",
      " 37%|███████████████▍                          | 55/150 [00:14<00:22,  4.21it/s]loss: 2.578 | unlearn_loss: 2.391 | retain_loss: 0.1846 | param_change: 0.0002213\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.25\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 26.25\n",
      "Topic 0 frozen_retain_activations.norm= 26.25\n",
      " 37%|███████████████▋                          | 56/150 [00:14<00:21,  4.30it/s]loss: 2.672 | unlearn_loss: 2.5 | retain_loss: 0.1729 | param_change: 0.0001173\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 22.625\n",
      "Topic 0 frozen_retain_activations.norm= 22.75\n",
      " 38%|███████████████▉                          | 57/150 [00:15<00:22,  4.19it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 150, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.234 | unlearn_loss: 3.016 | retain_loss: 0.2178 | param_change: 0.0001593\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 25.125\n",
      "Topic 0 frozen_forget_activations.norm= 25.25\n",
      "Topic 0 updated_retain_activations.norm= 24.125\n",
      "Topic 0 frozen_retain_activations.norm= 24.25\n",
      " 39%|████████████████▏                         | 58/150 [00:15<00:21,  4.30it/s]loss: 2.359 | unlearn_loss: 2.219 | retain_loss: 0.1357 | param_change: 0.0001516\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.0\n",
      "Topic 0 updated_retain_activations.norm= 26.0\n",
      "Topic 0 frozen_retain_activations.norm= 26.0\n",
      " 39%|████████████████▌                         | 59/150 [00:15<00:21,  4.33it/s]loss: 2.5 | unlearn_loss: 2.109 | retain_loss: 0.3887 | param_change: 0.000309\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 22.0\n",
      "Topic 0 frozen_forget_activations.norm= 22.125\n",
      "Topic 0 updated_retain_activations.norm= 24.75\n",
      "Topic 0 frozen_retain_activations.norm= 24.75\n",
      " 40%|████████████████▊                         | 60/150 [00:15<00:20,  4.33it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 135, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.531 | unlearn_loss: 3.344 | retain_loss: 0.1885 | param_change: 0.0001593\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 26.5\n",
      "Topic 0 frozen_forget_activations.norm= 26.5\n",
      "Topic 0 updated_retain_activations.norm= 27.75\n",
      "Topic 0 frozen_retain_activations.norm= 27.75\n",
      " 41%|█████████████████                         | 61/150 [00:15<00:19,  4.47it/s]loss: 2.625 | unlearn_loss: 2.516 | retain_loss: 0.1167 | param_change: 0.0001082\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.375\n",
      "Topic 0 frozen_forget_activations.norm= 23.5\n",
      "Topic 0 updated_retain_activations.norm= 24.0\n",
      "Topic 0 frozen_retain_activations.norm= 24.0\n",
      " 41%|█████████████████▎                        | 62/150 [00:16<00:19,  4.47it/s]loss: 2.156 | unlearn_loss: 1.93 | retain_loss: 0.2266 | param_change: 0.0001869\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.75\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 22.5\n",
      "Topic 0 frozen_retain_activations.norm= 22.5\n",
      " 42%|█████████████████▋                        | 63/150 [00:16<00:20,  4.33it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 102, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 4.562 | unlearn_loss: 4.406 | retain_loss: 0.1504 | param_change: 0.0001307\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 30.25\n",
      "Topic 0 frozen_forget_activations.norm= 30.25\n",
      "Topic 0 updated_retain_activations.norm= 23.25\n",
      "Topic 0 frozen_retain_activations.norm= 23.375\n",
      " 43%|█████████████████▉                        | 64/150 [00:16<00:19,  4.40it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 180, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.656 | unlearn_loss: 2.531 | retain_loss: 0.1309 | param_change: 0.000123\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.625\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 25.25\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 43%|██████████████████▏                       | 65/150 [00:16<00:19,  4.45it/s]loss: 2.953 | unlearn_loss: 2.797 | retain_loss: 0.1533 | param_change: 0.0001526\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.75\n",
      "Topic 0 frozen_forget_activations.norm= 24.75\n",
      "Topic 0 updated_retain_activations.norm= 25.875\n",
      "Topic 0 frozen_retain_activations.norm= 25.875\n",
      " 44%|██████████████████▍                       | 66/150 [00:17<00:18,  4.51it/s]loss: 1.992 | unlearn_loss: 1.836 | retain_loss: 0.1592 | param_change: 0.000123\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.0\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 22.5\n",
      "Topic 0 frozen_retain_activations.norm= 22.75\n",
      " 45%|██████████████████▊                       | 67/150 [00:17<00:19,  4.30it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 146, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.375 | unlearn_loss: 3.094 | retain_loss: 0.2891 | param_change: 0.0002098\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 25.5\n",
      "Topic 0 frozen_forget_activations.norm= 25.75\n",
      "Topic 0 updated_retain_activations.norm= 20.25\n",
      "Topic 0 frozen_retain_activations.norm= 20.375\n",
      " 45%|███████████████████                       | 68/150 [00:17<00:20,  3.94it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 184, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.578 | unlearn_loss: 2.469 | retain_loss: 0.1089 | param_change: 0.0001116\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 26.375\n",
      "Topic 0 frozen_retain_activations.norm= 26.375\n",
      " 46%|███████████████████▎                      | 69/150 [00:17<00:19,  4.12it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 281, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.828 | unlearn_loss: 1.68 | retain_loss: 0.1445 | param_change: 0.0001411\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.25\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 25.125\n",
      "Topic 0 frozen_retain_activations.norm= 25.125\n",
      " 47%|███████████████████▌                      | 70/150 [00:18<00:19,  4.03it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 223, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.375 | unlearn_loss: 2.047 | retain_loss: 0.3281 | param_change: 0.0002174\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 22.25\n",
      "Topic 0 frozen_forget_activations.norm= 22.375\n",
      "Topic 0 updated_retain_activations.norm= 23.875\n",
      "Topic 0 frozen_retain_activations.norm= 24.0\n",
      " 47%|███████████████████▉                      | 71/150 [00:18<00:19,  4.10it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 158, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.062 | unlearn_loss: 2.875 | retain_loss: 0.1914 | param_change: 0.0001459\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 25.125\n",
      "Topic 0 frozen_forget_activations.norm= 25.25\n",
      "Topic 0 updated_retain_activations.norm= 21.0\n",
      "Topic 0 frozen_retain_activations.norm= 21.0\n",
      " 48%|████████████████████▏                     | 72/150 [00:18<00:19,  4.00it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 228, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.219 | unlearn_loss: 2.031 | retain_loss: 0.1855 | param_change: 0.0001707\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.0\n",
      "Topic 0 frozen_forget_activations.norm= 22.25\n",
      "Topic 0 updated_retain_activations.norm= 26.25\n",
      "Topic 0 frozen_retain_activations.norm= 26.25\n",
      " 49%|████████████████████▍                     | 73/150 [00:18<00:18,  4.08it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 324, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.617 | unlearn_loss: 1.453 | retain_loss: 0.1641 | param_change: 0.0001507\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 20.5\n",
      "Topic 0 frozen_forget_activations.norm= 20.75\n",
      "Topic 0 updated_retain_activations.norm= 30.25\n",
      "Topic 0 frozen_retain_activations.norm= 30.25\n",
      " 49%|████████████████████▋                     | 74/150 [00:19<00:19,  3.99it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 163, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.109 | unlearn_loss: 2.781 | retain_loss: 0.334 | param_change: 0.0002499\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 24.75\n",
      "Topic 0 frozen_forget_activations.norm= 24.75\n",
      "Topic 0 updated_retain_activations.norm= 24.0\n",
      "Topic 0 frozen_retain_activations.norm= 24.25\n",
      " 50%|█████████████████████                     | 75/150 [00:19<00:18,  4.14it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 265, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.016 | unlearn_loss: 1.758 | retain_loss: 0.2637 | param_change: 0.0003929\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.25\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 21.0\n",
      "Topic 0 frozen_retain_activations.norm= 21.0\n",
      " 51%|█████████████████████▎                    | 76/150 [00:19<00:19,  3.85it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 207, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.5 | unlearn_loss: 2.203 | retain_loss: 0.3047 | param_change: 0.0001955\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 22.875\n",
      "Topic 0 frozen_forget_activations.norm= 23.0\n",
      "Topic 0 updated_retain_activations.norm= 21.75\n",
      "Topic 0 frozen_retain_activations.norm= 21.75\n",
      " 51%|█████████████████████▌                    | 77/150 [00:19<00:18,  3.91it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 179, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.672 | unlearn_loss: 2.531 | retain_loss: 0.1396 | param_change: 0.0001154\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.5\n",
      "Topic 0 frozen_forget_activations.norm= 23.625\n",
      "Topic 0 updated_retain_activations.norm= 23.125\n",
      "Topic 0 frozen_retain_activations.norm= 23.125\n",
      " 52%|█████████████████████▊                    | 78/150 [00:20<00:17,  4.03it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 152, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.234 | unlearn_loss: 2.984 | retain_loss: 0.252 | param_change: 0.0001688\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 25.75\n",
      "Topic 0 frozen_forget_activations.norm= 25.875\n",
      "Topic 0 updated_retain_activations.norm= 23.125\n",
      "Topic 0 frozen_retain_activations.norm= 23.25\n",
      " 53%|██████████████████████                    | 79/150 [00:20<00:17,  4.13it/s]loss: 2.656 | unlearn_loss: 2.469 | retain_loss: 0.1807 | param_change: 0.0001173\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.125\n",
      "Topic 0 frozen_forget_activations.norm= 24.25\n",
      "Topic 0 updated_retain_activations.norm= 21.5\n",
      "Topic 0 frozen_retain_activations.norm= 21.625\n",
      " 53%|██████████████████████▍                   | 80/150 [00:20<00:17,  4.03it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 188, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.25 | unlearn_loss: 2.422 | retain_loss: 0.8281 | param_change: 0.000824\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 23.5\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 20.5\n",
      "Topic 0 frozen_retain_activations.norm= 20.125\n",
      " 54%|██████████████████████▋                   | 81/150 [00:21<00:20,  3.42it/s]loss: 3.062 | unlearn_loss: 2.906 | retain_loss: 0.1504 | param_change: 0.0001307\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 25.25\n",
      "Topic 0 frozen_forget_activations.norm= 25.5\n",
      "Topic 0 updated_retain_activations.norm= 27.5\n",
      "Topic 0 frozen_retain_activations.norm= 27.625\n",
      " 55%|██████████████████████▉                   | 82/150 [00:21<00:18,  3.74it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 192, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.562 | unlearn_loss: 2.375 | retain_loss: 0.1855 | param_change: 0.000165\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.5\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 25.0\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 55%|███████████████████████▏                  | 83/150 [00:21<00:16,  3.94it/s]loss: 2.219 | unlearn_loss: 2.047 | retain_loss: 0.1777 | param_change: 0.0001345\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.0\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 25.75\n",
      "Topic 0 frozen_retain_activations.norm= 25.75\n",
      " 56%|███████████████████████▌                  | 84/150 [00:21<00:16,  4.04it/s]loss: 3.297 | unlearn_loss: 3.094 | retain_loss: 0.2002 | param_change: 0.0001497\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 26.0\n",
      "Topic 0 frozen_forget_activations.norm= 25.875\n",
      "Topic 0 updated_retain_activations.norm= 23.75\n",
      "Topic 0 frozen_retain_activations.norm= 23.75\n",
      " 57%|███████████████████████▊                  | 85/150 [00:21<00:15,  4.19it/s]loss: 2.453 | unlearn_loss: 2.109 | retain_loss: 0.3457 | param_change: 0.0002375\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 22.25\n",
      "Topic 0 frozen_forget_activations.norm= 22.5\n",
      "Topic 0 updated_retain_activations.norm= 24.875\n",
      "Topic 0 frozen_retain_activations.norm= 24.875\n",
      " 57%|████████████████████████                  | 86/150 [00:22<00:15,  4.23it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 166, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.891 | unlearn_loss: 2.734 | retain_loss: 0.1611 | param_change: 0.0001249\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.25\n",
      "Topic 0 frozen_forget_activations.norm= 24.5\n",
      "Topic 0 updated_retain_activations.norm= 24.125\n",
      "Topic 0 frozen_retain_activations.norm= 24.125\n",
      " 58%|████████████████████████▎                 | 87/150 [00:22<00:14,  4.32it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 215, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.312 | unlearn_loss: 2.125 | retain_loss: 0.1904 | param_change: 0.0001621\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.75\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 25.25\n",
      "Topic 0 frozen_retain_activations.norm= 25.125\n",
      " 59%|████████████████████████▋                 | 88/150 [00:22<00:14,  4.33it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 169, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3 | unlearn_loss: 2.688 | retain_loss: 0.3047 | param_change: 0.0001717\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 24.375\n",
      "Topic 0 frozen_forget_activations.norm= 24.375\n",
      "Topic 0 updated_retain_activations.norm= 22.125\n",
      "Topic 0 frozen_retain_activations.norm= 22.25\n",
      " 59%|████████████████████████▉                 | 89/150 [00:22<00:14,  4.33it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 129, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.75 | unlearn_loss: 3.5 | retain_loss: 0.2471 | param_change: 0.0001841\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 27.75\n",
      "Topic 0 frozen_forget_activations.norm= 27.75\n",
      "Topic 0 updated_retain_activations.norm= 27.0\n",
      "Topic 0 frozen_retain_activations.norm= 27.0\n",
      " 60%|█████████████████████████▏                | 90/150 [00:23<00:13,  4.45it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 361, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.453 | unlearn_loss: 1.305 | retain_loss: 0.1514 | param_change: 0.0001383\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 20.125\n",
      "Topic 0 frozen_forget_activations.norm= 20.25\n",
      "Topic 0 updated_retain_activations.norm= 24.75\n",
      "Topic 0 frozen_retain_activations.norm= 24.75\n",
      " 61%|█████████████████████████▍                | 91/150 [00:23<00:14,  4.14it/s]loss: 3.078 | unlearn_loss: 2.875 | retain_loss: 0.1982 | param_change: 0.0001488\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 25.25\n",
      "Topic 0 frozen_forget_activations.norm= 25.25\n",
      "Topic 0 updated_retain_activations.norm= 23.5\n",
      "Topic 0 frozen_retain_activations.norm= 23.5\n",
      " 61%|█████████████████████████▊                | 92/150 [00:23<00:13,  4.24it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 258, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.016 | unlearn_loss: 1.797 | retain_loss: 0.2148 | param_change: 0.0001659\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.25\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 34.5\n",
      "Topic 0 frozen_retain_activations.norm= 34.5\n",
      " 62%|██████████████████████████                | 93/150 [00:23<00:13,  4.19it/s]loss: 2.078 | unlearn_loss: 1.648 | retain_loss: 0.4238 | param_change: 0.0001755\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 21.0\n",
      "Topic 0 frozen_forget_activations.norm= 21.0\n",
      "Topic 0 updated_retain_activations.norm= 288.0\n",
      "Topic 0 frozen_retain_activations.norm= 290.0\n",
      " 63%|██████████████████████████▎               | 94/150 [00:24<00:14,  3.85it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 103, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 4.75 | unlearn_loss: 4.375 | retain_loss: 0.3809 | param_change: 0.0001926\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 30.0\n",
      "Topic 0 frozen_forget_activations.norm= 30.0\n",
      "Topic 0 updated_retain_activations.norm= 22.25\n",
      "Topic 0 frozen_retain_activations.norm= 22.25\n",
      " 63%|██████████████████████████▌               | 95/150 [00:24<00:13,  4.02it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 161, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 4.531 | unlearn_loss: 2.812 | retain_loss: 1.711 | param_change: 0.0004272\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.98828125\n",
      "Topic 0 updated_forget_activations.norm= 25.0\n",
      "Topic 0 frozen_forget_activations.norm= 25.0\n",
      "Topic 0 updated_retain_activations.norm= 21.75\n",
      "Topic 0 frozen_retain_activations.norm= 22.0\n",
      " 64%|██████████████████████████▉               | 96/150 [00:24<00:13,  4.09it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 282, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.836 | unlearn_loss: 1.648 | retain_loss: 0.1885 | param_change: 0.0001554\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 20.75\n",
      "Topic 0 frozen_forget_activations.norm= 20.75\n",
      "Topic 0 updated_retain_activations.norm= 21.875\n",
      "Topic 0 frozen_retain_activations.norm= 22.0\n",
      " 65%|███████████████████████████▏              | 97/150 [00:24<00:13,  3.92it/s]loss: 2.938 | unlearn_loss: 2.594 | retain_loss: 0.3516 | param_change: 0.0001822\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 23.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 22.25\n",
      "Topic 0 frozen_retain_activations.norm= 22.25\n",
      " 65%|███████████████████████████▍              | 98/150 [00:25<00:12,  4.03it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 269, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.977 | unlearn_loss: 1.734 | retain_loss: 0.2402 | param_change: 0.0002146\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.25\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 26.5\n",
      "Topic 0 frozen_retain_activations.norm= 26.375\n",
      " 66%|███████████████████████████▋              | 99/150 [00:25<00:12,  3.99it/s]loss: 2.891 | unlearn_loss: 2.766 | retain_loss: 0.1299 | param_change: 0.0001125\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.75\n",
      "Topic 0 frozen_forget_activations.norm= 24.875\n",
      "Topic 0 updated_retain_activations.norm= 23.5\n",
      "Topic 0 frozen_retain_activations.norm= 23.5\n",
      " 67%|███████████████████████████▎             | 100/150 [00:25<00:12,  4.10it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 154, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.641 | unlearn_loss: 2.938 | retain_loss: 0.6992 | param_change: 0.0002899\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 25.0\n",
      "Topic 0 frozen_forget_activations.norm= 25.0\n",
      "Topic 0 updated_retain_activations.norm= 24.25\n",
      "Topic 0 frozen_retain_activations.norm= 24.0\n",
      " 67%|███████████████████████████▌             | 101/150 [00:25<00:11,  4.23it/s]loss: 2.5 | unlearn_loss: 2.297 | retain_loss: 0.2012 | param_change: 0.0001488\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 24.375\n",
      "Topic 0 frozen_retain_activations.norm= 24.5\n",
      " 68%|███████████████████████████▉             | 102/150 [00:25<00:11,  4.27it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 155, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.203 | unlearn_loss: 2.922 | retain_loss: 0.2773 | param_change: 0.0001574\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 25.0\n",
      "Topic 0 frozen_forget_activations.norm= 25.0\n",
      "Topic 0 updated_retain_activations.norm= 22.25\n",
      "Topic 0 frozen_retain_activations.norm= 22.25\n",
      " 69%|████████████████████████████▏            | 103/150 [00:26<00:11,  4.27it/s]loss: 2.531 | unlearn_loss: 2.344 | retain_loss: 0.1953 | param_change: 0.0001364\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.25\n",
      "Topic 0 frozen_forget_activations.norm= 23.125\n",
      "Topic 0 updated_retain_activations.norm= 21.5\n",
      "Topic 0 frozen_retain_activations.norm= 21.625\n",
      " 69%|████████████████████████████▍            | 104/150 [00:26<00:11,  4.16it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 245, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.75 | unlearn_loss: 1.875 | retain_loss: 0.8828 | param_change: 0.0004101\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 21.75\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 27.25\n",
      "Topic 0 frozen_retain_activations.norm= 27.0\n",
      " 70%|████████████████████████████▋            | 105/150 [00:26<00:10,  4.15it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 323, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.703 | unlearn_loss: 1.438 | retain_loss: 0.2637 | param_change: 0.0001831\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 20.0\n",
      "Topic 0 frozen_forget_activations.norm= 20.0\n",
      "Topic 0 updated_retain_activations.norm= 28.125\n",
      "Topic 0 frozen_retain_activations.norm= 28.125\n",
      " 71%|████████████████████████████▉            | 106/150 [00:26<00:10,  4.03it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 230, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.281 | unlearn_loss: 2.016 | retain_loss: 0.2637 | param_change: 0.0001612\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 22.375\n",
      "Topic 0 frozen_forget_activations.norm= 22.375\n",
      "Topic 0 updated_retain_activations.norm= 22.75\n",
      "Topic 0 frozen_retain_activations.norm= 22.75\n",
      " 71%|█████████████████████████████▏           | 107/150 [00:27<00:10,  4.03it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 165, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.938 | unlearn_loss: 2.75 | retain_loss: 0.1816 | param_change: 0.0001564\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.75\n",
      "Topic 0 frozen_forget_activations.norm= 24.75\n",
      "Topic 0 updated_retain_activations.norm= 26.5\n",
      "Topic 0 frozen_retain_activations.norm= 26.5\n",
      " 72%|█████████████████████████████▌           | 108/150 [00:27<00:10,  4.20it/s]loss: 2.672 | unlearn_loss: 2.438 | retain_loss: 0.2314 | param_change: 0.0002022\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.5\n",
      "Topic 0 frozen_forget_activations.norm= 23.625\n",
      "Topic 0 updated_retain_activations.norm= 27.25\n",
      "Topic 0 frozen_retain_activations.norm= 27.125\n",
      " 73%|█████████████████████████████▊           | 109/150 [00:27<00:09,  4.31it/s]loss: 2.328 | unlearn_loss: 1.891 | retain_loss: 0.4414 | param_change: 0.0001984\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 21.75\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 22.5\n",
      "Topic 0 frozen_retain_activations.norm= 22.625\n",
      " 73%|██████████████████████████████           | 110/150 [00:27<00:09,  4.19it/s]loss: 1.898 | unlearn_loss: 1.75 | retain_loss: 0.1465 | param_change: 0.0001497\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.125\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 34.25\n",
      "Topic 0 frozen_retain_activations.norm= 34.25\n",
      " 74%|██████████████████████████████▎          | 111/150 [00:28<00:09,  4.15it/s]loss: 2.516 | unlearn_loss: 2.297 | retain_loss: 0.2246 | param_change: 0.0001802\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.125\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 24.5\n",
      "Topic 0 frozen_retain_activations.norm= 24.625\n",
      " 75%|██████████████████████████████▌          | 112/150 [00:28<00:09,  4.21it/s]loss: 3.141 | unlearn_loss: 2.938 | retain_loss: 0.2061 | param_change: 0.0001621\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 25.0\n",
      "Topic 0 frozen_forget_activations.norm= 25.125\n",
      "Topic 0 updated_retain_activations.norm= 25.625\n",
      "Topic 0 frozen_retain_activations.norm= 25.625\n",
      " 75%|██████████████████████████████▉          | 113/150 [00:28<00:08,  4.33it/s]loss: 2.656 | unlearn_loss: 2.406 | retain_loss: 0.2559 | param_change: 0.0001583\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 23.5\n",
      "Topic 0 frozen_forget_activations.norm= 23.625\n",
      "Topic 0 updated_retain_activations.norm= 28.0\n",
      "Topic 0 frozen_retain_activations.norm= 28.0\n",
      " 76%|███████████████████████████████▏         | 114/150 [00:28<00:08,  4.43it/s]loss: 2.844 | unlearn_loss: 2.562 | retain_loss: 0.2891 | param_change: 0.0001659\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.0\n",
      "Topic 0 frozen_forget_activations.norm= 24.25\n",
      "Topic 0 updated_retain_activations.norm= 23.5\n",
      "Topic 0 frozen_retain_activations.norm= 23.5\n",
      " 77%|███████████████████████████████▍         | 115/150 [00:29<00:07,  4.40it/s]loss: 3.109 | unlearn_loss: 2.812 | retain_loss: 0.2949 | param_change: 0.0001888\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.5\n",
      "Topic 0 frozen_forget_activations.norm= 24.5\n",
      "Topic 0 updated_retain_activations.norm= 21.875\n",
      "Topic 0 frozen_retain_activations.norm= 22.0\n",
      " 77%|███████████████████████████████▋         | 116/150 [00:29<00:07,  4.34it/s]loss: 3 | unlearn_loss: 2.5 | retain_loss: 0.5078 | param_change: 0.0001812\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 23.75\n",
      "Topic 0 frozen_forget_activations.norm= 24.0\n",
      "Topic 0 updated_retain_activations.norm= 22.25\n",
      "Topic 0 frozen_retain_activations.norm= 22.375\n",
      " 78%|███████████████████████████████▉         | 117/150 [00:29<00:07,  4.33it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 193, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.797 | unlearn_loss: 2.359 | retain_loss: 0.4434 | param_change: 0.0002251\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 23.25\n",
      "Topic 0 frozen_forget_activations.norm= 23.5\n",
      "Topic 0 updated_retain_activations.norm= 19.75\n",
      "Topic 0 frozen_retain_activations.norm= 19.875\n",
      " 79%|████████████████████████████████▎        | 118/150 [00:29<00:07,  4.02it/s]loss: 3 | unlearn_loss: 2.812 | retain_loss: 0.1846 | param_change: 0.0001802\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.25\n",
      "Topic 0 frozen_forget_activations.norm= 24.5\n",
      "Topic 0 updated_retain_activations.norm= 32.25\n",
      "Topic 0 frozen_retain_activations.norm= 32.25\n",
      " 79%|████████████████████████████████▌        | 119/150 [00:30<00:07,  4.24it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 131, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.781 | unlearn_loss: 3.438 | retain_loss: 0.3418 | param_change: 0.0002127\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 26.75\n",
      "Topic 0 frozen_forget_activations.norm= 26.75\n",
      "Topic 0 updated_retain_activations.norm= 22.5\n",
      "Topic 0 frozen_retain_activations.norm= 22.75\n",
      " 80%|████████████████████████████████▊        | 120/150 [00:30<00:06,  4.30it/s]loss: 2.578 | unlearn_loss: 2.344 | retain_loss: 0.2393 | param_change: 0.0002413\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 28.75\n",
      "Topic 0 frozen_retain_activations.norm= 29.0\n",
      " 81%|█████████████████████████████████        | 121/150 [00:30<00:06,  4.38it/s]loss: 2.625 | unlearn_loss: 2.469 | retain_loss: 0.1514 | param_change: 0.0001206\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.625\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 24.625\n",
      "Topic 0 frozen_retain_activations.norm= 24.5\n",
      " 81%|█████████████████████████████████▎       | 122/150 [00:30<00:06,  4.41it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 168, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.922 | unlearn_loss: 2.703 | retain_loss: 0.2139 | param_change: 0.0001812\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.0\n",
      "Topic 0 frozen_forget_activations.norm= 24.0\n",
      "Topic 0 updated_retain_activations.norm= 24.5\n",
      "Topic 0 frozen_retain_activations.norm= 24.5\n",
      " 82%|█████████████████████████████████▌       | 123/150 [00:30<00:06,  4.46it/s]loss: 2.391 | unlearn_loss: 2.219 | retain_loss: 0.1777 | param_change: 0.0001335\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.875\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 27.25\n",
      "Topic 0 frozen_retain_activations.norm= 27.25\n",
      " 83%|█████████████████████████████████▉       | 124/150 [00:31<00:05,  4.47it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 235, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.219 | unlearn_loss: 1.969 | retain_loss: 0.249 | param_change: 0.0001497\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.0\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 23.5\n",
      "Topic 0 frozen_retain_activations.norm= 23.5\n",
      " 83%|██████████████████████████████████▏      | 125/150 [00:31<00:05,  4.34it/s]loss: 2.875 | unlearn_loss: 2.688 | retain_loss: 0.1816 | param_change: 0.0001564\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.25\n",
      "Topic 0 frozen_forget_activations.norm= 24.25\n",
      "Topic 0 updated_retain_activations.norm= 26.25\n",
      "Topic 0 frozen_retain_activations.norm= 26.25\n",
      " 84%|██████████████████████████████████▍      | 126/150 [00:31<00:05,  4.42it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 122, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 4.062 | unlearn_loss: 3.703 | retain_loss: 0.3555 | param_change: 0.0002203\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 28.0\n",
      "Topic 0 frozen_forget_activations.norm= 28.0\n",
      "Topic 0 updated_retain_activations.norm= 21.625\n",
      "Topic 0 frozen_retain_activations.norm= 21.5\n",
      " 85%|██████████████████████████████████▋      | 127/150 [00:31<00:05,  4.36it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 232, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.125 | unlearn_loss: 1.992 | retain_loss: 0.1396 | param_change: 0.0001211\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.75\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 26.0\n",
      "Topic 0 frozen_retain_activations.norm= 26.0\n",
      " 85%|██████████████████████████████████▉      | 128/150 [00:32<00:05,  4.32it/s]loss: 2.938 | unlearn_loss: 2.734 | retain_loss: 0.208 | param_change: 0.0001574\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.75\n",
      "Topic 0 frozen_forget_activations.norm= 25.0\n",
      "Topic 0 updated_retain_activations.norm= 27.625\n",
      "Topic 0 frozen_retain_activations.norm= 27.75\n",
      " 86%|███████████████████████████████████▎     | 129/150 [00:32<00:04,  4.43it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 218, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.25 | unlearn_loss: 2.094 | retain_loss: 0.1611 | param_change: 0.0001364\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.5\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 24.75\n",
      "Topic 0 frozen_retain_activations.norm= 24.875\n",
      " 87%|███████████████████████████████████▌     | 130/150 [00:32<00:04,  4.40it/s]loss: 2.797 | unlearn_loss: 2.469 | retain_loss: 0.334 | param_change: 0.0002069\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 23.625\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 25.25\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 87%|███████████████████████████████████▊     | 131/150 [00:32<00:04,  4.44it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 112, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 4.281 | unlearn_loss: 4.031 | retain_loss: 0.249 | param_change: 0.0001984\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 29.25\n",
      "Topic 0 frozen_forget_activations.norm= 29.375\n",
      "Topic 0 updated_retain_activations.norm= 26.375\n",
      "Topic 0 frozen_retain_activations.norm= 26.5\n",
      " 88%|████████████████████████████████████     | 132/150 [00:32<00:03,  4.55it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 329, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.531 | unlearn_loss: 1.414 | retain_loss: 0.1201 | param_change: 9.871e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 20.25\n",
      "Topic 0 frozen_forget_activations.norm= 20.375\n",
      "Topic 0 updated_retain_activations.norm= 27.0\n",
      "Topic 0 frozen_retain_activations.norm= 27.125\n",
      " 89%|████████████████████████████████████▎    | 133/150 [00:33<00:03,  4.25it/s]loss: 2.953 | unlearn_loss: 2.406 | retain_loss: 0.5508 | param_change: 0.000515\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 23.5\n",
      "Topic 0 frozen_forget_activations.norm= 23.5\n",
      "Topic 0 updated_retain_activations.norm= 21.5\n",
      "Topic 0 frozen_retain_activations.norm= 21.625\n",
      " 89%|████████████████████████████████████▋    | 134/150 [00:33<00:03,  4.18it/s]loss: 2.422 | unlearn_loss: 2.266 | retain_loss: 0.1582 | param_change: 0.0001554\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.0\n",
      "Topic 0 updated_retain_activations.norm= 28.75\n",
      "Topic 0 frozen_retain_activations.norm= 28.625\n",
      " 90%|████████████████████████████████████▉    | 135/150 [00:33<00:03,  4.28it/s]loss: 2.422 | unlearn_loss: 2.188 | retain_loss: 0.2344 | param_change: 0.0001583\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.75\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 23.25\n",
      "Topic 0 frozen_retain_activations.norm= 23.25\n",
      " 91%|█████████████████████████████████████▏   | 136/150 [00:33<00:03,  4.25it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 224, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.219 | unlearn_loss: 2.047 | retain_loss: 0.165 | param_change: 0.0001602\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.25\n",
      "Topic 0 frozen_forget_activations.norm= 22.125\n",
      "Topic 0 updated_retain_activations.norm= 29.875\n",
      "Topic 0 frozen_retain_activations.norm= 29.75\n",
      " 91%|█████████████████████████████████████▍   | 137/150 [00:34<00:03,  4.32it/s]loss: 3.047 | unlearn_loss: 2.734 | retain_loss: 0.3066 | param_change: 0.0001945\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 24.5\n",
      "Topic 0 frozen_forget_activations.norm= 24.5\n",
      "Topic 0 updated_retain_activations.norm= 20.75\n",
      "Topic 0 frozen_retain_activations.norm= 20.5\n",
      " 92%|█████████████████████████████████████▋   | 138/150 [00:34<00:02,  4.13it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 250, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.281 | unlearn_loss: 1.836 | retain_loss: 0.4492 | param_change: 0.0004253\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 21.25\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 26.0\n",
      "Topic 0 frozen_retain_activations.norm= 25.875\n",
      " 93%|█████████████████████████████████████▉   | 139/150 [00:34<00:02,  4.12it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 138, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.438 | unlearn_loss: 3.281 | retain_loss: 0.1572 | param_change: 0.0001307\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 26.5\n",
      "Topic 0 frozen_forget_activations.norm= 26.5\n",
      "Topic 0 updated_retain_activations.norm= 23.25\n",
      "Topic 0 frozen_retain_activations.norm= 23.25\n",
      " 93%|██████████████████████████████████████▎  | 140/150 [00:34<00:02,  4.25it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 216, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.328 | unlearn_loss: 2.125 | retain_loss: 0.2012 | param_change: 0.0001564\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.5\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 25.25\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 94%|██████████████████████████████████████▌  | 141/150 [00:35<00:02,  4.28it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 311, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.969 | unlearn_loss: 1.516 | retain_loss: 0.4492 | param_change: 0.0002384\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 20.75\n",
      "Topic 0 frozen_forget_activations.norm= 20.75\n",
      "Topic 0 updated_retain_activations.norm= 25.375\n",
      "Topic 0 frozen_retain_activations.norm= 25.5\n",
      " 95%|██████████████████████████████████████▊  | 142/150 [00:35<00:01,  4.11it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 331, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.578 | unlearn_loss: 1.406 | retain_loss: 0.1729 | param_change: 0.0001535\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 20.125\n",
      "Topic 0 frozen_forget_activations.norm= 20.25\n",
      "Topic 0 updated_retain_activations.norm= 26.125\n",
      "Topic 0 frozen_retain_activations.norm= 26.25\n",
      " 95%|███████████████████████████████████████  | 143/150 [00:35<00:01,  3.96it/s]loss: 2.75 | unlearn_loss: 2.219 | retain_loss: 0.5234 | param_change: 0.0003452\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 22.625\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 24.5\n",
      "Topic 0 frozen_retain_activations.norm= 24.5\n",
      " 96%|███████████████████████████████████████▎ | 144/150 [00:35<00:01,  4.07it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 115, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 4.156 | unlearn_loss: 3.922 | retain_loss: 0.2256 | param_change: 0.0001488\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 28.875\n",
      "Topic 0 frozen_forget_activations.norm= 29.0\n",
      "Topic 0 updated_retain_activations.norm= 22.5\n",
      "Topic 0 frozen_retain_activations.norm= 22.5\n",
      " 97%|███████████████████████████████████████▋ | 145/150 [00:36<00:01,  4.19it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 171, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.938 | unlearn_loss: 2.656 | retain_loss: 0.2793 | param_change: 0.0002031\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.25\n",
      "Topic 0 frozen_forget_activations.norm= 24.5\n",
      "Topic 0 updated_retain_activations.norm= 25.25\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 97%|███████████████████████████████████████▉ | 146/150 [00:36<00:00,  4.30it/s]loss: 2.656 | unlearn_loss: 2.297 | retain_loss: 0.3594 | param_change: 0.0002537\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 23.125\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 21.0\n",
      "Topic 0 frozen_retain_activations.norm= 21.125\n",
      " 98%|████████████████████████████████████████▏| 147/150 [00:36<00:00,  4.10it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 147, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.297 | unlearn_loss: 3.078 | retain_loss: 0.2197 | param_change: 0.0001621\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 25.75\n",
      "Topic 0 frozen_forget_activations.norm= 25.875\n",
      "Topic 0 updated_retain_activations.norm= 24.0\n",
      "Topic 0 frozen_retain_activations.norm= 24.0\n",
      " 99%|████████████████████████████████████████▍| 148/150 [00:36<00:00,  4.23it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 318, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.633 | unlearn_loss: 1.469 | retain_loss: 0.167 | param_change: 0.0001535\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 20.0\n",
      "Topic 0 frozen_forget_activations.norm= 20.0\n",
      "Topic 0 updated_retain_activations.norm= 24.5\n",
      "Topic 0 frozen_retain_activations.norm= 24.5\n",
      " 99%|████████████████████████████████████████▋| 149/150 [00:37<00:00,  4.06it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 210, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.438 | unlearn_loss: 2.172 | retain_loss: 0.2734 | param_change: 0.0001612\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 22.5\n",
      "Topic 0 frozen_forget_activations.norm= 22.5\n",
      "Topic 0 updated_retain_activations.norm= 20.25\n",
      "Topic 0 frozen_retain_activations.norm= 20.25\n",
      "100%|█████████████████████████████████████████| 150/150 [00:37<00:00,  4.02it/s]\n",
      "Saved model to models/alpaca_rmu_alpha_1000\n"
     ]
    }
   ],
   "source": [
    "!python3 -m rmu.unlearn --model_name PKU-Alignment/alpaca-7b-reproduced --max_num_batches 150 --batch_size=2 --retain_corpora SafeRLHF-corpora/safe_train_sampled --forget_corpora SafeRLHF-corpora/Privacy_Violation_train --layer_id 7 --steering_coeffs 6.5 --alpha 1200 --lr 1e-4 --seed 42 --output_dir models/alpaca_rmu_alpha_1000 --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [01:23<00:00, 11.89s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [00:55<00:00,  7.97s/it]\n",
      "====rmu Config====\n",
      "model_name_or_path=PKU-Alignment/alpaca-7b-reproduced\n",
      "module_str={model_name}.model.layers[{layer_id}]\n",
      "output_dir=models/alpaca_rmu_alpha_10\n",
      "retain_corpora=['SafeRLHF-corpora/safe_train_sampled']\n",
      "forget_corpora=['SafeRLHF-corpora/Privacy_Violation_train']\n",
      "alpha=[10.0]\n",
      "steering_coeffs=6.5\n",
      "lr=0.0001\n",
      "min_len=0\n",
      "max_len=2000\n",
      "batch_size=2\n",
      "max_num_batches=150\n",
      "layer_id=7\n",
      "layer_ids=[5, 6, 7]\n",
      "param_ids=[6]\n",
      "seed=42\n",
      "verbose=True\n",
      "steering_coeff_list=[6.5]\n",
      "=====\n",
      "/home/hice1/jli928/.conda/envs/model-unlearning/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "======= Epoch 0 =======\n",
      "  0%|                                                   | 0/150 [00:00<?, ?it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 185, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.453 | unlearn_loss: 2.453 | retain_loss: 0 | param_change: 1.982e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.125\n",
      "Topic 0 frozen_forget_activations.norm= 23.125\n",
      "Topic 0 updated_retain_activations.norm= 23.5\n",
      "Topic 0 frozen_retain_activations.norm= 23.5\n",
      "  1%|▎                                          | 1/150 [00:01<03:11,  1.29s/it]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 170, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.672 | unlearn_loss: 2.672 | retain_loss: 8.345e-05 | param_change: 2.116e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.375\n",
      "Topic 0 frozen_forget_activations.norm= 24.5\n",
      "Topic 0 updated_retain_activations.norm= 19.5\n",
      "Topic 0 frozen_retain_activations.norm= 19.5\n",
      "  1%|▌                                          | 2/150 [00:01<01:44,  1.42it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 199, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.297 | unlearn_loss: 2.297 | retain_loss: 0.0002079 | param_change: 1.781e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.625\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 25.25\n",
      "Topic 0 frozen_retain_activations.norm= 25.5\n",
      "  2%|▊                                          | 3/150 [00:01<01:11,  2.05it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 251, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.836 | unlearn_loss: 1.836 | retain_loss: 0.0003242 | param_change: 1.84e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.5\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 23.0\n",
      "Topic 0 frozen_retain_activations.norm= 23.0\n",
      "  3%|█▏                                         | 4/150 [00:02<00:58,  2.51it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 190, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.391 | unlearn_loss: 2.391 | retain_loss: 0.0005798 | param_change: 1.892e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 23.75\n",
      "Topic 0 frozen_retain_activations.norm= 24.0\n",
      "  3%|█▍                                         | 5/150 [00:02<00:48,  2.98it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 243, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.891 | unlearn_loss: 1.891 | retain_loss: 0.0007591 | param_change: 1.855e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.5\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 24.0\n",
      "Topic 0 frozen_retain_activations.norm= 24.25\n",
      "  4%|█▋                                         | 6/150 [00:02<00:44,  3.27it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 293, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.594 | unlearn_loss: 1.594 | retain_loss: 0.0008736 | param_change: 1.907e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 20.25\n",
      "Topic 0 frozen_forget_activations.norm= 20.625\n",
      "Topic 0 updated_retain_activations.norm= 24.25\n",
      "Topic 0 frozen_retain_activations.norm= 24.5\n",
      "  5%|██                                         | 7/150 [00:02<00:42,  3.40it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 244, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.875 | unlearn_loss: 1.875 | retain_loss: 0.001602 | param_change: 2.369e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.25\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 24.75\n",
      "Topic 0 frozen_retain_activations.norm= 25.125\n",
      "  5%|██▎                                        | 8/150 [00:03<00:39,  3.58it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 162, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.797 | unlearn_loss: 2.797 | retain_loss: 0.002106 | param_change: 2.488e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.5\n",
      "Topic 0 frozen_forget_activations.norm= 25.125\n",
      "Topic 0 updated_retain_activations.norm= 25.125\n",
      "Topic 0 frozen_retain_activations.norm= 25.625\n",
      "  6%|██▌                                        | 9/150 [00:03<00:36,  3.84it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 219, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.078 | unlearn_loss: 2.078 | retain_loss: 0.002258 | param_change: 2.22e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.875\n",
      "Topic 0 frozen_forget_activations.norm= 22.5\n",
      "Topic 0 updated_retain_activations.norm= 21.75\n",
      "Topic 0 frozen_retain_activations.norm= 22.375\n",
      "  7%|██▊                                       | 10/150 [00:03<00:35,  3.90it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 151, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3 | unlearn_loss: 3 | retain_loss: 0.002365 | param_change: 2.533e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 25.0\n",
      "Topic 0 frozen_forget_activations.norm= 25.75\n",
      "Topic 0 updated_retain_activations.norm= 24.25\n",
      "Topic 0 frozen_retain_activations.norm= 24.75\n",
      "  7%|███                                       | 11/150 [00:03<00:34,  4.08it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 144, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.141 | unlearn_loss: 3.141 | retain_loss: 0.002258 | param_change: 2.22e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 25.0\n",
      "Topic 0 frozen_forget_activations.norm= 25.75\n",
      "Topic 0 updated_retain_activations.norm= 35.0\n",
      "Topic 0 frozen_retain_activations.norm= 35.5\n",
      "  8%|███▎                                      | 12/150 [00:04<00:33,  4.06it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 255, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.797 | unlearn_loss: 1.797 | retain_loss: 0.002457 | param_change: 2.19e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 20.75\n",
      "Topic 0 frozen_forget_activations.norm= 21.5\n",
      "Topic 0 updated_retain_activations.norm= 21.875\n",
      "Topic 0 frozen_retain_activations.norm= 22.5\n",
      "  9%|███▋                                      | 13/150 [00:04<00:34,  3.99it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 283, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.641 | unlearn_loss: 1.641 | retain_loss: 0.003632 | param_change: 2.608e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 20.25\n",
      "Topic 0 frozen_forget_activations.norm= 21.125\n",
      "Topic 0 updated_retain_activations.norm= 21.5\n",
      "Topic 0 frozen_retain_activations.norm= 22.25\n",
      "  9%|███▉                                      | 14/150 [00:04<00:35,  3.86it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 141, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.203 | unlearn_loss: 3.203 | retain_loss: 0.003021 | param_change: 2.593e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 25.0\n",
      "Topic 0 frozen_forget_activations.norm= 25.75\n",
      "Topic 0 updated_retain_activations.norm= 25.5\n",
      "Topic 0 frozen_retain_activations.norm= 26.0\n",
      " 10%|████▏                                     | 15/150 [00:04<00:33,  4.07it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 181, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.516 | unlearn_loss: 2.516 | retain_loss: 0.003662 | param_change: 2.429e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.125\n",
      "Topic 0 frozen_forget_activations.norm= 24.0\n",
      "Topic 0 updated_retain_activations.norm= 21.75\n",
      "Topic 0 frozen_retain_activations.norm= 22.5\n",
      " 11%|████▍                                     | 16/150 [00:04<00:32,  4.13it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 220, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.078 | unlearn_loss: 2.078 | retain_loss: 0.003174 | param_change: 2.22e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.5\n",
      "Topic 0 frozen_forget_activations.norm= 22.125\n",
      "Topic 0 updated_retain_activations.norm= 22.75\n",
      "Topic 0 frozen_retain_activations.norm= 23.5\n",
      " 11%|████▊                                     | 17/150 [00:05<00:32,  4.15it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 231, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.992 | unlearn_loss: 1.992 | retain_loss: 0.002441 | param_change: 1.796e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.0\n",
      "Topic 0 frozen_forget_activations.norm= 21.875\n",
      "Topic 0 updated_retain_activations.norm= 21.75\n",
      "Topic 0 frozen_retain_activations.norm= 22.375\n",
      " 12%|█████                                     | 18/150 [00:05<00:32,  4.10it/s]loss: 3.141 | unlearn_loss: 3.141 | retain_loss: 0.003067 | param_change: 2.265e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 25.0\n",
      "Topic 0 frozen_forget_activations.norm= 26.0\n",
      "Topic 0 updated_retain_activations.norm= 24.5\n",
      "Topic 0 frozen_retain_activations.norm= 25.125\n",
      " 13%|█████▎                                    | 19/150 [00:05<00:30,  4.24it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 153, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.953 | unlearn_loss: 2.953 | retain_loss: 0.00267 | param_change: 2.339e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.5\n",
      "Topic 0 frozen_forget_activations.norm= 25.5\n",
      "Topic 0 updated_retain_activations.norm= 23.5\n",
      "Topic 0 frozen_retain_activations.norm= 24.25\n",
      " 13%|█████▌                                    | 20/150 [00:05<00:30,  4.32it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 217, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.109 | unlearn_loss: 2.109 | retain_loss: 0.002335 | param_change: 2.22e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.625\n",
      "Topic 0 frozen_forget_activations.norm= 22.5\n",
      "Topic 0 updated_retain_activations.norm= 23.25\n",
      "Topic 0 frozen_retain_activations.norm= 23.75\n",
      " 14%|█████▉                                    | 21/150 [00:06<00:30,  4.30it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 197, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.312 | unlearn_loss: 2.312 | retain_loss: 0.002441 | param_change: 2.265e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.5\n",
      "Topic 0 frozen_forget_activations.norm= 23.5\n",
      "Topic 0 updated_retain_activations.norm= 32.0\n",
      "Topic 0 frozen_retain_activations.norm= 32.75\n",
      " 15%|██████▏                                   | 22/150 [00:06<00:29,  4.38it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 195, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.328 | unlearn_loss: 2.328 | retain_loss: 0.002914 | param_change: 2.056e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.625\n",
      "Topic 0 frozen_forget_activations.norm= 23.5\n",
      "Topic 0 updated_retain_activations.norm= 22.0\n",
      "Topic 0 frozen_retain_activations.norm= 22.625\n",
      " 15%|██████▍                                   | 23/150 [00:06<00:29,  4.30it/s]loss: 1.805 | unlearn_loss: 1.797 | retain_loss: 0.005157 | param_change: 3.144e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 20.375\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 32.5\n",
      "Topic 0 frozen_retain_activations.norm= 33.5\n",
      " 16%|██████▋                                   | 24/150 [00:06<00:29,  4.28it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 201, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.266 | unlearn_loss: 2.266 | retain_loss: 0.006714 | param_change: 3.383e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 22.125\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 22.75\n",
      "Topic 0 frozen_retain_activations.norm= 23.75\n",
      " 17%|███████                                   | 25/150 [00:07<00:29,  4.27it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 252, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.82 | unlearn_loss: 1.82 | retain_loss: 0.002686 | param_change: 2.071e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 20.5\n",
      "Topic 0 frozen_forget_activations.norm= 21.5\n",
      "Topic 0 updated_retain_activations.norm= 27.0\n",
      "Topic 0 frozen_retain_activations.norm= 27.625\n",
      " 17%|███████▎                                  | 26/150 [00:07<00:29,  4.24it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 205, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.219 | unlearn_loss: 2.219 | retain_loss: 0.002518 | param_change: 2.146e-06\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 34.5\n",
      "Topic 0 frozen_retain_activations.norm= 35.0\n",
      " 18%|███████▌                                  | 27/150 [00:07<00:28,  4.34it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 187, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.422 | unlearn_loss: 2.422 | retain_loss: 0.002518 | param_change: 2.027e-06\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.625\n",
      "Topic 0 frozen_forget_activations.norm= 24.0\n",
      "Topic 0 updated_retain_activations.norm= 22.5\n",
      "Topic 0 frozen_retain_activations.norm= 23.0\n",
      " 19%|███████▊                                  | 28/150 [00:07<00:28,  4.31it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 176, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.578 | unlearn_loss: 2.578 | retain_loss: 0.003052 | param_change: 1.937e-06\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.0\n",
      "Topic 0 frozen_forget_activations.norm= 24.25\n",
      "Topic 0 updated_retain_activations.norm= 21.75\n",
      "Topic 0 frozen_retain_activations.norm= 22.5\n",
      " 19%|████████                                  | 29/150 [00:08<00:28,  4.29it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 84, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 5.25 | unlearn_loss: 5.25 | retain_loss: 0.003647 | param_change: 2.965e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 32.0\n",
      "Topic 0 frozen_forget_activations.norm= 32.75\n",
      "Topic 0 updated_retain_activations.norm= 21.375\n",
      "Topic 0 frozen_retain_activations.norm= 22.0\n",
      " 20%|████████▍                                 | 30/150 [00:08<00:27,  4.33it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 198, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.297 | unlearn_loss: 2.297 | retain_loss: 0.003479 | param_change: 2.31e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.0\n",
      "Topic 0 updated_retain_activations.norm= 23.25\n",
      "Topic 0 frozen_retain_activations.norm= 24.0\n",
      " 21%|████████▋                                 | 31/150 [00:08<00:27,  4.32it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 212, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.141 | unlearn_loss: 2.141 | retain_loss: 0.00415 | param_change: 2.176e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 21.25\n",
      "Topic 0 frozen_forget_activations.norm= 22.5\n",
      "Topic 0 updated_retain_activations.norm= 20.625\n",
      "Topic 0 frozen_retain_activations.norm= 21.375\n",
      " 21%|████████▉                                 | 32/150 [00:08<00:28,  4.17it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 242, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.891 | unlearn_loss: 1.891 | retain_loss: 0.002502 | param_change: 1.781e-06\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 20.75\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 26.5\n",
      "Topic 0 frozen_retain_activations.norm= 27.125\n",
      " 22%|█████████▏                                | 33/150 [00:08<00:28,  4.15it/s]loss: 2.219 | unlearn_loss: 2.219 | retain_loss: 0.002808 | param_change: 2.071e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.75\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 25.0\n",
      "Topic 0 frozen_retain_activations.norm= 25.75\n",
      " 23%|█████████▌                                | 34/150 [00:09<00:27,  4.21it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 175, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.594 | unlearn_loss: 2.594 | retain_loss: 0.003647 | param_change: 2.056e-06\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.0\n",
      "Topic 0 frozen_forget_activations.norm= 24.375\n",
      "Topic 0 updated_retain_activations.norm= 18.875\n",
      "Topic 0 frozen_retain_activations.norm= 19.5\n",
      " 23%|█████████▊                                | 35/150 [00:09<00:29,  3.96it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 182, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.484 | unlearn_loss: 2.484 | retain_loss: 0.002533 | param_change: 1.676e-06\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.5\n",
      "Topic 0 frozen_forget_activations.norm= 24.0\n",
      "Topic 0 updated_retain_activations.norm= 23.25\n",
      "Topic 0 frozen_retain_activations.norm= 23.75\n",
      " 24%|██████████                                | 36/150 [00:09<00:27,  4.09it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 172, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.625 | unlearn_loss: 2.625 | retain_loss: 0.003891 | param_change: 2.235e-06\n",
      "unlearn_cosine_sim=0.98828125\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.75\n",
      "Topic 0 frozen_forget_activations.norm= 24.25\n",
      "Topic 0 updated_retain_activations.norm= 25.0\n",
      "Topic 0 frozen_retain_activations.norm= 26.0\n",
      " 25%|██████████▎                               | 37/150 [00:09<00:26,  4.22it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 189, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.406 | unlearn_loss: 2.406 | retain_loss: 0.002747 | param_change: 1.863e-06\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.375\n",
      "Topic 0 frozen_forget_activations.norm= 23.5\n",
      "Topic 0 updated_retain_activations.norm= 24.0\n",
      "Topic 0 frozen_retain_activations.norm= 24.75\n",
      " 25%|██████████▋                               | 38/150 [00:10<00:26,  4.29it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 225, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.047 | unlearn_loss: 2.047 | retain_loss: 0.004822 | param_change: 2.682e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 21.25\n",
      "Topic 0 frozen_forget_activations.norm= 22.125\n",
      "Topic 0 updated_retain_activations.norm= 25.125\n",
      "Topic 0 frozen_retain_activations.norm= 26.0\n",
      " 26%|██████████▉                               | 39/150 [00:10<00:25,  4.28it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 113, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.969 | unlearn_loss: 3.969 | retain_loss: 0.003479 | param_change: 2.056e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 27.25\n",
      "Topic 0 frozen_forget_activations.norm= 28.25\n",
      "Topic 0 updated_retain_activations.norm= 24.75\n",
      "Topic 0 frozen_retain_activations.norm= 25.5\n",
      " 27%|███████████▏                              | 40/150 [00:10<00:24,  4.41it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 119, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.797 | unlearn_loss: 3.781 | retain_loss: 0.008423 | param_change: 4.202e-06\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 26.875\n",
      "Topic 0 frozen_forget_activations.norm= 28.25\n",
      "Topic 0 updated_retain_activations.norm= 24.25\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 27%|███████████▍                              | 41/150 [00:10<00:24,  4.50it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 174, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.594 | unlearn_loss: 2.594 | retain_loss: 0.002197 | param_change: 1.781e-06\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.5\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 19.5\n",
      "Topic 0 frozen_retain_activations.norm= 20.0\n",
      " 28%|███████████▊                              | 42/150 [00:11<00:25,  4.17it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 248, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.844 | unlearn_loss: 1.844 | retain_loss: 0.002319 | param_change: 1.907e-06\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 20.5\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 26.25\n",
      "Topic 0 frozen_retain_activations.norm= 26.875\n",
      " 29%|████████████                              | 43/150 [00:11<00:25,  4.15it/s]loss: 1.797 | unlearn_loss: 1.797 | retain_loss: 0.003738 | param_change: 1.84e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 20.25\n",
      "Topic 0 frozen_forget_activations.norm= 21.5\n",
      "Topic 0 updated_retain_activations.norm= 22.0\n",
      "Topic 0 frozen_retain_activations.norm= 22.625\n",
      " 29%|████████████▎                             | 44/150 [00:11<00:26,  4.04it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 164, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.75 | unlearn_loss: 2.75 | retain_loss: 0.003265 | param_change: 1.907e-06\n",
      "unlearn_cosine_sim=0.98828125\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.125\n",
      "Topic 0 frozen_forget_activations.norm= 24.75\n",
      "Topic 0 updated_retain_activations.norm= 24.5\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 30%|████████████▌                             | 45/150 [00:11<00:25,  4.18it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 339, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.367 | unlearn_loss: 1.367 | retain_loss: 0.003876 | param_change: 1.743e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 19.0\n",
      "Topic 0 frozen_forget_activations.norm= 20.125\n",
      "Topic 0 updated_retain_activations.norm= 20.875\n",
      "Topic 0 frozen_retain_activations.norm= 21.75\n",
      " 31%|████████████▉                             | 46/150 [00:12<00:28,  3.60it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 177, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.562 | unlearn_loss: 2.562 | retain_loss: 0.003235 | param_change: 1.863e-06\n",
      "unlearn_cosine_sim=0.98828125\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.5\n",
      "Topic 0 frozen_forget_activations.norm= 23.875\n",
      "Topic 0 updated_retain_activations.norm= 20.75\n",
      "Topic 0 frozen_retain_activations.norm= 21.375\n",
      " 31%|█████████████▏                            | 47/150 [00:12<00:27,  3.71it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 206, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.203 | unlearn_loss: 2.203 | retain_loss: 0.006989 | param_change: 3.397e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 21.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.0\n",
      "Topic 0 updated_retain_activations.norm= 29.75\n",
      "Topic 0 frozen_retain_activations.norm= 30.75\n",
      " 32%|█████████████▍                            | 48/150 [00:12<00:26,  3.92it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 156, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.891 | unlearn_loss: 2.891 | retain_loss: 0.003036 | param_change: 1.892e-06\n",
      "unlearn_cosine_sim=0.984375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.0\n",
      "Topic 0 frozen_forget_activations.norm= 25.625\n",
      "Topic 0 updated_retain_activations.norm= 24.5\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 33%|█████████████▋                            | 49/150 [00:12<00:24,  4.09it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 111, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 4.031 | unlearn_loss: 4.031 | retain_loss: 0.008057 | param_change: 3.695e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 27.75\n",
      "Topic 0 frozen_forget_activations.norm= 28.75\n",
      "Topic 0 updated_retain_activations.norm= 34.0\n",
      "Topic 0 frozen_retain_activations.norm= 35.0\n",
      " 33%|██████████████                            | 50/150 [00:13<00:23,  4.25it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 209, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.172 | unlearn_loss: 2.172 | retain_loss: 0.002563 | param_change: 2.086e-06\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.5\n",
      "Topic 0 frozen_forget_activations.norm= 22.875\n",
      "Topic 0 updated_retain_activations.norm= 30.75\n",
      "Topic 0 frozen_retain_activations.norm= 31.25\n",
      " 34%|██████████████▎                           | 51/150 [00:13<00:22,  4.32it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 240, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.922 | unlearn_loss: 1.922 | retain_loss: 0.002457 | param_change: 1.907e-06\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 20.75\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 21.125\n",
      "Topic 0 frozen_retain_activations.norm= 21.75\n",
      " 35%|██████████████▌                           | 52/150 [00:13<00:23,  4.17it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 79, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 5.562 | unlearn_loss: 5.562 | retain_loss: 0.002563 | param_change: 2.012e-06\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 32.5\n",
      "Topic 0 frozen_forget_activations.norm= 34.0\n",
      "Topic 0 updated_retain_activations.norm= 28.875\n",
      "Topic 0 frozen_retain_activations.norm= 29.5\n",
      " 35%|██████████████▊                           | 53/150 [00:13<00:22,  4.39it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 264, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.758 | unlearn_loss: 1.75 | retain_loss: 0.005127 | param_change: 2.518e-06\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 20.375\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 21.25\n",
      "Topic 0 frozen_retain_activations.norm= 22.0\n",
      " 36%|███████████████                           | 54/150 [00:14<00:23,  4.11it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 226, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.031 | unlearn_loss: 2.031 | retain_loss: 0.003189 | param_change: 1.654e-06\n",
      "unlearn_cosine_sim=0.98046875\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 20.375\n",
      "Topic 0 frozen_forget_activations.norm= 22.25\n",
      "Topic 0 updated_retain_activations.norm= 26.125\n",
      "Topic 0 frozen_retain_activations.norm= 26.875\n",
      " 37%|███████████████▍                          | 55/150 [00:14<00:22,  4.15it/s]loss: 2.391 | unlearn_loss: 2.391 | retain_loss: 0.002884 | param_change: 1.654e-06\n",
      "unlearn_cosine_sim=0.98828125\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 25.5\n",
      "Topic 0 frozen_retain_activations.norm= 26.25\n",
      " 37%|███████████████▋                          | 56/150 [00:14<00:22,  4.25it/s]loss: 2.5 | unlearn_loss: 2.484 | retain_loss: 0.009888 | param_change: 4.679e-06\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 22.375\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 21.5\n",
      "Topic 0 frozen_retain_activations.norm= 22.75\n",
      " 38%|███████████████▉                          | 57/150 [00:14<00:21,  4.24it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 150, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.016 | unlearn_loss: 3 | retain_loss: 0.01172 | param_change: 4.59e-06\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 23.75\n",
      "Topic 0 frozen_forget_activations.norm= 25.25\n",
      "Topic 0 updated_retain_activations.norm= 22.875\n",
      "Topic 0 frozen_retain_activations.norm= 24.25\n",
      " 39%|████████████████▏                         | 58/150 [00:14<00:21,  4.32it/s]loss: 2.203 | unlearn_loss: 2.203 | retain_loss: 0.002991 | param_change: 1.781e-06\n",
      "unlearn_cosine_sim=0.98828125\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.5\n",
      "Topic 0 frozen_forget_activations.norm= 23.0\n",
      "Topic 0 updated_retain_activations.norm= 25.25\n",
      "Topic 0 frozen_retain_activations.norm= 26.0\n",
      " 39%|████████████████▌                         | 59/150 [00:15<00:21,  4.33it/s]loss: 2.094 | unlearn_loss: 2.094 | retain_loss: 0.003113 | param_change: 1.81e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 20.875\n",
      "Topic 0 frozen_forget_activations.norm= 22.125\n",
      "Topic 0 updated_retain_activations.norm= 24.0\n",
      "Topic 0 frozen_retain_activations.norm= 24.75\n",
      " 40%|████████████████▊                         | 60/150 [00:15<00:20,  4.31it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 135, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.328 | unlearn_loss: 3.328 | retain_loss: 0.002502 | param_change: 1.937e-06\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 25.0\n",
      "Topic 0 frozen_forget_activations.norm= 26.5\n",
      "Topic 0 updated_retain_activations.norm= 27.125\n",
      "Topic 0 frozen_retain_activations.norm= 27.75\n",
      " 41%|█████████████████                         | 61/150 [00:15<00:20,  4.40it/s]loss: 2.5 | unlearn_loss: 2.5 | retain_loss: 0.003342 | param_change: 1.863e-06\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.25\n",
      "Topic 0 frozen_forget_activations.norm= 23.5\n",
      "Topic 0 updated_retain_activations.norm= 23.25\n",
      "Topic 0 frozen_retain_activations.norm= 24.0\n",
      " 41%|█████████████████▎                        | 62/150 [00:15<00:19,  4.41it/s]loss: 1.914 | unlearn_loss: 1.914 | retain_loss: 0.003128 | param_change: 1.587e-06\n",
      "unlearn_cosine_sim=0.98046875\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 20.0\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 21.875\n",
      "Topic 0 frozen_retain_activations.norm= 22.5\n",
      " 42%|█████████████████▋                        | 63/150 [00:16<00:20,  4.26it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 102, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 4.406 | unlearn_loss: 4.406 | retain_loss: 0.003387 | param_change: 2.146e-06\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 29.0\n",
      "Topic 0 frozen_forget_activations.norm= 30.25\n",
      "Topic 0 updated_retain_activations.norm= 22.625\n",
      "Topic 0 frozen_retain_activations.norm= 23.375\n",
      " 43%|█████████████████▉                        | 64/150 [00:16<00:19,  4.34it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 180, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.516 | unlearn_loss: 2.516 | retain_loss: 0.003815 | param_change: 1.766e-06\n",
      "unlearn_cosine_sim=0.984375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 24.5\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 43%|██████████████████▏                       | 65/150 [00:16<00:19,  4.39it/s]loss: 2.781 | unlearn_loss: 2.781 | retain_loss: 0.003174 | param_change: 1.855e-06\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.375\n",
      "Topic 0 frozen_forget_activations.norm= 24.75\n",
      "Topic 0 updated_retain_activations.norm= 25.25\n",
      "Topic 0 frozen_retain_activations.norm= 25.875\n",
      " 44%|██████████████████▍                       | 66/150 [00:16<00:18,  4.45it/s]loss: 1.836 | unlearn_loss: 1.828 | retain_loss: 0.00412 | param_change: 2.161e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 21.125\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 22.0\n",
      "Topic 0 frozen_retain_activations.norm= 22.75\n",
      " 45%|██████████████████▊                       | 67/150 [00:17<00:19,  4.24it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 146, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.078 | unlearn_loss: 3.078 | retain_loss: 0.003937 | param_change: 1.982e-06\n",
      "unlearn_cosine_sim=0.9765625\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.75\n",
      "Topic 0 frozen_forget_activations.norm= 25.75\n",
      "Topic 0 updated_retain_activations.norm= 19.75\n",
      "Topic 0 frozen_retain_activations.norm= 20.375\n",
      " 45%|███████████████████                       | 68/150 [00:17<00:21,  3.89it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 184, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.469 | unlearn_loss: 2.469 | retain_loss: 0.005188 | param_change: 2.921e-06\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 22.25\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 25.5\n",
      "Topic 0 frozen_retain_activations.norm= 26.375\n",
      " 46%|███████████████████▎                      | 69/150 [00:17<00:19,  4.06it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 281, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.672 | unlearn_loss: 1.664 | retain_loss: 0.006287 | param_change: 2.831e-06\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 19.75\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 24.0\n",
      "Topic 0 frozen_retain_activations.norm= 25.125\n",
      " 47%|███████████████████▌                      | 70/150 [00:17<00:20,  3.98it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 223, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.047 | unlearn_loss: 2.047 | retain_loss: 0.00415 | param_change: 2.056e-06\n",
      "unlearn_cosine_sim=0.98828125\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 20.75\n",
      "Topic 0 frozen_forget_activations.norm= 22.375\n",
      "Topic 0 updated_retain_activations.norm= 23.125\n",
      "Topic 0 frozen_retain_activations.norm= 24.0\n",
      " 47%|███████████████████▉                      | 71/150 [00:18<00:19,  4.04it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 158, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.875 | unlearn_loss: 2.859 | retain_loss: 0.008667 | param_change: 3.293e-06\n",
      "unlearn_cosine_sim=0.97265625\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 23.125\n",
      "Topic 0 frozen_forget_activations.norm= 25.25\n",
      "Topic 0 updated_retain_activations.norm= 19.75\n",
      "Topic 0 frozen_retain_activations.norm= 21.0\n",
      " 48%|████████████████████▏                     | 72/150 [00:18<00:19,  3.95it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 228, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.031 | unlearn_loss: 2.016 | retain_loss: 0.01068 | param_change: 4.709e-06\n",
      "unlearn_cosine_sim=0.98828125\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 20.375\n",
      "Topic 0 frozen_forget_activations.norm= 22.25\n",
      "Topic 0 updated_retain_activations.norm= 25.0\n",
      "Topic 0 frozen_retain_activations.norm= 26.25\n",
      " 49%|████████████████████▍                     | 73/150 [00:18<00:19,  4.03it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 324, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.445 | unlearn_loss: 1.438 | retain_loss: 0.007355 | param_change: 2.965e-06\n",
      "unlearn_cosine_sim=0.98046875\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 18.75\n",
      "Topic 0 frozen_forget_activations.norm= 20.75\n",
      "Topic 0 updated_retain_activations.norm= 29.25\n",
      "Topic 0 frozen_retain_activations.norm= 30.25\n",
      " 49%|████████████████████▋                     | 74/150 [00:18<00:19,  3.94it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 163, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.766 | unlearn_loss: 2.766 | retain_loss: 0.002823 | param_change: 2.056e-06\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.5\n",
      "Topic 0 frozen_forget_activations.norm= 24.75\n",
      "Topic 0 updated_retain_activations.norm= 23.625\n",
      "Topic 0 frozen_retain_activations.norm= 24.25\n",
      " 50%|█████████████████████                     | 75/150 [00:19<00:18,  4.09it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 265, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.742 | unlearn_loss: 1.742 | retain_loss: 0.003662 | param_change: 2.563e-06\n",
      "unlearn_cosine_sim=0.98828125\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 19.625\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 20.25\n",
      "Topic 0 frozen_retain_activations.norm= 21.0\n",
      " 51%|█████████████████████▎                    | 76/150 [00:19<00:19,  3.80it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 207, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.188 | unlearn_loss: 2.188 | retain_loss: 0.005188 | param_change: 2.339e-06\n",
      "unlearn_cosine_sim=0.984375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 21.25\n",
      "Topic 0 frozen_forget_activations.norm= 23.0\n",
      "Topic 0 updated_retain_activations.norm= 20.75\n",
      "Topic 0 frozen_retain_activations.norm= 21.75\n",
      " 51%|█████████████████████▌                    | 77/150 [00:19<00:18,  3.85it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 179, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.531 | unlearn_loss: 2.531 | retain_loss: 0.003281 | param_change: 1.743e-06\n",
      "unlearn_cosine_sim=0.98828125\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.625\n",
      "Topic 0 updated_retain_activations.norm= 22.5\n",
      "Topic 0 frozen_retain_activations.norm= 23.125\n",
      " 52%|█████████████████████▊                    | 78/150 [00:19<00:18,  3.97it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 152, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.984 | unlearn_loss: 2.969 | retain_loss: 0.01807 | param_change: 5.245e-06\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=0.9921875\n",
      "Topic 0 updated_forget_activations.norm= 24.25\n",
      "Topic 0 frozen_forget_activations.norm= 25.875\n",
      "Topic 0 updated_retain_activations.norm= 21.75\n",
      "Topic 0 frozen_retain_activations.norm= 23.25\n",
      " 53%|██████████████████████                    | 79/150 [00:20<00:17,  4.07it/s]loss: 2.438 | unlearn_loss: 2.438 | retain_loss: 0.002869 | param_change: 2.25e-06\n",
      "unlearn_cosine_sim=0.96484375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.75\n",
      "Topic 0 frozen_forget_activations.norm= 24.25\n",
      "Topic 0 updated_retain_activations.norm= 21.25\n",
      "Topic 0 frozen_retain_activations.norm= 21.625\n",
      " 53%|██████████████████████▍                   | 80/150 [00:20<00:17,  3.98it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 188, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.406 | unlearn_loss: 2.406 | retain_loss: 0.003891 | param_change: 1.848e-06\n",
      "unlearn_cosine_sim=0.98828125\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 19.5\n",
      "Topic 0 frozen_retain_activations.norm= 20.125\n",
      " 54%|██████████████████████▋                   | 81/150 [00:20<00:18,  3.70it/s]loss: 2.891 | unlearn_loss: 2.891 | retain_loss: 0.002914 | param_change: 1.952e-06\n",
      "unlearn_cosine_sim=0.984375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.75\n",
      "Topic 0 frozen_forget_activations.norm= 25.5\n",
      "Topic 0 updated_retain_activations.norm= 27.0\n",
      "Topic 0 frozen_retain_activations.norm= 27.625\n",
      " 55%|██████████████████████▉                   | 82/150 [00:20<00:17,  3.96it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 192, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.375 | unlearn_loss: 2.359 | retain_loss: 0.007874 | param_change: 3.085e-06\n",
      "unlearn_cosine_sim=0.97265625\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 21.5\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 24.0\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 55%|███████████████████████▏                  | 83/150 [00:21<00:16,  4.10it/s]loss: 2.047 | unlearn_loss: 2.031 | retain_loss: 0.00824 | param_change: 3.174e-06\n",
      "unlearn_cosine_sim=0.98046875\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 20.25\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 24.625\n",
      "Topic 0 frozen_retain_activations.norm= 25.75\n",
      " 56%|███████████████████████▌                  | 84/150 [00:21<00:15,  4.15it/s]loss: 3.094 | unlearn_loss: 3.094 | retain_loss: 0.003143 | param_change: 2.354e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.5\n",
      "Topic 0 frozen_forget_activations.norm= 25.875\n",
      "Topic 0 updated_retain_activations.norm= 23.0\n",
      "Topic 0 frozen_retain_activations.norm= 23.75\n",
      " 57%|███████████████████████▊                  | 85/150 [00:21<00:15,  4.25it/s]loss: 2.094 | unlearn_loss: 2.094 | retain_loss: 0.004303 | param_change: 3.07e-06\n",
      "unlearn_cosine_sim=0.9765625\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 20.375\n",
      "Topic 0 frozen_forget_activations.norm= 22.5\n",
      "Topic 0 updated_retain_activations.norm= 24.375\n",
      "Topic 0 frozen_retain_activations.norm= 24.875\n",
      " 57%|████████████████████████                  | 86/150 [00:21<00:15,  4.26it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 166, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.719 | unlearn_loss: 2.719 | retain_loss: 0.004364 | param_change: 1.833e-06\n",
      "unlearn_cosine_sim=0.98046875\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 22.5\n",
      "Topic 0 frozen_forget_activations.norm= 24.5\n",
      "Topic 0 updated_retain_activations.norm= 23.375\n",
      "Topic 0 frozen_retain_activations.norm= 24.125\n",
      " 58%|████████████████████████▎                 | 87/150 [00:22<00:14,  4.33it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 215, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.109 | unlearn_loss: 2.109 | retain_loss: 0.00412 | param_change: 2.414e-06\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 21.25\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 24.5\n",
      "Topic 0 frozen_retain_activations.norm= 25.125\n",
      " 59%|████████████████████████▋                 | 88/150 [00:22<00:14,  4.31it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 169, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.672 | unlearn_loss: 2.672 | retain_loss: 0.003342 | param_change: 1.937e-06\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.875\n",
      "Topic 0 frozen_forget_activations.norm= 24.375\n",
      "Topic 0 updated_retain_activations.norm= 21.5\n",
      "Topic 0 frozen_retain_activations.norm= 22.25\n",
      " 59%|████████████████████████▉                 | 89/150 [00:22<00:14,  4.30it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 129, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.484 | unlearn_loss: 3.484 | retain_loss: 0.003845 | param_change: 1.997e-06\n",
      "unlearn_cosine_sim=0.98046875\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 26.0\n",
      "Topic 0 frozen_forget_activations.norm= 27.75\n",
      "Topic 0 updated_retain_activations.norm= 26.25\n",
      "Topic 0 frozen_retain_activations.norm= 27.0\n",
      " 60%|█████████████████████████▏                | 90/150 [00:22<00:13,  4.41it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 361, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.281 | unlearn_loss: 1.281 | retain_loss: 0.002716 | param_change: 1.848e-06\n",
      "unlearn_cosine_sim=0.96484375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 17.75\n",
      "Topic 0 frozen_forget_activations.norm= 20.25\n",
      "Topic 0 updated_retain_activations.norm= 24.25\n",
      "Topic 0 frozen_retain_activations.norm= 24.75\n",
      " 61%|█████████████████████████▍                | 91/150 [00:22<00:14,  4.10it/s]loss: 2.859 | unlearn_loss: 2.859 | retain_loss: 0.004608 | param_change: 2.116e-06\n",
      "unlearn_cosine_sim=0.96484375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 23.0\n",
      "Topic 0 frozen_forget_activations.norm= 25.25\n",
      "Topic 0 updated_retain_activations.norm= 22.625\n",
      "Topic 0 frozen_retain_activations.norm= 23.5\n",
      " 61%|█████████████████████████▊                | 92/150 [00:23<00:13,  4.20it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 258, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.781 | unlearn_loss: 1.781 | retain_loss: 0.003342 | param_change: 1.863e-06\n",
      "unlearn_cosine_sim=0.98046875\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 19.375\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 34.0\n",
      "Topic 0 frozen_retain_activations.norm= 34.5\n",
      " 62%|██████████████████████████                | 93/150 [00:23<00:13,  4.14it/s]loss: 1.633 | unlearn_loss: 1.633 | retain_loss: 0.002289 | param_change: 1.766e-06\n",
      "unlearn_cosine_sim=0.9765625\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 19.0\n",
      "Topic 0 frozen_forget_activations.norm= 21.0\n",
      "Topic 0 updated_retain_activations.norm= 288.0\n",
      "Topic 0 frozen_retain_activations.norm= 290.0\n",
      " 63%|██████████████████████████▎               | 94/150 [00:23<00:14,  3.80it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 103, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 4.344 | unlearn_loss: 4.344 | retain_loss: 0.01288 | param_change: 5.096e-06\n",
      "unlearn_cosine_sim=0.98828125\n",
      "retain_cosine_sim=0.9921875\n",
      "Topic 0 updated_forget_activations.norm= 28.375\n",
      "Topic 0 frozen_forget_activations.norm= 30.0\n",
      "Topic 0 updated_retain_activations.norm= 21.0\n",
      "Topic 0 frozen_retain_activations.norm= 22.25\n",
      " 63%|██████████████████████████▌               | 95/150 [00:24<00:13,  3.98it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 161, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.797 | unlearn_loss: 2.797 | retain_loss: 0.006348 | param_change: 2.98e-06\n",
      "unlearn_cosine_sim=0.9765625\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 22.875\n",
      "Topic 0 frozen_forget_activations.norm= 25.0\n",
      "Topic 0 updated_retain_activations.norm= 21.25\n",
      "Topic 0 frozen_retain_activations.norm= 22.0\n",
      " 64%|██████████████████████████▉               | 96/150 [00:24<00:13,  4.04it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 282, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.641 | unlearn_loss: 1.633 | retain_loss: 0.00531 | param_change: 2.623e-06\n",
      "unlearn_cosine_sim=0.98046875\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 18.625\n",
      "Topic 0 frozen_forget_activations.norm= 20.75\n",
      "Topic 0 updated_retain_activations.norm= 21.0\n",
      "Topic 0 frozen_retain_activations.norm= 22.0\n",
      " 65%|███████████████████████████▏              | 97/150 [00:24<00:13,  3.87it/s]loss: 2.578 | unlearn_loss: 2.578 | retain_loss: 0.004852 | param_change: 2.012e-06\n",
      "unlearn_cosine_sim=0.98828125\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 22.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 21.5\n",
      "Topic 0 frozen_retain_activations.norm= 22.25\n",
      " 65%|███████████████████████████▍              | 98/150 [00:24<00:13,  3.98it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 269, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.711 | unlearn_loss: 1.711 | retain_loss: 0.003052 | param_change: 1.967e-06\n",
      "unlearn_cosine_sim=0.93359375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 18.5\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 25.75\n",
      "Topic 0 frozen_retain_activations.norm= 26.375\n",
      " 66%|███████████████████████████▋              | 99/150 [00:25<00:12,  3.94it/s]loss: 2.75 | unlearn_loss: 2.75 | retain_loss: 0.004822 | param_change: 2.369e-06\n",
      "unlearn_cosine_sim=0.9609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 22.625\n",
      "Topic 0 frozen_forget_activations.norm= 24.875\n",
      "Topic 0 updated_retain_activations.norm= 22.625\n",
      "Topic 0 frozen_retain_activations.norm= 23.5\n",
      " 67%|███████████████████████████▎             | 100/150 [00:25<00:12,  4.04it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 154, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.922 | unlearn_loss: 2.922 | retain_loss: 0.006042 | param_change: 2.488e-06\n",
      "unlearn_cosine_sim=0.98046875\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 22.875\n",
      "Topic 0 frozen_forget_activations.norm= 25.0\n",
      "Topic 0 updated_retain_activations.norm= 23.0\n",
      "Topic 0 frozen_retain_activations.norm= 24.0\n",
      " 67%|███████████████████████████▌             | 101/150 [00:25<00:11,  4.18it/s]loss: 2.281 | unlearn_loss: 2.281 | retain_loss: 0.005432 | param_change: 2.28e-06\n",
      "unlearn_cosine_sim=0.9609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 20.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 23.5\n",
      "Topic 0 frozen_retain_activations.norm= 24.5\n",
      " 68%|███████████████████████████▉             | 102/150 [00:25<00:11,  4.21it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 155, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.906 | unlearn_loss: 2.906 | retain_loss: 0.003784 | param_change: 1.952e-06\n",
      "unlearn_cosine_sim=0.984375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.25\n",
      "Topic 0 frozen_forget_activations.norm= 25.0\n",
      "Topic 0 updated_retain_activations.norm= 21.5\n",
      "Topic 0 frozen_retain_activations.norm= 22.25\n",
      " 69%|████████████████████████████▏            | 103/150 [00:25<00:11,  4.21it/s]loss: 2.328 | unlearn_loss: 2.328 | retain_loss: 0.00296 | param_change: 2.131e-06\n",
      "unlearn_cosine_sim=0.98828125\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.25\n",
      "Topic 0 frozen_forget_activations.norm= 23.125\n",
      "Topic 0 updated_retain_activations.norm= 21.25\n",
      "Topic 0 frozen_retain_activations.norm= 21.625\n",
      " 69%|████████████████████████████▍            | 104/150 [00:26<00:11,  4.10it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 245, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.859 | unlearn_loss: 1.859 | retain_loss: 0.00383 | param_change: 2.101e-06\n",
      "unlearn_cosine_sim=0.984375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 19.75\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 26.25\n",
      "Topic 0 frozen_retain_activations.norm= 27.0\n",
      " 70%|████████████████████████████▋            | 105/150 [00:26<00:10,  4.09it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 323, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.438 | unlearn_loss: 1.43 | retain_loss: 0.00531 | param_change: 2.429e-06\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 18.5\n",
      "Topic 0 frozen_forget_activations.norm= 20.0\n",
      "Topic 0 updated_retain_activations.norm= 27.25\n",
      "Topic 0 frozen_retain_activations.norm= 28.125\n",
      " 71%|████████████████████████████▉            | 106/150 [00:26<00:11,  3.97it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 230, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2 | unlearn_loss: 1.992 | retain_loss: 0.005829 | param_change: 2.22e-06\n",
      "unlearn_cosine_sim=0.953125\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 20.0\n",
      "Topic 0 frozen_forget_activations.norm= 22.375\n",
      "Topic 0 updated_retain_activations.norm= 21.625\n",
      "Topic 0 frozen_retain_activations.norm= 22.75\n",
      " 71%|█████████████████████████████▏           | 107/150 [00:26<00:10,  3.96it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 165, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.734 | unlearn_loss: 2.734 | retain_loss: 0.00415 | param_change: 2.012e-06\n",
      "unlearn_cosine_sim=0.96875\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.75\n",
      "Topic 0 frozen_forget_activations.norm= 24.75\n",
      "Topic 0 updated_retain_activations.norm= 25.75\n",
      "Topic 0 frozen_retain_activations.norm= 26.5\n",
      " 72%|█████████████████████████████▌           | 108/150 [00:27<00:10,  4.13it/s]loss: 2.422 | unlearn_loss: 2.422 | retain_loss: 0.005005 | param_change: 2.205e-06\n",
      "unlearn_cosine_sim=0.984375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 21.5\n",
      "Topic 0 frozen_forget_activations.norm= 23.625\n",
      "Topic 0 updated_retain_activations.norm= 26.25\n",
      "Topic 0 frozen_retain_activations.norm= 27.125\n",
      " 73%|█████████████████████████████▊           | 109/150 [00:27<00:09,  4.25it/s]loss: 1.875 | unlearn_loss: 1.875 | retain_loss: 0.002655 | param_change: 2.027e-06\n",
      "unlearn_cosine_sim=0.97265625\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 19.625\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 22.0\n",
      "Topic 0 frozen_retain_activations.norm= 22.625\n",
      " 73%|██████████████████████████████           | 110/150 [00:27<00:09,  4.12it/s]loss: 1.742 | unlearn_loss: 1.734 | retain_loss: 0.008118 | param_change: 3.695e-06\n",
      "unlearn_cosine_sim=0.9375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 18.5\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 33.0\n",
      "Topic 0 frozen_retain_activations.norm= 34.25\n",
      " 74%|██████████████████████████████▎          | 111/150 [00:27<00:09,  4.08it/s]loss: 2.281 | unlearn_loss: 2.281 | retain_loss: 0.005829 | param_change: 2.757e-06\n",
      "unlearn_cosine_sim=0.9765625\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 21.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 23.75\n",
      "Topic 0 frozen_retain_activations.norm= 24.625\n",
      " 75%|██████████████████████████████▌          | 112/150 [00:28<00:09,  4.14it/s]loss: 2.922 | unlearn_loss: 2.922 | retain_loss: 0.003815 | param_change: 1.84e-06\n",
      "unlearn_cosine_sim=0.9765625\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.875\n",
      "Topic 0 frozen_forget_activations.norm= 25.125\n",
      "Topic 0 updated_retain_activations.norm= 24.75\n",
      "Topic 0 frozen_retain_activations.norm= 25.625\n",
      " 75%|██████████████████████████████▉          | 113/150 [00:28<00:08,  4.27it/s]loss: 2.391 | unlearn_loss: 2.375 | retain_loss: 0.01245 | param_change: 4.5e-06\n",
      "unlearn_cosine_sim=0.98046875\n",
      "retain_cosine_sim=0.9921875\n",
      "Topic 0 updated_forget_activations.norm= 21.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.625\n",
      "Topic 0 updated_retain_activations.norm= 26.75\n",
      "Topic 0 frozen_retain_activations.norm= 28.0\n",
      " 76%|███████████████████████████████▏         | 114/150 [00:28<00:08,  4.37it/s]loss: 2.562 | unlearn_loss: 2.547 | retain_loss: 0.01111 | param_change: 4.172e-06\n",
      "unlearn_cosine_sim=0.97265625\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 22.0\n",
      "Topic 0 frozen_forget_activations.norm= 24.25\n",
      "Topic 0 updated_retain_activations.norm= 22.25\n",
      "Topic 0 frozen_retain_activations.norm= 23.5\n",
      " 77%|███████████████████████████████▍         | 115/150 [00:28<00:08,  4.34it/s]loss: 2.812 | unlearn_loss: 2.797 | retain_loss: 0.01135 | param_change: 5.513e-06\n",
      "unlearn_cosine_sim=0.98046875\n",
      "retain_cosine_sim=0.9921875\n",
      "Topic 0 updated_forget_activations.norm= 22.5\n",
      "Topic 0 frozen_forget_activations.norm= 24.5\n",
      "Topic 0 updated_retain_activations.norm= 20.75\n",
      "Topic 0 frozen_retain_activations.norm= 22.0\n",
      " 77%|███████████████████████████████▋         | 116/150 [00:29<00:07,  4.29it/s]loss: 2.484 | unlearn_loss: 2.484 | retain_loss: 0.007019 | param_change: 2.98e-06\n",
      "unlearn_cosine_sim=0.94921875\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 21.25\n",
      "Topic 0 frozen_forget_activations.norm= 24.0\n",
      "Topic 0 updated_retain_activations.norm= 21.25\n",
      "Topic 0 frozen_retain_activations.norm= 22.375\n",
      " 78%|███████████████████████████████▉         | 117/150 [00:29<00:07,  4.27it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 193, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.344 | unlearn_loss: 2.344 | retain_loss: 0.005798 | param_change: 2.995e-06\n",
      "unlearn_cosine_sim=0.9765625\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 21.25\n",
      "Topic 0 frozen_forget_activations.norm= 23.5\n",
      "Topic 0 updated_retain_activations.norm= 19.0\n",
      "Topic 0 frozen_retain_activations.norm= 19.875\n",
      " 79%|████████████████████████████████▎        | 118/150 [00:29<00:08,  3.97it/s]loss: 2.797 | unlearn_loss: 2.797 | retain_loss: 0.004608 | param_change: 2.652e-06\n",
      "unlearn_cosine_sim=0.94921875\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 22.0\n",
      "Topic 0 frozen_forget_activations.norm= 24.5\n",
      "Topic 0 updated_retain_activations.norm= 31.5\n",
      "Topic 0 frozen_retain_activations.norm= 32.25\n",
      " 79%|████████████████████████████████▌        | 119/150 [00:29<00:07,  4.18it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 131, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.438 | unlearn_loss: 3.438 | retain_loss: 0.004547 | param_change: 2.578e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 25.75\n",
      "Topic 0 frozen_forget_activations.norm= 26.75\n",
      "Topic 0 updated_retain_activations.norm= 22.0\n",
      "Topic 0 frozen_retain_activations.norm= 22.75\n",
      " 80%|████████████████████████████████▊        | 120/150 [00:30<00:07,  4.24it/s]loss: 2.328 | unlearn_loss: 2.328 | retain_loss: 0.00769 | param_change: 3.308e-06\n",
      "unlearn_cosine_sim=0.984375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 21.5\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 28.25\n",
      "Topic 0 frozen_retain_activations.norm= 29.0\n",
      " 81%|█████████████████████████████████        | 121/150 [00:30<00:06,  4.32it/s]loss: 2.438 | unlearn_loss: 2.438 | retain_loss: 0.003357 | param_change: 1.922e-06\n",
      "unlearn_cosine_sim=0.921875\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 20.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 24.0\n",
      "Topic 0 frozen_retain_activations.norm= 24.5\n",
      " 81%|█████████████████████████████████▎       | 122/150 [00:30<00:06,  4.36it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 168, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.688 | unlearn_loss: 2.688 | retain_loss: 0.003448 | param_change: 2.429e-06\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.5\n",
      "Topic 0 frozen_forget_activations.norm= 24.0\n",
      "Topic 0 updated_retain_activations.norm= 24.0\n",
      "Topic 0 frozen_retain_activations.norm= 24.5\n",
      " 82%|█████████████████████████████████▌       | 123/150 [00:30<00:06,  4.41it/s]loss: 2.203 | unlearn_loss: 2.203 | retain_loss: 0.005981 | param_change: 3.01e-06\n",
      "unlearn_cosine_sim=0.98828125\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 21.0\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 26.5\n",
      "Topic 0 frozen_retain_activations.norm= 27.25\n",
      " 83%|█████████████████████████████████▉       | 124/150 [00:30<00:05,  4.42it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 235, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.945 | unlearn_loss: 1.945 | retain_loss: 0.003448 | param_change: 2.116e-06\n",
      "unlearn_cosine_sim=0.921875\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 19.375\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 23.0\n",
      "Topic 0 frozen_retain_activations.norm= 23.5\n",
      " 83%|██████████████████████████████████▏      | 125/150 [00:31<00:05,  4.28it/s]loss: 2.672 | unlearn_loss: 2.672 | retain_loss: 0.004791 | param_change: 2.339e-06\n",
      "unlearn_cosine_sim=0.98828125\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 22.5\n",
      "Topic 0 frozen_forget_activations.norm= 24.25\n",
      "Topic 0 updated_retain_activations.norm= 25.5\n",
      "Topic 0 frozen_retain_activations.norm= 26.25\n",
      " 84%|██████████████████████████████████▍      | 126/150 [00:31<00:05,  4.36it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 122, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.703 | unlearn_loss: 3.688 | retain_loss: 0.0116 | param_change: 4.321e-06\n",
      "unlearn_cosine_sim=0.98828125\n",
      "retain_cosine_sim=0.9921875\n",
      "Topic 0 updated_forget_activations.norm= 26.25\n",
      "Topic 0 frozen_forget_activations.norm= 28.0\n",
      "Topic 0 updated_retain_activations.norm= 20.375\n",
      "Topic 0 frozen_retain_activations.norm= 21.5\n",
      " 85%|██████████████████████████████████▋      | 127/150 [00:31<00:05,  4.30it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 232, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.977 | unlearn_loss: 1.969 | retain_loss: 0.0047 | param_change: 2.131e-06\n",
      "unlearn_cosine_sim=0.921875\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 19.25\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 25.125\n",
      "Topic 0 frozen_retain_activations.norm= 26.0\n",
      " 85%|██████████████████████████████████▉      | 128/150 [00:31<00:05,  4.28it/s]loss: 2.734 | unlearn_loss: 2.719 | retain_loss: 0.01941 | param_change: 5.841e-06\n",
      "unlearn_cosine_sim=0.984375\n",
      "retain_cosine_sim=0.98828125\n",
      "Topic 0 updated_forget_activations.norm= 23.25\n",
      "Topic 0 frozen_forget_activations.norm= 25.0\n",
      "Topic 0 updated_retain_activations.norm= 26.5\n",
      "Topic 0 frozen_retain_activations.norm= 27.75\n",
      " 86%|███████████████████████████████████▎     | 129/150 [00:32<00:04,  4.40it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 218, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.094 | unlearn_loss: 2.078 | retain_loss: 0.0141 | param_change: 5.126e-06\n",
      "unlearn_cosine_sim=0.890625\n",
      "retain_cosine_sim=0.9921875\n",
      "Topic 0 updated_forget_activations.norm= 19.25\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 23.75\n",
      "Topic 0 frozen_retain_activations.norm= 24.875\n",
      " 87%|███████████████████████████████████▌     | 130/150 [00:32<00:04,  4.36it/s]loss: 2.438 | unlearn_loss: 2.438 | retain_loss: 0.004181 | param_change: 2.429e-06\n",
      "unlearn_cosine_sim=0.96484375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 21.25\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 24.625\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 87%|███████████████████████████████████▊     | 131/150 [00:32<00:04,  4.39it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 112, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 4 | unlearn_loss: 4 | retain_loss: 0.004669 | param_change: 2.444e-06\n",
      "unlearn_cosine_sim=0.94921875\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 26.5\n",
      "Topic 0 frozen_forget_activations.norm= 29.375\n",
      "Topic 0 updated_retain_activations.norm= 25.75\n",
      "Topic 0 frozen_retain_activations.norm= 26.5\n",
      " 88%|████████████████████████████████████     | 132/150 [00:32<00:04,  4.48it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 329, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.398 | unlearn_loss: 1.391 | retain_loss: 0.0047 | param_change: 2.235e-06\n",
      "unlearn_cosine_sim=0.94140625\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 17.75\n",
      "Topic 0 frozen_forget_activations.norm= 20.375\n",
      "Topic 0 updated_retain_activations.norm= 26.5\n",
      "Topic 0 frozen_retain_activations.norm= 27.125\n",
      " 89%|████████████████████████████████████▎    | 133/150 [00:33<00:04,  4.19it/s]loss: 2.391 | unlearn_loss: 2.391 | retain_loss: 0.005615 | param_change: 2.578e-06\n",
      "unlearn_cosine_sim=0.9765625\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 21.25\n",
      "Topic 0 frozen_forget_activations.norm= 23.5\n",
      "Topic 0 updated_retain_activations.norm= 20.75\n",
      "Topic 0 frozen_retain_activations.norm= 21.625\n",
      " 89%|████████████████████████████████████▋    | 134/150 [00:33<00:03,  4.12it/s]loss: 2.25 | unlearn_loss: 2.25 | retain_loss: 0.007172 | param_change: 3.07e-06\n",
      "unlearn_cosine_sim=0.98046875\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 21.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.0\n",
      "Topic 0 updated_retain_activations.norm= 27.75\n",
      "Topic 0 frozen_retain_activations.norm= 28.625\n",
      " 90%|████████████████████████████████████▉    | 135/150 [00:33<00:03,  4.23it/s]loss: 2.156 | unlearn_loss: 2.156 | retain_loss: 0.004425 | param_change: 1.997e-06\n",
      "unlearn_cosine_sim=0.95703125\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 20.0\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 22.5\n",
      "Topic 0 frozen_retain_activations.norm= 23.25\n",
      " 91%|█████████████████████████████████████▏   | 136/150 [00:33<00:03,  4.20it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 224, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.031 | unlearn_loss: 2.031 | retain_loss: 0.006775 | param_change: 3.397e-06\n",
      "unlearn_cosine_sim=0.98828125\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 20.5\n",
      "Topic 0 frozen_forget_activations.norm= 22.125\n",
      "Topic 0 updated_retain_activations.norm= 29.0\n",
      "Topic 0 frozen_retain_activations.norm= 29.75\n",
      " 91%|█████████████████████████████████████▍   | 137/150 [00:33<00:03,  4.27it/s]loss: 2.734 | unlearn_loss: 2.719 | retain_loss: 0.0116 | param_change: 3.144e-06\n",
      "unlearn_cosine_sim=0.9765625\n",
      "retain_cosine_sim=0.9921875\n",
      "Topic 0 updated_forget_activations.norm= 22.25\n",
      "Topic 0 frozen_forget_activations.norm= 24.5\n",
      "Topic 0 updated_retain_activations.norm= 19.5\n",
      "Topic 0 frozen_retain_activations.norm= 20.5\n",
      " 92%|█████████████████████████████████████▋   | 138/150 [00:34<00:02,  4.08it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 250, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.828 | unlearn_loss: 1.82 | retain_loss: 0.004791 | param_change: 2.429e-06\n",
      "unlearn_cosine_sim=0.97265625\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 19.0\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 25.125\n",
      "Topic 0 frozen_retain_activations.norm= 25.875\n",
      " 93%|█████████████████████████████████████▉   | 139/150 [00:34<00:02,  4.07it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 138, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.25 | unlearn_loss: 3.25 | retain_loss: 0.006775 | param_change: 2.31e-06\n",
      "unlearn_cosine_sim=0.9453125\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 23.625\n",
      "Topic 0 frozen_forget_activations.norm= 26.5\n",
      "Topic 0 updated_retain_activations.norm= 22.25\n",
      "Topic 0 frozen_retain_activations.norm= 23.25\n",
      " 93%|██████████████████████████████████████▎  | 140/150 [00:34<00:02,  4.20it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 216, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.094 | unlearn_loss: 2.094 | retain_loss: 0.003433 | param_change: 2.429e-06\n",
      "unlearn_cosine_sim=0.9453125\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 20.0\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 25.0\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 94%|██████████████████████████████████████▌  | 141/150 [00:34<00:02,  4.23it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 311, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.5 | unlearn_loss: 1.492 | retain_loss: 0.006989 | param_change: 3.025e-06\n",
      "unlearn_cosine_sim=0.9765625\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 18.5\n",
      "Topic 0 frozen_forget_activations.norm= 20.75\n",
      "Topic 0 updated_retain_activations.norm= 24.5\n",
      "Topic 0 frozen_retain_activations.norm= 25.5\n",
      " 95%|██████████████████████████████████████▊  | 142/150 [00:35<00:01,  4.06it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 331, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.383 | unlearn_loss: 1.383 | retain_loss: 0.002975 | param_change: 2.325e-06\n",
      "unlearn_cosine_sim=0.94140625\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 17.5\n",
      "Topic 0 frozen_forget_activations.norm= 20.25\n",
      "Topic 0 updated_retain_activations.norm= 25.75\n",
      "Topic 0 frozen_retain_activations.norm= 26.25\n",
      " 95%|███████████████████████████████████████  | 143/150 [00:35<00:01,  3.91it/s]loss: 2.203 | unlearn_loss: 2.203 | retain_loss: 0.004089 | param_change: 2.295e-06\n",
      "unlearn_cosine_sim=0.98046875\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 21.0\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 24.0\n",
      "Topic 0 frozen_retain_activations.norm= 24.5\n",
      " 96%|███████████████████████████████████████▎ | 144/150 [00:35<00:01,  4.02it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 115, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.891 | unlearn_loss: 3.891 | retain_loss: 0.007324 | param_change: 3.055e-06\n",
      "unlearn_cosine_sim=0.91796875\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 25.75\n",
      "Topic 0 frozen_forget_activations.norm= 29.0\n",
      "Topic 0 updated_retain_activations.norm= 21.625\n",
      "Topic 0 frozen_retain_activations.norm= 22.5\n",
      " 97%|███████████████████████████████████████▋ | 145/150 [00:35<00:01,  4.14it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 171, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.641 | unlearn_loss: 2.641 | retain_loss: 0.003265 | param_change: 2.071e-06\n",
      "unlearn_cosine_sim=0.95703125\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.25\n",
      "Topic 0 frozen_forget_activations.norm= 24.5\n",
      "Topic 0 updated_retain_activations.norm= 24.75\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 97%|███████████████████████████████████████▉ | 146/150 [00:36<00:00,  4.24it/s]loss: 2.312 | unlearn_loss: 2.297 | retain_loss: 0.008728 | param_change: 3.934e-06\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 21.875\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 20.0\n",
      "Topic 0 frozen_retain_activations.norm= 21.125\n",
      " 98%|████████████████████████████████████████▏| 147/150 [00:36<00:00,  4.04it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 147, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.078 | unlearn_loss: 3.062 | retain_loss: 0.007996 | param_change: 2.936e-06\n",
      "unlearn_cosine_sim=0.9375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 23.0\n",
      "Topic 0 frozen_forget_activations.norm= 25.875\n",
      "Topic 0 updated_retain_activations.norm= 23.0\n",
      "Topic 0 frozen_retain_activations.norm= 24.0\n",
      " 99%|████████████████████████████████████████▍| 148/150 [00:36<00:00,  4.17it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 318, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.461 | unlearn_loss: 1.453 | retain_loss: 0.004211 | param_change: 2.354e-06\n",
      "unlearn_cosine_sim=0.984375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 18.25\n",
      "Topic 0 frozen_forget_activations.norm= 20.0\n",
      "Topic 0 updated_retain_activations.norm= 23.75\n",
      "Topic 0 frozen_retain_activations.norm= 24.5\n",
      " 99%|████████████████████████████████████████▋| 149/150 [00:36<00:00,  4.01it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 210, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.234 | unlearn_loss: 2.156 | retain_loss: 0.07666 | param_change: 1.353e-05\n",
      "unlearn_cosine_sim=0.96875\n",
      "retain_cosine_sim=0.94140625\n",
      "Topic 0 updated_forget_activations.norm= 20.25\n",
      "Topic 0 frozen_forget_activations.norm= 22.5\n",
      "Topic 0 updated_retain_activations.norm= 18.0\n",
      "Topic 0 frozen_retain_activations.norm= 20.25\n",
      "100%|█████████████████████████████████████████| 150/150 [00:37<00:00,  4.03it/s]\n",
      "Saved model to models/alpaca_rmu_alpha_10\n"
     ]
    }
   ],
   "source": [
    "!python3 -m rmu.unlearn --model_name PKU-Alignment/alpaca-7b-reproduced --max_num_batches 150 --batch_size=2 --retain_corpora SafeRLHF-corpora/safe_train_sampled --forget_corpora SafeRLHF-corpora/Privacy_Violation_train --layer_id 7 --steering_coeffs 6.5 --alpha 10 --lr 1e-4 --seed 42 --output_dir models/alpaca_rmu_alpha_10 --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [01:10<00:00, 10.04s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [00:17<00:00,  2.48s/it]\n",
      "====rmu Config====\n",
      "model_name_or_path=PKU-Alignment/alpaca-7b-reproduced\n",
      "module_str={model_name}.model.layers[{layer_id}]\n",
      "output_dir=models/alpaca_rmu_alpha_100\n",
      "retain_corpora=['SafeRLHF-corpora/safe_train_sampled']\n",
      "forget_corpora=['SafeRLHF-corpora/Privacy_Violation_train']\n",
      "alpha=[100.0]\n",
      "steering_coeffs=6.5\n",
      "lr=0.0001\n",
      "min_len=0\n",
      "max_len=2000\n",
      "batch_size=2\n",
      "max_num_batches=150\n",
      "layer_id=7\n",
      "layer_ids=[5, 6, 7]\n",
      "param_ids=[6]\n",
      "seed=42\n",
      "verbose=True\n",
      "steering_coeff_list=[6.5]\n",
      "=====\n",
      "/home/hice1/jli928/.conda/envs/model-unlearning/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "======= Epoch 0 =======\n",
      "  0%|                                                   | 0/150 [00:00<?, ?it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 185, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.453 | unlearn_loss: 2.453 | retain_loss: 0 | param_change: 1.982e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.125\n",
      "Topic 0 frozen_forget_activations.norm= 23.125\n",
      "Topic 0 updated_retain_activations.norm= 23.5\n",
      "Topic 0 frozen_retain_activations.norm= 23.5\n",
      "  1%|▎                                          | 1/150 [00:01<02:57,  1.19s/it]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 170, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.672 | unlearn_loss: 2.672 | retain_loss: 0.0008354 | param_change: 4.411e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.375\n",
      "Topic 0 frozen_forget_activations.norm= 24.5\n",
      "Topic 0 updated_retain_activations.norm= 19.5\n",
      "Topic 0 frozen_retain_activations.norm= 19.5\n",
      "  1%|▌                                          | 2/150 [00:01<01:38,  1.51it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 199, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.297 | unlearn_loss: 2.297 | retain_loss: 0.002136 | param_change: 6.02e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.625\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 25.25\n",
      "Topic 0 frozen_retain_activations.norm= 25.5\n",
      "  2%|▊                                          | 3/150 [00:01<01:08,  2.15it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 251, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.836 | unlearn_loss: 1.836 | retain_loss: 0.0009003 | param_change: 2.995e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.5\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 23.0\n",
      "Topic 0 frozen_retain_activations.norm= 23.0\n",
      "  3%|█▏                                         | 4/150 [00:01<00:55,  2.61it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 190, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.391 | unlearn_loss: 2.391 | retain_loss: 0.0009842 | param_change: 2.98e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.125\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 23.875\n",
      "Topic 0 frozen_retain_activations.norm= 24.0\n",
      "  3%|█▍                                         | 5/150 [00:02<00:47,  3.07it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 243, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.891 | unlearn_loss: 1.891 | retain_loss: 0.0009193 | param_change: 2.861e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.75\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 24.25\n",
      "Topic 0 frozen_retain_activations.norm= 24.25\n",
      "  4%|█▋                                         | 6/150 [00:02<00:43,  3.34it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 293, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.594 | unlearn_loss: 1.594 | retain_loss: 0.0008583 | param_change: 2.578e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 20.5\n",
      "Topic 0 frozen_forget_activations.norm= 20.625\n",
      "Topic 0 updated_retain_activations.norm= 24.5\n",
      "Topic 0 frozen_retain_activations.norm= 24.5\n",
      "  5%|██                                         | 7/150 [00:02<00:41,  3.46it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 244, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.883 | unlearn_loss: 1.883 | retain_loss: 0.001434 | param_change: 4.739e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.5\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 25.0\n",
      "Topic 0 frozen_retain_activations.norm= 25.125\n",
      "  5%|██▎                                        | 8/150 [00:02<00:39,  3.63it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 162, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.797 | unlearn_loss: 2.797 | retain_loss: 0.002228 | param_change: 6.258e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.875\n",
      "Topic 0 frozen_forget_activations.norm= 25.125\n",
      "Topic 0 updated_retain_activations.norm= 25.5\n",
      "Topic 0 frozen_retain_activations.norm= 25.625\n",
      "  6%|██▌                                        | 9/150 [00:03<00:36,  3.88it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 219, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.094 | unlearn_loss: 2.094 | retain_loss: 0.001617 | param_change: 3.725e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.375\n",
      "Topic 0 frozen_forget_activations.norm= 22.5\n",
      "Topic 0 updated_retain_activations.norm= 22.25\n",
      "Topic 0 frozen_retain_activations.norm= 22.375\n",
      "  7%|██▊                                       | 10/150 [00:03<00:35,  3.93it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 151, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3 | unlearn_loss: 3 | retain_loss: 0.001373 | param_change: 3.219e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 25.5\n",
      "Topic 0 frozen_forget_activations.norm= 25.75\n",
      "Topic 0 updated_retain_activations.norm= 24.75\n",
      "Topic 0 frozen_retain_activations.norm= 24.75\n",
      "  7%|███                                       | 11/150 [00:03<00:33,  4.11it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 144, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.141 | unlearn_loss: 3.141 | retain_loss: 0.001617 | param_change: 3.725e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 25.5\n",
      "Topic 0 frozen_forget_activations.norm= 25.75\n",
      "Topic 0 updated_retain_activations.norm= 35.5\n",
      "Topic 0 frozen_retain_activations.norm= 35.5\n",
      "  8%|███▎                                      | 12/150 [00:03<00:33,  4.11it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 255, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.805 | unlearn_loss: 1.805 | retain_loss: 0.001297 | param_change: 2.906e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.25\n",
      "Topic 0 frozen_forget_activations.norm= 21.5\n",
      "Topic 0 updated_retain_activations.norm= 22.375\n",
      "Topic 0 frozen_retain_activations.norm= 22.5\n",
      "  9%|███▋                                      | 13/150 [00:04<00:34,  4.03it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 283, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.648 | unlearn_loss: 1.648 | retain_loss: 0.003265 | param_change: 6.229e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 20.75\n",
      "Topic 0 frozen_forget_activations.norm= 21.125\n",
      "Topic 0 updated_retain_activations.norm= 22.25\n",
      "Topic 0 frozen_retain_activations.norm= 22.25\n",
      "  9%|███▉                                      | 14/150 [00:04<00:34,  3.89it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 141, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.203 | unlearn_loss: 3.203 | retain_loss: 0.002106 | param_change: 6.139e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 25.5\n",
      "Topic 0 frozen_forget_activations.norm= 25.75\n",
      "Topic 0 updated_retain_activations.norm= 26.0\n",
      "Topic 0 frozen_retain_activations.norm= 26.0\n",
      " 10%|████▏                                     | 15/150 [00:04<00:32,  4.09it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 181, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.516 | unlearn_loss: 2.516 | retain_loss: 0.004639 | param_change: 8.106e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.75\n",
      "Topic 0 frozen_forget_activations.norm= 24.0\n",
      "Topic 0 updated_retain_activations.norm= 22.375\n",
      "Topic 0 frozen_retain_activations.norm= 22.5\n",
      " 11%|████▍                                     | 16/150 [00:04<00:32,  4.15it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 220, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.078 | unlearn_loss: 2.078 | retain_loss: 0.002014 | param_change: 4.56e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.0\n",
      "Topic 0 frozen_forget_activations.norm= 22.125\n",
      "Topic 0 updated_retain_activations.norm= 23.375\n",
      "Topic 0 frozen_retain_activations.norm= 23.5\n",
      " 11%|████▊                                     | 17/150 [00:05<00:31,  4.17it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 231, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2 | unlearn_loss: 2 | retain_loss: 0.00174 | param_change: 4.828e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.75\n",
      "Topic 0 frozen_forget_activations.norm= 21.875\n",
      "Topic 0 updated_retain_activations.norm= 22.375\n",
      "Topic 0 frozen_retain_activations.norm= 22.375\n",
      " 12%|█████                                     | 18/150 [00:05<00:32,  4.11it/s]loss: 3.141 | unlearn_loss: 3.141 | retain_loss: 0.003128 | param_change: 8.285e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 25.75\n",
      "Topic 0 frozen_forget_activations.norm= 26.0\n",
      "Topic 0 updated_retain_activations.norm= 25.0\n",
      "Topic 0 frozen_retain_activations.norm= 25.125\n",
      " 13%|█████▎                                    | 19/150 [00:05<00:30,  4.25it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 153, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.953 | unlearn_loss: 2.953 | retain_loss: 0.002197 | param_change: 6.586e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 25.25\n",
      "Topic 0 frozen_forget_activations.norm= 25.5\n",
      "Topic 0 updated_retain_activations.norm= 24.0\n",
      "Topic 0 frozen_retain_activations.norm= 24.25\n",
      " 13%|█████▌                                    | 20/150 [00:05<00:30,  4.33it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 217, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.109 | unlearn_loss: 2.109 | retain_loss: 0.002319 | param_change: 6.914e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.25\n",
      "Topic 0 frozen_forget_activations.norm= 22.5\n",
      "Topic 0 updated_retain_activations.norm= 23.75\n",
      "Topic 0 frozen_retain_activations.norm= 23.75\n",
      " 14%|█████▉                                    | 21/150 [00:06<00:29,  4.31it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 197, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.312 | unlearn_loss: 2.312 | retain_loss: 0.001717 | param_change: 4.47e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.25\n",
      "Topic 0 frozen_forget_activations.norm= 23.5\n",
      "Topic 0 updated_retain_activations.norm= 32.5\n",
      "Topic 0 frozen_retain_activations.norm= 32.75\n",
      " 15%|██████▏                                   | 22/150 [00:06<00:29,  4.39it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 195, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.344 | unlearn_loss: 2.344 | retain_loss: 0.003052 | param_change: 6.169e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.25\n",
      "Topic 0 frozen_forget_activations.norm= 23.5\n",
      "Topic 0 updated_retain_activations.norm= 22.5\n",
      "Topic 0 frozen_retain_activations.norm= 22.625\n",
      " 15%|██████▍                                   | 23/150 [00:06<00:29,  4.31it/s]loss: 1.812 | unlearn_loss: 1.805 | retain_loss: 0.008606 | param_change: 1.395e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.0\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 33.0\n",
      "Topic 0 frozen_retain_activations.norm= 33.5\n",
      " 16%|██████▋                                   | 24/150 [00:06<00:29,  4.30it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 201, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.281 | unlearn_loss: 2.266 | retain_loss: 0.01068 | param_change: 1.359e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 23.375\n",
      "Topic 0 frozen_retain_activations.norm= 23.75\n",
      " 17%|███████                                   | 25/150 [00:06<00:29,  4.29it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 252, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.828 | unlearn_loss: 1.82 | retain_loss: 0.005371 | param_change: 8.702e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.25\n",
      "Topic 0 frozen_forget_activations.norm= 21.5\n",
      "Topic 0 updated_retain_activations.norm= 27.5\n",
      "Topic 0 frozen_retain_activations.norm= 27.625\n",
      " 17%|███████▎                                  | 26/150 [00:07<00:29,  4.25it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 205, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.234 | unlearn_loss: 2.234 | retain_loss: 0.004883 | param_change: 1.252e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 35.0\n",
      "Topic 0 frozen_retain_activations.norm= 35.0\n",
      " 18%|███████▌                                  | 27/150 [00:07<00:28,  4.35it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 187, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.438 | unlearn_loss: 2.438 | retain_loss: 0.003784 | param_change: 8.225e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.5\n",
      "Topic 0 frozen_forget_activations.norm= 24.0\n",
      "Topic 0 updated_retain_activations.norm= 23.0\n",
      "Topic 0 frozen_retain_activations.norm= 23.0\n",
      " 19%|███████▊                                  | 28/150 [00:07<00:28,  4.32it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 176, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.578 | unlearn_loss: 2.578 | retain_loss: 0.006195 | param_change: 1.109e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.0\n",
      "Topic 0 frozen_forget_activations.norm= 24.25\n",
      "Topic 0 updated_retain_activations.norm= 22.5\n",
      "Topic 0 frozen_retain_activations.norm= 22.5\n",
      " 19%|████████                                  | 29/150 [00:07<00:28,  4.30it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 84, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 5.25 | unlearn_loss: 5.25 | retain_loss: 0.004333 | param_change: 1.085e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 32.5\n",
      "Topic 0 frozen_forget_activations.norm= 32.75\n",
      "Topic 0 updated_retain_activations.norm= 22.0\n",
      "Topic 0 frozen_retain_activations.norm= 22.0\n",
      " 20%|████████▍                                 | 30/150 [00:08<00:27,  4.34it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 198, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.297 | unlearn_loss: 2.297 | retain_loss: 0.004303 | param_change: 7.242e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.875\n",
      "Topic 0 frozen_forget_activations.norm= 23.0\n",
      "Topic 0 updated_retain_activations.norm= 23.75\n",
      "Topic 0 frozen_retain_activations.norm= 24.0\n",
      " 21%|████████▋                                 | 31/150 [00:08<00:27,  4.34it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 212, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.156 | unlearn_loss: 2.156 | retain_loss: 0.005188 | param_change: 7.987e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.25\n",
      "Topic 0 frozen_forget_activations.norm= 22.5\n",
      "Topic 0 updated_retain_activations.norm= 21.25\n",
      "Topic 0 frozen_retain_activations.norm= 21.375\n",
      " 21%|████████▉                                 | 32/150 [00:08<00:28,  4.18it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 242, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.898 | unlearn_loss: 1.898 | retain_loss: 0.002533 | param_change: 4.381e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.75\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 27.0\n",
      "Topic 0 frozen_retain_activations.norm= 27.125\n",
      " 22%|█████████▏                                | 33/150 [00:08<00:28,  4.17it/s]loss: 2.219 | unlearn_loss: 2.219 | retain_loss: 0.002869 | param_change: 5.603e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.5\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 25.5\n",
      "Topic 0 frozen_retain_activations.norm= 25.75\n",
      " 23%|█████████▌                                | 34/150 [00:09<00:27,  4.22it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 175, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.594 | unlearn_loss: 2.594 | retain_loss: 0.007812 | param_change: 1.252e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.0\n",
      "Topic 0 frozen_forget_activations.norm= 24.375\n",
      "Topic 0 updated_retain_activations.norm= 19.5\n",
      "Topic 0 frozen_retain_activations.norm= 19.5\n",
      " 23%|█████████▊                                | 35/150 [00:09<00:28,  3.98it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 182, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.5 | unlearn_loss: 2.5 | retain_loss: 0.002747 | param_change: 5.126e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.5\n",
      "Topic 0 frozen_forget_activations.norm= 24.0\n",
      "Topic 0 updated_retain_activations.norm= 23.75\n",
      "Topic 0 frozen_retain_activations.norm= 23.75\n",
      " 24%|██████████                                | 36/150 [00:09<00:27,  4.10it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 172, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.641 | unlearn_loss: 2.641 | retain_loss: 0.003387 | param_change: 6.199e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.75\n",
      "Topic 0 frozen_forget_activations.norm= 24.25\n",
      "Topic 0 updated_retain_activations.norm= 25.75\n",
      "Topic 0 frozen_retain_activations.norm= 26.0\n",
      " 25%|██████████▎                               | 37/150 [00:09<00:26,  4.23it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 189, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.422 | unlearn_loss: 2.406 | retain_loss: 0.01154 | param_change: 1.729e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.125\n",
      "Topic 0 frozen_forget_activations.norm= 23.5\n",
      "Topic 0 updated_retain_activations.norm= 24.625\n",
      "Topic 0 frozen_retain_activations.norm= 24.75\n",
      " 25%|██████████▋                               | 38/150 [00:10<00:26,  4.31it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 225, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.047 | unlearn_loss: 2.047 | retain_loss: 0.006714 | param_change: 1.174e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.875\n",
      "Topic 0 frozen_forget_activations.norm= 22.125\n",
      "Topic 0 updated_retain_activations.norm= 26.0\n",
      "Topic 0 frozen_retain_activations.norm= 26.0\n",
      " 26%|██████████▉                               | 39/150 [00:10<00:25,  4.29it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 113, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.984 | unlearn_loss: 3.984 | retain_loss: 0.007538 | param_change: 1.15e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 28.0\n",
      "Topic 0 frozen_forget_activations.norm= 28.25\n",
      "Topic 0 updated_retain_activations.norm= 25.25\n",
      "Topic 0 frozen_retain_activations.norm= 25.5\n",
      " 27%|███████████▏                              | 40/150 [00:10<00:24,  4.42it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 119, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.797 | unlearn_loss: 3.781 | retain_loss: 0.00946 | param_change: 1.067e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 27.75\n",
      "Topic 0 frozen_forget_activations.norm= 28.25\n",
      "Topic 0 updated_retain_activations.norm= 25.0\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 27%|███████████▍                              | 41/150 [00:10<00:24,  4.51it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 174, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.609 | unlearn_loss: 2.609 | retain_loss: 0.004059 | param_change: 7.063e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.375\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 20.0\n",
      "Topic 0 frozen_retain_activations.norm= 20.0\n",
      " 28%|███████████▊                              | 42/150 [00:10<00:25,  4.18it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 248, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.859 | unlearn_loss: 1.852 | retain_loss: 0.00824 | param_change: 1.585e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.375\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 26.75\n",
      "Topic 0 frozen_retain_activations.norm= 26.875\n",
      " 29%|████████████                              | 43/150 [00:11<00:25,  4.16it/s]loss: 1.812 | unlearn_loss: 1.805 | retain_loss: 0.005737 | param_change: 8.881e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.25\n",
      "Topic 0 frozen_forget_activations.norm= 21.5\n",
      "Topic 0 updated_retain_activations.norm= 22.625\n",
      "Topic 0 frozen_retain_activations.norm= 22.625\n",
      " 29%|████████████▎                             | 44/150 [00:11<00:26,  4.05it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 164, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.766 | unlearn_loss: 2.766 | retain_loss: 0.007019 | param_change: 1.085e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.25\n",
      "Topic 0 frozen_forget_activations.norm= 24.75\n",
      "Topic 0 updated_retain_activations.norm= 25.25\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 30%|████████████▌                             | 45/150 [00:11<00:25,  4.20it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 339, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.383 | unlearn_loss: 1.375 | retain_loss: 0.007263 | param_change: 9.477e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 19.875\n",
      "Topic 0 frozen_forget_activations.norm= 20.125\n",
      "Topic 0 updated_retain_activations.norm= 21.625\n",
      "Topic 0 frozen_retain_activations.norm= 21.75\n",
      " 31%|████████████▉                             | 46/150 [00:12<00:29,  3.57it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 177, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.562 | unlearn_loss: 2.562 | retain_loss: 0.004517 | param_change: 6.735e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.375\n",
      "Topic 0 frozen_forget_activations.norm= 23.875\n",
      "Topic 0 updated_retain_activations.norm= 21.25\n",
      "Topic 0 frozen_retain_activations.norm= 21.375\n",
      " 31%|█████████████▏                            | 47/150 [00:12<00:27,  3.69it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 206, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.219 | unlearn_loss: 2.219 | retain_loss: 0.007538 | param_change: 8.702e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.5\n",
      "Topic 0 frozen_forget_activations.norm= 23.0\n",
      "Topic 0 updated_retain_activations.norm= 30.5\n",
      "Topic 0 frozen_retain_activations.norm= 30.75\n",
      " 32%|█████████████▍                            | 48/150 [00:12<00:26,  3.91it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 156, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.906 | unlearn_loss: 2.906 | retain_loss: 0.004211 | param_change: 7.689e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 25.0\n",
      "Topic 0 frozen_forget_activations.norm= 25.625\n",
      "Topic 0 updated_retain_activations.norm= 25.125\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 33%|█████████████▋                            | 49/150 [00:12<00:24,  4.09it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 111, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 4.062 | unlearn_loss: 4.062 | retain_loss: 0.01147 | param_change: 1.216e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 28.5\n",
      "Topic 0 frozen_forget_activations.norm= 28.75\n",
      "Topic 0 updated_retain_activations.norm= 34.75\n",
      "Topic 0 frozen_retain_activations.norm= 35.0\n",
      " 33%|██████████████                            | 50/150 [00:12<00:23,  4.23it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 209, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.188 | unlearn_loss: 2.188 | retain_loss: 0.00705 | param_change: 1.371e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.375\n",
      "Topic 0 frozen_forget_activations.norm= 22.875\n",
      "Topic 0 updated_retain_activations.norm= 31.25\n",
      "Topic 0 frozen_retain_activations.norm= 31.25\n",
      " 34%|██████████████▎                           | 51/150 [00:13<00:22,  4.32it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 240, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.938 | unlearn_loss: 1.93 | retain_loss: 0.0108 | param_change: 1.585e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.625\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 21.625\n",
      "Topic 0 frozen_retain_activations.norm= 21.75\n",
      " 35%|██████████████▌                           | 52/150 [00:13<00:23,  4.16it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 79, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 5.594 | unlearn_loss: 5.594 | retain_loss: 0.005951 | param_change: 1.168e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 33.75\n",
      "Topic 0 frozen_forget_activations.norm= 34.0\n",
      "Topic 0 updated_retain_activations.norm= 29.5\n",
      "Topic 0 frozen_retain_activations.norm= 29.5\n",
      " 35%|██████████████▊                           | 53/150 [00:13<00:22,  4.40it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 264, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.766 | unlearn_loss: 1.758 | retain_loss: 0.009888 | param_change: 1.198e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.25\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 21.875\n",
      "Topic 0 frozen_retain_activations.norm= 22.0\n",
      " 36%|███████████████                           | 54/150 [00:13<00:23,  4.12it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 226, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.047 | unlearn_loss: 2.047 | retain_loss: 0.006042 | param_change: 8.523e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.5\n",
      "Topic 0 frozen_forget_activations.norm= 22.25\n",
      "Topic 0 updated_retain_activations.norm= 26.75\n",
      "Topic 0 frozen_retain_activations.norm= 26.875\n",
      " 37%|███████████████▍                          | 55/150 [00:14<00:22,  4.16it/s]loss: 2.391 | unlearn_loss: 2.391 | retain_loss: 0.005829 | param_change: 1.025e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 26.25\n",
      "Topic 0 frozen_retain_activations.norm= 26.25\n",
      " 37%|███████████████▋                          | 56/150 [00:14<00:22,  4.23it/s]loss: 2.516 | unlearn_loss: 2.5 | retain_loss: 0.02014 | param_change: 2.122e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.5\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 22.25\n",
      "Topic 0 frozen_retain_activations.norm= 22.75\n",
      " 38%|███████████████▉                          | 57/150 [00:14<00:22,  4.23it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 150, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.031 | unlearn_loss: 3.016 | retain_loss: 0.01001 | param_change: 9.298e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.75\n",
      "Topic 0 frozen_forget_activations.norm= 25.25\n",
      "Topic 0 updated_retain_activations.norm= 23.875\n",
      "Topic 0 frozen_retain_activations.norm= 24.25\n",
      " 39%|████████████████▏                         | 58/150 [00:14<00:21,  4.31it/s]loss: 2.219 | unlearn_loss: 2.219 | retain_loss: 0.007019 | param_change: 1.216e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.0\n",
      "Topic 0 updated_retain_activations.norm= 26.0\n",
      "Topic 0 frozen_retain_activations.norm= 26.0\n",
      " 39%|████████████████▌                         | 59/150 [00:15<00:21,  4.32it/s]loss: 2.125 | unlearn_loss: 2.109 | retain_loss: 0.02039 | param_change: 2.337e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.75\n",
      "Topic 0 frozen_forget_activations.norm= 22.125\n",
      "Topic 0 updated_retain_activations.norm= 24.75\n",
      "Topic 0 frozen_retain_activations.norm= 24.75\n",
      " 40%|████████████████▊                         | 60/150 [00:15<00:20,  4.30it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 135, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.359 | unlearn_loss: 3.344 | retain_loss: 0.01831 | param_change: 2.038e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 26.0\n",
      "Topic 0 frozen_forget_activations.norm= 26.5\n",
      "Topic 0 updated_retain_activations.norm= 27.75\n",
      "Topic 0 frozen_retain_activations.norm= 27.75\n",
      " 41%|█████████████████                         | 61/150 [00:15<00:20,  4.45it/s]loss: 2.531 | unlearn_loss: 2.516 | retain_loss: 0.008789 | param_change: 1.15e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.125\n",
      "Topic 0 frozen_forget_activations.norm= 23.5\n",
      "Topic 0 updated_retain_activations.norm= 23.875\n",
      "Topic 0 frozen_retain_activations.norm= 24.0\n",
      " 41%|█████████████████▎                        | 62/150 [00:15<00:19,  4.45it/s]loss: 1.945 | unlearn_loss: 1.93 | retain_loss: 0.01526 | param_change: 1.633e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.25\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 22.375\n",
      "Topic 0 frozen_retain_activations.norm= 22.5\n",
      " 42%|█████████████████▋                        | 63/150 [00:15<00:20,  4.29it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 102, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 4.406 | unlearn_loss: 4.406 | retain_loss: 0.00885 | param_change: 1.353e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 30.0\n",
      "Topic 0 frozen_forget_activations.norm= 30.25\n",
      "Topic 0 updated_retain_activations.norm= 23.25\n",
      "Topic 0 frozen_retain_activations.norm= 23.375\n",
      " 43%|█████████████████▉                        | 64/150 [00:16<00:19,  4.34it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 180, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.531 | unlearn_loss: 2.516 | retain_loss: 0.009888 | param_change: 1.383e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.125\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 25.0\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 43%|██████████████████▏                       | 65/150 [00:16<00:19,  4.40it/s]loss: 2.812 | unlearn_loss: 2.797 | retain_loss: 0.007874 | param_change: 9.954e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.5\n",
      "Topic 0 frozen_forget_activations.norm= 24.75\n",
      "Topic 0 updated_retain_activations.norm= 25.75\n",
      "Topic 0 frozen_retain_activations.norm= 25.875\n",
      " 44%|██████████████████▍                       | 66/150 [00:16<00:18,  4.46it/s]loss: 1.844 | unlearn_loss: 1.836 | retain_loss: 0.01013 | param_change: 1.305e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.75\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 22.5\n",
      "Topic 0 frozen_retain_activations.norm= 22.75\n",
      " 45%|██████████████████▊                       | 67/150 [00:16<00:19,  4.25it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 146, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.109 | unlearn_loss: 3.094 | retain_loss: 0.02332 | param_change: 2.217e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 25.0\n",
      "Topic 0 frozen_forget_activations.norm= 25.75\n",
      "Topic 0 updated_retain_activations.norm= 20.25\n",
      "Topic 0 frozen_retain_activations.norm= 20.375\n",
      " 45%|███████████████████                       | 68/150 [00:17<00:21,  3.90it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 184, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.484 | unlearn_loss: 2.469 | retain_loss: 0.01477 | param_change: 1.478e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.5\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 26.25\n",
      "Topic 0 frozen_retain_activations.norm= 26.375\n",
      " 46%|███████████████████▎                      | 69/150 [00:17<00:19,  4.08it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 281, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.688 | unlearn_loss: 1.68 | retain_loss: 0.01123 | param_change: 1.132e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 20.875\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 25.0\n",
      "Topic 0 frozen_retain_activations.norm= 25.125\n",
      " 47%|███████████████████▌                      | 70/150 [00:17<00:20,  3.99it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 223, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.078 | unlearn_loss: 2.047 | retain_loss: 0.03882 | param_change: 3.815e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 22.0\n",
      "Topic 0 frozen_forget_activations.norm= 22.375\n",
      "Topic 0 updated_retain_activations.norm= 23.75\n",
      "Topic 0 frozen_retain_activations.norm= 24.0\n",
      " 47%|███████████████████▉                      | 71/150 [00:17<00:19,  4.05it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 158, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.875 | unlearn_loss: 2.859 | retain_loss: 0.01135 | param_change: 8.404e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.5\n",
      "Topic 0 frozen_forget_activations.norm= 25.25\n",
      "Topic 0 updated_retain_activations.norm= 20.75\n",
      "Topic 0 frozen_retain_activations.norm= 21.0\n",
      " 48%|████████████████████▏                     | 72/150 [00:18<00:19,  3.96it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 228, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.047 | unlearn_loss: 2.031 | retain_loss: 0.0141 | param_change: 1.293e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.625\n",
      "Topic 0 frozen_forget_activations.norm= 22.25\n",
      "Topic 0 updated_retain_activations.norm= 26.0\n",
      "Topic 0 frozen_retain_activations.norm= 26.25\n",
      " 49%|████████████████████▍                     | 73/150 [00:18<00:19,  4.04it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 324, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.469 | unlearn_loss: 1.453 | retain_loss: 0.01294 | param_change: 1.156e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 20.0\n",
      "Topic 0 frozen_forget_activations.norm= 20.75\n",
      "Topic 0 updated_retain_activations.norm= 30.125\n",
      "Topic 0 frozen_retain_activations.norm= 30.25\n",
      " 49%|████████████████████▋                     | 74/150 [00:18<00:19,  3.95it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 163, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.797 | unlearn_loss: 2.781 | retain_loss: 0.0177 | param_change: 1.848e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.5\n",
      "Topic 0 frozen_forget_activations.norm= 24.75\n",
      "Topic 0 updated_retain_activations.norm= 24.125\n",
      "Topic 0 frozen_retain_activations.norm= 24.25\n",
      " 50%|█████████████████████                     | 75/150 [00:18<00:18,  4.10it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 265, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.766 | unlearn_loss: 1.75 | retain_loss: 0.01373 | param_change: 1.895e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.0\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 21.0\n",
      "Topic 0 frozen_retain_activations.norm= 21.0\n",
      " 51%|█████████████████████▎                    | 76/150 [00:19<00:19,  3.81it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 207, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.234 | unlearn_loss: 2.203 | retain_loss: 0.02417 | param_change: 1.55e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 22.5\n",
      "Topic 0 frozen_forget_activations.norm= 23.0\n",
      "Topic 0 updated_retain_activations.norm= 21.75\n",
      "Topic 0 frozen_retain_activations.norm= 21.75\n",
      " 51%|█████████████████████▌                    | 77/150 [00:19<00:18,  3.86it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 179, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.547 | unlearn_loss: 2.531 | retain_loss: 0.01233 | param_change: 1.305e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.125\n",
      "Topic 0 frozen_forget_activations.norm= 23.625\n",
      "Topic 0 updated_retain_activations.norm= 23.25\n",
      "Topic 0 frozen_retain_activations.norm= 23.125\n",
      " 52%|█████████████████████▊                    | 78/150 [00:19<00:18,  3.98it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 152, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.016 | unlearn_loss: 2.984 | retain_loss: 0.02747 | param_change: 1.478e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 25.375\n",
      "Topic 0 frozen_forget_activations.norm= 25.875\n",
      "Topic 0 updated_retain_activations.norm= 22.75\n",
      "Topic 0 frozen_retain_activations.norm= 23.25\n",
      " 53%|██████████████████████                    | 79/150 [00:19<00:17,  4.08it/s]loss: 2.469 | unlearn_loss: 2.453 | retain_loss: 0.01196 | param_change: 1.043e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.5\n",
      "Topic 0 frozen_forget_activations.norm= 24.25\n",
      "Topic 0 updated_retain_activations.norm= 21.625\n",
      "Topic 0 frozen_retain_activations.norm= 21.625\n",
      " 53%|██████████████████████▍                   | 80/150 [00:20<00:17,  3.99it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 188, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.5 | unlearn_loss: 2.422 | retain_loss: 0.08203 | param_change: 4.005e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.9921875\n",
      "Topic 0 updated_forget_activations.norm= 23.125\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 20.25\n",
      "Topic 0 frozen_retain_activations.norm= 20.125\n",
      " 54%|██████████████████████▋                   | 81/150 [00:20<00:18,  3.71it/s]loss: 2.922 | unlearn_loss: 2.906 | retain_loss: 0.01056 | param_change: 1.174e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 25.0\n",
      "Topic 0 frozen_forget_activations.norm= 25.5\n",
      "Topic 0 updated_retain_activations.norm= 27.5\n",
      "Topic 0 frozen_retain_activations.norm= 27.625\n",
      " 55%|██████████████████████▉                   | 82/150 [00:20<00:17,  3.97it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 192, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.391 | unlearn_loss: 2.375 | retain_loss: 0.01514 | param_change: 1.258e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 24.875\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 55%|███████████████████████▏                  | 83/150 [00:20<00:16,  4.12it/s]loss: 2.062 | unlearn_loss: 2.047 | retain_loss: 0.01184 | param_change: 9.954e-06\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.5\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 25.625\n",
      "Topic 0 frozen_retain_activations.norm= 25.75\n",
      " 56%|███████████████████████▌                  | 84/150 [00:21<00:15,  4.16it/s]loss: 3.109 | unlearn_loss: 3.094 | retain_loss: 0.01843 | param_change: 1.228e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 25.75\n",
      "Topic 0 frozen_forget_activations.norm= 25.875\n",
      "Topic 0 updated_retain_activations.norm= 23.625\n",
      "Topic 0 frozen_retain_activations.norm= 23.75\n",
      " 57%|███████████████████████▊                  | 85/150 [00:21<00:15,  4.26it/s]loss: 2.141 | unlearn_loss: 2.109 | retain_loss: 0.03857 | param_change: 2.074e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 21.75\n",
      "Topic 0 frozen_forget_activations.norm= 22.5\n",
      "Topic 0 updated_retain_activations.norm= 24.875\n",
      "Topic 0 frozen_retain_activations.norm= 24.875\n",
      " 57%|████████████████████████                  | 86/150 [00:21<00:14,  4.27it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 166, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.75 | unlearn_loss: 2.734 | retain_loss: 0.008972 | param_change: 9.477e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.875\n",
      "Topic 0 frozen_forget_activations.norm= 24.5\n",
      "Topic 0 updated_retain_activations.norm= 24.0\n",
      "Topic 0 frozen_retain_activations.norm= 24.125\n",
      " 58%|████████████████████████▎                 | 87/150 [00:21<00:14,  4.34it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 215, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.141 | unlearn_loss: 2.125 | retain_loss: 0.008911 | param_change: 9.298e-06\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.5\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 25.0\n",
      "Topic 0 frozen_retain_activations.norm= 25.125\n",
      " 59%|████████████████████████▋                 | 88/150 [00:22<00:14,  4.33it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 169, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.719 | unlearn_loss: 2.688 | retain_loss: 0.02856 | param_change: 1.293e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 24.125\n",
      "Topic 0 frozen_forget_activations.norm= 24.375\n",
      "Topic 0 updated_retain_activations.norm= 22.0\n",
      "Topic 0 frozen_retain_activations.norm= 22.25\n",
      " 59%|████████████████████████▉                 | 89/150 [00:22<00:14,  4.31it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 129, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.531 | unlearn_loss: 3.5 | retain_loss: 0.02393 | param_change: 2.098e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 27.25\n",
      "Topic 0 frozen_forget_activations.norm= 27.75\n",
      "Topic 0 updated_retain_activations.norm= 26.875\n",
      "Topic 0 frozen_retain_activations.norm= 27.0\n",
      " 60%|█████████████████████████▏                | 90/150 [00:22<00:13,  4.43it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 361, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.367 | unlearn_loss: 1.297 | retain_loss: 0.06787 | param_change: 3.29e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 19.375\n",
      "Topic 0 frozen_forget_activations.norm= 20.25\n",
      "Topic 0 updated_retain_activations.norm= 24.75\n",
      "Topic 0 frozen_retain_activations.norm= 24.75\n",
      " 61%|█████████████████████████▍                | 91/150 [00:22<00:14,  4.11it/s]loss: 2.875 | unlearn_loss: 2.859 | retain_loss: 0.01746 | param_change: 1.359e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.625\n",
      "Topic 0 frozen_forget_activations.norm= 25.25\n",
      "Topic 0 updated_retain_activations.norm= 23.5\n",
      "Topic 0 frozen_retain_activations.norm= 23.5\n",
      " 61%|█████████████████████████▊                | 92/150 [00:23<00:13,  4.21it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 258, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.812 | unlearn_loss: 1.797 | retain_loss: 0.01697 | param_change: 1.466e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 20.75\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 34.5\n",
      "Topic 0 frozen_retain_activations.norm= 34.5\n",
      " 62%|██████████████████████████                | 93/150 [00:23<00:13,  4.15it/s]loss: 1.68 | unlearn_loss: 1.648 | retain_loss: 0.03247 | param_change: 1.144e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 20.625\n",
      "Topic 0 frozen_forget_activations.norm= 21.0\n",
      "Topic 0 updated_retain_activations.norm= 288.0\n",
      "Topic 0 frozen_retain_activations.norm= 290.0\n",
      " 63%|██████████████████████████▎               | 94/150 [00:23<00:14,  3.81it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 103, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 4.406 | unlearn_loss: 4.375 | retain_loss: 0.04248 | param_change: 2.11e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 29.5\n",
      "Topic 0 frozen_forget_activations.norm= 30.0\n",
      "Topic 0 updated_retain_activations.norm= 22.0\n",
      "Topic 0 frozen_retain_activations.norm= 22.25\n",
      " 63%|██████████████████████████▌               | 95/150 [00:23<00:13,  4.00it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 161, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.953 | unlearn_loss: 2.812 | retain_loss: 0.1445 | param_change: 3.338e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.98828125\n",
      "Topic 0 updated_forget_activations.norm= 24.5\n",
      "Topic 0 frozen_forget_activations.norm= 25.0\n",
      "Topic 0 updated_retain_activations.norm= 21.75\n",
      "Topic 0 frozen_retain_activations.norm= 22.0\n",
      " 64%|██████████████████████████▉               | 96/150 [00:24<00:13,  4.06it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 282, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.664 | unlearn_loss: 1.648 | retain_loss: 0.01685 | param_change: 1.27e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 20.25\n",
      "Topic 0 frozen_forget_activations.norm= 20.75\n",
      "Topic 0 updated_retain_activations.norm= 21.75\n",
      "Topic 0 frozen_retain_activations.norm= 22.0\n",
      " 65%|███████████████████████████▏              | 97/150 [00:24<00:13,  3.88it/s]loss: 2.641 | unlearn_loss: 2.594 | retain_loss: 0.04004 | param_change: 1.931e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 23.25\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 22.125\n",
      "Topic 0 frozen_retain_activations.norm= 22.25\n",
      " 65%|███████████████████████████▍              | 98/150 [00:24<00:13,  3.99it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 269, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.734 | unlearn_loss: 1.719 | retain_loss: 0.01746 | param_change: 1.824e-05\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 20.25\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 26.25\n",
      "Topic 0 frozen_retain_activations.norm= 26.375\n",
      " 66%|███████████████████████████▋              | 99/150 [00:24<00:12,  3.95it/s]loss: 2.781 | unlearn_loss: 2.766 | retain_loss: 0.00946 | param_change: 7.868e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.125\n",
      "Topic 0 frozen_forget_activations.norm= 24.875\n",
      "Topic 0 updated_retain_activations.norm= 23.375\n",
      "Topic 0 frozen_retain_activations.norm= 23.5\n",
      " 67%|███████████████████████████▎             | 100/150 [00:25<00:12,  4.05it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 154, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.984 | unlearn_loss: 2.938 | retain_loss: 0.05078 | param_change: 2.134e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 24.5\n",
      "Topic 0 frozen_forget_activations.norm= 25.0\n",
      "Topic 0 updated_retain_activations.norm= 24.0\n",
      "Topic 0 frozen_retain_activations.norm= 24.0\n",
      " 67%|███████████████████████████▌             | 101/150 [00:25<00:11,  4.19it/s]loss: 2.312 | unlearn_loss: 2.297 | retain_loss: 0.0188 | param_change: 1.234e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.375\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 24.25\n",
      "Topic 0 frozen_retain_activations.norm= 24.5\n",
      " 68%|███████████████████████████▉             | 102/150 [00:25<00:11,  4.22it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 155, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.938 | unlearn_loss: 2.922 | retain_loss: 0.02185 | param_change: 1.371e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 24.5\n",
      "Topic 0 frozen_forget_activations.norm= 25.0\n",
      "Topic 0 updated_retain_activations.norm= 22.125\n",
      "Topic 0 frozen_retain_activations.norm= 22.25\n",
      " 69%|████████████████████████████▏            | 103/150 [00:25<00:11,  4.22it/s]loss: 2.344 | unlearn_loss: 2.328 | retain_loss: 0.01746 | param_change: 1.138e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.625\n",
      "Topic 0 frozen_forget_activations.norm= 23.125\n",
      "Topic 0 updated_retain_activations.norm= 21.5\n",
      "Topic 0 frozen_retain_activations.norm= 21.625\n",
      " 69%|████████████████████████████▍            | 104/150 [00:26<00:11,  4.12it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 245, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.953 | unlearn_loss: 1.875 | retain_loss: 0.07959 | param_change: 4.339e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.9921875\n",
      "Topic 0 updated_forget_activations.norm= 21.25\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 27.0\n",
      "Topic 0 frozen_retain_activations.norm= 27.0\n",
      " 70%|████████████████████████████▋            | 105/150 [00:26<00:10,  4.11it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 323, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.484 | unlearn_loss: 1.438 | retain_loss: 0.04932 | param_change: 2.325e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 19.5\n",
      "Topic 0 frozen_forget_activations.norm= 20.0\n",
      "Topic 0 updated_retain_activations.norm= 28.0\n",
      "Topic 0 frozen_retain_activations.norm= 28.125\n",
      " 71%|████████████████████████████▉            | 106/150 [00:26<00:11,  3.99it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 230, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.031 | unlearn_loss: 2 | retain_loss: 0.03857 | param_change: 1.585e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 21.5\n",
      "Topic 0 frozen_forget_activations.norm= 22.375\n",
      "Topic 0 updated_retain_activations.norm= 22.5\n",
      "Topic 0 frozen_retain_activations.norm= 22.75\n",
      " 71%|█████████████████████████████▏           | 107/150 [00:26<00:10,  3.99it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 165, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.766 | unlearn_loss: 2.75 | retain_loss: 0.01257 | param_change: 1.127e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.25\n",
      "Topic 0 frozen_forget_activations.norm= 24.75\n",
      "Topic 0 updated_retain_activations.norm= 26.375\n",
      "Topic 0 frozen_retain_activations.norm= 26.5\n",
      " 72%|█████████████████████████████▌           | 108/150 [00:27<00:10,  4.15it/s]loss: 2.453 | unlearn_loss: 2.438 | retain_loss: 0.01953 | param_change: 1.633e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.625\n",
      "Topic 0 updated_retain_activations.norm= 27.0\n",
      "Topic 0 frozen_retain_activations.norm= 27.125\n",
      " 73%|█████████████████████████████▊           | 109/150 [00:27<00:09,  4.27it/s]loss: 1.922 | unlearn_loss: 1.883 | retain_loss: 0.03613 | param_change: 1.884e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 21.25\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 22.5\n",
      "Topic 0 frozen_retain_activations.norm= 22.625\n",
      " 73%|██████████████████████████████           | 110/150 [00:27<00:09,  4.14it/s]loss: 1.766 | unlearn_loss: 1.75 | retain_loss: 0.01489 | param_change: 1.252e-05\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 20.25\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 34.0\n",
      "Topic 0 frozen_retain_activations.norm= 34.25\n",
      " 74%|██████████████████████████████▎          | 111/150 [00:27<00:09,  4.10it/s]loss: 2.297 | unlearn_loss: 2.281 | retain_loss: 0.01575 | param_change: 1.425e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.625\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 24.5\n",
      "Topic 0 frozen_retain_activations.norm= 24.625\n",
      " 75%|██████████████████████████████▌          | 112/150 [00:27<00:09,  4.16it/s]loss: 2.953 | unlearn_loss: 2.938 | retain_loss: 0.02002 | param_change: 1.681e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 24.375\n",
      "Topic 0 frozen_forget_activations.norm= 25.125\n",
      "Topic 0 updated_retain_activations.norm= 25.5\n",
      "Topic 0 frozen_retain_activations.norm= 25.625\n",
      " 75%|██████████████████████████████▉          | 113/150 [00:28<00:08,  4.29it/s]loss: 2.422 | unlearn_loss: 2.391 | retain_loss: 0.02747 | param_change: 1.633e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 23.25\n",
      "Topic 0 frozen_forget_activations.norm= 23.625\n",
      "Topic 0 updated_retain_activations.norm= 27.625\n",
      "Topic 0 frozen_retain_activations.norm= 28.0\n",
      " 76%|███████████████████████████████▏         | 114/150 [00:28<00:08,  4.39it/s]loss: 2.594 | unlearn_loss: 2.562 | retain_loss: 0.02844 | param_change: 2.074e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 23.5\n",
      "Topic 0 frozen_forget_activations.norm= 24.25\n",
      "Topic 0 updated_retain_activations.norm= 23.25\n",
      "Topic 0 frozen_retain_activations.norm= 23.5\n",
      " 77%|███████████████████████████████▍         | 115/150 [00:28<00:08,  4.33it/s]loss: 2.844 | unlearn_loss: 2.812 | retain_loss: 0.03296 | param_change: 1.454e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 24.0\n",
      "Topic 0 frozen_forget_activations.norm= 24.5\n",
      "Topic 0 updated_retain_activations.norm= 21.625\n",
      "Topic 0 frozen_retain_activations.norm= 22.0\n",
      " 77%|███████████████████████████████▋         | 116/150 [00:28<00:07,  4.28it/s]loss: 2.531 | unlearn_loss: 2.5 | retain_loss: 0.03271 | param_change: 1.526e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 23.0\n",
      "Topic 0 frozen_forget_activations.norm= 24.0\n",
      "Topic 0 updated_retain_activations.norm= 22.125\n",
      "Topic 0 frozen_retain_activations.norm= 22.375\n",
      " 78%|███████████████████████████████▉         | 117/150 [00:29<00:07,  4.27it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 193, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.422 | unlearn_loss: 2.359 | retain_loss: 0.05835 | param_change: 3.862e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 23.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.5\n",
      "Topic 0 updated_retain_activations.norm= 19.75\n",
      "Topic 0 frozen_retain_activations.norm= 19.875\n",
      " 79%|████████████████████████████████▎        | 118/150 [00:29<00:08,  3.97it/s]loss: 2.844 | unlearn_loss: 2.812 | retain_loss: 0.02478 | param_change: 1.991e-05\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.75\n",
      "Topic 0 frozen_forget_activations.norm= 24.5\n",
      "Topic 0 updated_retain_activations.norm= 32.0\n",
      "Topic 0 frozen_retain_activations.norm= 32.25\n",
      " 79%|████████████████████████████████▌        | 119/150 [00:29<00:07,  4.19it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 131, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.469 | unlearn_loss: 3.438 | retain_loss: 0.03088 | param_change: 1.55e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 26.75\n",
      "Topic 0 frozen_forget_activations.norm= 26.75\n",
      "Topic 0 updated_retain_activations.norm= 22.75\n",
      "Topic 0 frozen_retain_activations.norm= 22.75\n",
      " 80%|████████████████████████████████▊        | 120/150 [00:29<00:07,  4.26it/s]loss: 2.359 | unlearn_loss: 2.344 | retain_loss: 0.01636 | param_change: 1.144e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 28.875\n",
      "Topic 0 frozen_retain_activations.norm= 29.0\n",
      " 81%|█████████████████████████████████        | 121/150 [00:30<00:06,  4.34it/s]loss: 2.469 | unlearn_loss: 2.453 | retain_loss: 0.01471 | param_change: 1.228e-05\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.75\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 24.5\n",
      "Topic 0 frozen_retain_activations.norm= 24.5\n",
      " 81%|█████████████████████████████████▎       | 122/150 [00:30<00:06,  4.37it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 168, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.719 | unlearn_loss: 2.703 | retain_loss: 0.02063 | param_change: 1.597e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.75\n",
      "Topic 0 frozen_forget_activations.norm= 24.0\n",
      "Topic 0 updated_retain_activations.norm= 24.5\n",
      "Topic 0 frozen_retain_activations.norm= 24.5\n",
      " 82%|█████████████████████████████████▌       | 123/150 [00:30<00:06,  4.42it/s]loss: 2.234 | unlearn_loss: 2.219 | retain_loss: 0.02087 | param_change: 1.585e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.5\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 27.125\n",
      "Topic 0 frozen_retain_activations.norm= 27.25\n",
      " 83%|█████████████████████████████████▉       | 124/150 [00:30<00:05,  4.43it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 235, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.992 | unlearn_loss: 1.961 | retain_loss: 0.0282 | param_change: 1.174e-05\n",
      "unlearn_cosine_sim=0.98828125\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 21.125\n",
      "Topic 0 frozen_forget_activations.norm= 22.0\n",
      "Topic 0 updated_retain_activations.norm= 23.5\n",
      "Topic 0 frozen_retain_activations.norm= 23.5\n",
      " 83%|██████████████████████████████████▏      | 125/150 [00:30<00:05,  4.30it/s]loss: 2.703 | unlearn_loss: 2.688 | retain_loss: 0.01154 | param_change: 8.404e-06\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.75\n",
      "Topic 0 frozen_forget_activations.norm= 24.25\n",
      "Topic 0 updated_retain_activations.norm= 26.125\n",
      "Topic 0 frozen_retain_activations.norm= 26.25\n",
      " 84%|██████████████████████████████████▍      | 126/150 [00:31<00:05,  4.38it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 122, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.75 | unlearn_loss: 3.688 | retain_loss: 0.05688 | param_change: 1.788e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 27.5\n",
      "Topic 0 frozen_forget_activations.norm= 28.0\n",
      "Topic 0 updated_retain_activations.norm= 21.25\n",
      "Topic 0 frozen_retain_activations.norm= 21.5\n",
      " 85%|██████████████████████████████████▋      | 127/150 [00:31<00:05,  4.32it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 232, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2 | unlearn_loss: 1.984 | retain_loss: 0.01556 | param_change: 1.067e-05\n",
      "unlearn_cosine_sim=0.98828125\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 20.75\n",
      "Topic 0 frozen_forget_activations.norm= 21.75\n",
      "Topic 0 updated_retain_activations.norm= 25.75\n",
      "Topic 0 frozen_retain_activations.norm= 26.0\n",
      " 85%|██████████████████████████████████▉      | 128/150 [00:31<00:05,  4.30it/s]loss: 2.766 | unlearn_loss: 2.734 | retain_loss: 0.03198 | param_change: 1.86e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 24.5\n",
      "Topic 0 frozen_forget_activations.norm= 25.0\n",
      "Topic 0 updated_retain_activations.norm= 27.375\n",
      "Topic 0 frozen_retain_activations.norm= 27.75\n",
      " 86%|███████████████████████████████████▎     | 129/150 [00:31<00:04,  4.41it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 218, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.109 | unlearn_loss: 2.094 | retain_loss: 0.01624 | param_change: 1.055e-05\n",
      "unlearn_cosine_sim=0.98828125\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.375\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 24.75\n",
      "Topic 0 frozen_retain_activations.norm= 24.875\n",
      " 87%|███████████████████████████████████▌     | 130/150 [00:32<00:04,  4.37it/s]loss: 2.484 | unlearn_loss: 2.453 | retain_loss: 0.02942 | param_change: 2.36e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 23.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.75\n",
      "Topic 0 updated_retain_activations.norm= 25.125\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 87%|███████████████████████████████████▊     | 131/150 [00:32<00:04,  4.41it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 112, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 4.062 | unlearn_loss: 4.031 | retain_loss: 0.01782 | param_change: 1.311e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 28.5\n",
      "Topic 0 frozen_forget_activations.norm= 29.375\n",
      "Topic 0 updated_retain_activations.norm= 26.25\n",
      "Topic 0 frozen_retain_activations.norm= 26.5\n",
      " 88%|████████████████████████████████████     | 132/150 [00:32<00:03,  4.53it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 329, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.422 | unlearn_loss: 1.406 | retain_loss: 0.01208 | param_change: 1.198e-05\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 19.5\n",
      "Topic 0 frozen_forget_activations.norm= 20.375\n",
      "Topic 0 updated_retain_activations.norm= 27.125\n",
      "Topic 0 frozen_retain_activations.norm= 27.125\n",
      " 89%|████████████████████████████████████▎    | 133/150 [00:32<00:04,  4.23it/s]loss: 2.453 | unlearn_loss: 2.406 | retain_loss: 0.04858 | param_change: 1.478e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 23.0\n",
      "Topic 0 frozen_forget_activations.norm= 23.5\n",
      "Topic 0 updated_retain_activations.norm= 21.5\n",
      "Topic 0 frozen_retain_activations.norm= 21.625\n",
      " 89%|████████████████████████████████████▋    | 134/150 [00:33<00:03,  4.15it/s]loss: 2.281 | unlearn_loss: 2.266 | retain_loss: 0.01672 | param_change: 1.419e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 22.5\n",
      "Topic 0 frozen_forget_activations.norm= 23.0\n",
      "Topic 0 updated_retain_activations.norm= 28.5\n",
      "Topic 0 frozen_retain_activations.norm= 28.625\n",
      " 90%|████████████████████████████████████▉    | 135/150 [00:33<00:03,  4.25it/s]loss: 2.219 | unlearn_loss: 2.188 | retain_loss: 0.02637 | param_change: 1.359e-05\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 22.125\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 23.125\n",
      "Topic 0 frozen_retain_activations.norm= 23.25\n",
      " 91%|█████████████████████████████████████▏   | 136/150 [00:33<00:03,  4.21it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 224, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.062 | unlearn_loss: 2.047 | retain_loss: 0.01306 | param_change: 1.222e-05\n",
      "unlearn_cosine_sim=1.0\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.75\n",
      "Topic 0 frozen_forget_activations.norm= 22.125\n",
      "Topic 0 updated_retain_activations.norm= 29.75\n",
      "Topic 0 frozen_retain_activations.norm= 29.75\n",
      " 91%|█████████████████████████████████████▍   | 137/150 [00:33<00:03,  4.29it/s]loss: 2.766 | unlearn_loss: 2.734 | retain_loss: 0.03442 | param_change: 1.079e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 24.0\n",
      "Topic 0 frozen_forget_activations.norm= 24.5\n",
      "Topic 0 updated_retain_activations.norm= 20.5\n",
      "Topic 0 frozen_retain_activations.norm= 20.5\n",
      " 92%|█████████████████████████████████████▋   | 138/150 [00:34<00:02,  4.09it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 250, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.891 | unlearn_loss: 1.828 | retain_loss: 0.06348 | param_change: 5.507e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 20.625\n",
      "Topic 0 frozen_forget_activations.norm= 21.25\n",
      "Topic 0 updated_retain_activations.norm= 25.875\n",
      "Topic 0 frozen_retain_activations.norm= 25.875\n",
      " 93%|█████████████████████████████████████▉   | 139/150 [00:34<00:02,  4.08it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 138, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.297 | unlearn_loss: 3.266 | retain_loss: 0.02917 | param_change: 2.635e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 25.625\n",
      "Topic 0 frozen_forget_activations.norm= 26.5\n",
      "Topic 0 updated_retain_activations.norm= 23.25\n",
      "Topic 0 frozen_retain_activations.norm= 23.25\n",
      " 93%|██████████████████████████████████████▎  | 140/150 [00:34<00:02,  4.22it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 216, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.125 | unlearn_loss: 2.109 | retain_loss: 0.01611 | param_change: 1.138e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 21.75\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 25.25\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 94%|██████████████████████████████████████▌  | 141/150 [00:34<00:02,  4.25it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 311, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.555 | unlearn_loss: 1.508 | retain_loss: 0.04468 | param_change: 2.503e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 20.25\n",
      "Topic 0 frozen_forget_activations.norm= 20.75\n",
      "Topic 0 updated_retain_activations.norm= 25.25\n",
      "Topic 0 frozen_retain_activations.norm= 25.5\n",
      " 95%|██████████████████████████████████████▊  | 142/150 [00:35<00:01,  4.07it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 331, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.414 | unlearn_loss: 1.398 | retain_loss: 0.01306 | param_change: 1.168e-05\n",
      "unlearn_cosine_sim=0.98828125\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 19.375\n",
      "Topic 0 frozen_forget_activations.norm= 20.25\n",
      "Topic 0 updated_retain_activations.norm= 26.0\n",
      "Topic 0 frozen_retain_activations.norm= 26.25\n",
      " 95%|███████████████████████████████████████  | 143/150 [00:35<00:01,  3.92it/s]loss: 2.266 | unlearn_loss: 2.219 | retain_loss: 0.05347 | param_change: 3.481e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 22.25\n",
      "Topic 0 frozen_forget_activations.norm= 22.75\n",
      "Topic 0 updated_retain_activations.norm= 24.5\n",
      "Topic 0 frozen_retain_activations.norm= 24.5\n",
      " 96%|███████████████████████████████████████▎ | 144/150 [00:35<00:01,  4.03it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 115, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.938 | unlearn_loss: 3.906 | retain_loss: 0.02856 | param_change: 1.752e-05\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 27.75\n",
      "Topic 0 frozen_forget_activations.norm= 29.0\n",
      "Topic 0 updated_retain_activations.norm= 22.25\n",
      "Topic 0 frozen_retain_activations.norm= 22.5\n",
      " 97%|███████████████████████████████████████▋ | 145/150 [00:35<00:01,  4.15it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 171, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.672 | unlearn_loss: 2.656 | retain_loss: 0.01794 | param_change: 1.431e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 23.625\n",
      "Topic 0 frozen_forget_activations.norm= 24.5\n",
      "Topic 0 updated_retain_activations.norm= 25.125\n",
      "Topic 0 frozen_retain_activations.norm= 25.25\n",
      " 97%|███████████████████████████████████████▉ | 146/150 [00:35<00:00,  4.26it/s]loss: 2.344 | unlearn_loss: 2.297 | retain_loss: 0.04199 | param_change: 1.597e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.99609375\n",
      "Topic 0 updated_forget_activations.norm= 22.875\n",
      "Topic 0 frozen_forget_activations.norm= 23.25\n",
      "Topic 0 updated_retain_activations.norm= 20.875\n",
      "Topic 0 frozen_retain_activations.norm= 21.125\n",
      " 98%|████████████████████████████████████████▏| 147/150 [00:36<00:00,  4.06it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 147, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 3.094 | unlearn_loss: 3.078 | retain_loss: 0.02258 | param_change: 1.514e-05\n",
      "unlearn_cosine_sim=0.9921875\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 25.0\n",
      "Topic 0 frozen_forget_activations.norm= 25.875\n",
      "Topic 0 updated_retain_activations.norm= 23.875\n",
      "Topic 0 frozen_retain_activations.norm= 24.0\n",
      " 99%|████████████████████████████████████████▍| 148/150 [00:36<00:00,  4.20it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 318, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 1.484 | unlearn_loss: 1.469 | retain_loss: 0.01324 | param_change: 1.055e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=1.0\n",
      "Topic 0 updated_forget_activations.norm= 19.625\n",
      "Topic 0 frozen_forget_activations.norm= 20.0\n",
      "Topic 0 updated_retain_activations.norm= 24.5\n",
      "Topic 0 frozen_retain_activations.norm= 24.5\n",
      " 99%|████████████████████████████████████████▋| 149/150 [00:36<00:00,  4.03it/s]/storage/ice1/6/7/jli928/model-unlearning/rmu/unlearn.py:68: UserWarning: Using a target size (torch.Size([1, 1, 4096])) that is different to the input size (torch.Size([2, 210, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  unlearn_loss = torch.nn.functional.mse_loss(\n",
      "loss: 2.266 | unlearn_loss: 2.172 | retain_loss: 0.09912 | param_change: 3.242e-05\n",
      "unlearn_cosine_sim=0.99609375\n",
      "retain_cosine_sim=0.9921875\n",
      "Topic 0 updated_forget_activations.norm= 22.0\n",
      "Topic 0 frozen_forget_activations.norm= 22.5\n",
      "Topic 0 updated_retain_activations.norm= 19.625\n",
      "Topic 0 frozen_retain_activations.norm= 20.25\n",
      "100%|█████████████████████████████████████████| 150/150 [00:37<00:00,  4.05it/s]\n",
      "Saved model to models/alpaca_rmu_alpha_100\n"
     ]
    }
   ],
   "source": [
    "!python3 -m rmu.unlearn --model_name PKU-Alignment/alpaca-7b-reproduced --max_num_batches 150 --batch_size=2 --retain_corpora SafeRLHF-corpora/safe_train_sampled --forget_corpora SafeRLHF-corpora/Privacy_Violation_train --layer_id 7 --steering_coeffs 6.5 --alpha 100 --lr 1e-4 --seed 42 --output_dir models/alpaca_rmu_alpha_100 --verbose"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model-unlearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
